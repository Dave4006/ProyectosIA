{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar Modulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import plotly.express as px\n",
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import display"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importación de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>normal</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>normal</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normal</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>normal</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>normal</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>collision_in_tool</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>collision_in_tool</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>collision_in_tool</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>collision_in_tool</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>collision_in_tool</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                labels 1  2  3  4  5 \n",
       "0               normal               \n",
       "1               normal               \n",
       "2               normal               \n",
       "3               normal               \n",
       "4               normal               \n",
       "..                 ... .. .. .. .. ..\n",
       "159  collision_in_tool               \n",
       "160  collision_in_tool               \n",
       "161  collision_in_tool               \n",
       "162  collision_in_tool               \n",
       "163  collision_in_tool               \n",
       "\n",
       "[164 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[[ -2.,  -1.,  81.,   0.,  -5.,   0.],\n",
       "        [ -2.,  -1.,  79.,   0.,  -4.,   0.],\n",
       "        [ -2.,  -1.,  79.,   0.,  -4.,   0.],\n",
       "        ...,\n",
       "        [ -2.,  -1.,  78.,   0.,  -5.,   0.],\n",
       "        [ -3.,  -1.,  80.,   1.,  -4.,   1.],\n",
       "        [ -2.,  -1.,  79.,   0.,  -4.,   0.]],\n",
       "\n",
       "       [[  6.,  -1.,  79.,  -2.,   4.,  -3.],\n",
       "        [ 42.,  -3.,  80.,   5.,  53.,   3.],\n",
       "        [ -5.,   4.,  74., -15., -10.,  -1.],\n",
       "        ...,\n",
       "        [ -1.,  -5.,  80.,   6.,  -6.,   0.],\n",
       "        [ -4.,   5.,  78., -14.,  -9.,  -4.],\n",
       "        [ -4.,   1.,  80.,  -3., -12.,   5.]],\n",
       "\n",
       "       [[ -2.,  -6.,  85.,  14.,  -5.,   2.],\n",
       "        [  0.,   2.,  74.,  -7.,   1.,   0.],\n",
       "        [ -4.,  -5.,  76.,   7., -11.,   4.],\n",
       "        ...,\n",
       "        [  0.,  -9.,  87.,  13.,  -5.,   2.],\n",
       "        [ -5.,   5.,  67., -17., -16.,   7.],\n",
       "        [ -6., -10.,  86.,  16., -14.,  -1.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-12.,  17.,   3., -19., -10.,  -4.],\n",
       "        [-12.,  12.,  11., -13., -16.,  -4.],\n",
       "        [ -8.,   3.,   6.,   2., -11.,  -4.],\n",
       "        ...,\n",
       "        [  0.,   1.,   3.,   1.,   1.,  -3.],\n",
       "        [  1.,   2.,   9.,   0.,   3.,  -4.],\n",
       "        [  1.,   2.,   9.,   0.,   3.,  -4.]],\n",
       "\n",
       "       [[-41.,  21.,  -5., -23., -59.,  -4.],\n",
       "        [-32.,  21.,  -6., -25., -45.,  -4.],\n",
       "        [-21.,  12.,  -6., -14., -31.,  -4.],\n",
       "        ...,\n",
       "        [ -4.,   4.,   3.,   0.,  -1.,  -3.],\n",
       "        [ -4.,   3.,   2.,   2.,  -3.,  -3.],\n",
       "        [ -2.,   3.,   5.,   0.,  -2.,  -3.]],\n",
       "\n",
       "       [[  9., -10., -11.,  17.,   7.,  -4.],\n",
       "        [  5.,   0.,   4.,   0.,   7.,  -4.],\n",
       "        [ -3.,   6.,  -2.,  -8.,  -8.,  -4.],\n",
       "        ...,\n",
       "        [ -1.,   1.,  -3.,  -3.,  -2.,  -3.],\n",
       "        [  0.,  -1.,  -5.,  -1.,   1.,  -3.],\n",
       "        [ -1.,   1.,   4.,   0.,  -1.,  -3.]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = np.loadtxt(\"lp5.csv\", delimiter=\",\", dtype=str)\n",
    "data_copy = data #va de 0 a 2623 o sea 2624 datos\n",
    "cont = 16\n",
    "labels = []\n",
    "numbers = []\n",
    "features= np.zeros((164,15,6))\n",
    "\n",
    "for i in range(len(data_copy)):\n",
    "    if(cont == 16):\n",
    "        labels.append(data_copy[i])\n",
    "    if(cont<16):\n",
    "        numbers.append(data_copy[i])\n",
    "    cont -= 1\n",
    "    if(cont == 0):\n",
    "        cont = 16\n",
    "        \n",
    "cont = 0\n",
    "for i in range(164):\n",
    "    for j in range(15):\n",
    "        for z in range(6):\n",
    "            features[i][j][z] = numbers[cont][z]\n",
    "        cont += 1\n",
    "        \n",
    "labels_df = pd.DataFrame(labels, columns=['labels','1','2','3','4','5'])\n",
    "#labels_df = labels_df.loc[:,['labels']]\n",
    "display(labels_df)\n",
    "display(features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manejo de Datos y Normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dave4\\AppData\\Local\\Temp\\ipykernel_19644\\1709456343.py:8: FutureWarning:\n",
      "\n",
      "In a future version of pandas all arguments of StringMethods.split except for the argument 'pat' will be keyword-only.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1  2  3  4  5\n",
       "0    1  0  0  0  0\n",
       "1    1  0  0  0  0\n",
       "2    1  0  0  0  0\n",
       "3    1  0  0  0  0\n",
       "4    1  0  0  0  0\n",
       "..  .. .. .. .. ..\n",
       "159  0  1  0  0  0\n",
       "160  0  1  0  0  0\n",
       "161  0  1  0  0  0\n",
       "162  0  1  0  0  0\n",
       "163  0  1  0  0  0\n",
       "\n",
       "[164 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[[0.77660263, 0.78156702, 0.79084826, 0.77055903, 0.7684006 ,\n",
       "         0.77422836],\n",
       "        [0.77466005, 0.78739478, 0.78717893, 0.75156486, 0.7638679 ,\n",
       "         0.77206993],\n",
       "        [0.77401252, 0.78804231, 0.79041658, 0.74465789, 0.76106195,\n",
       "         0.77012735],\n",
       "        ...,\n",
       "        [0.78005612, 0.7804878 , 0.78437298, 0.78135118, 0.78113533,\n",
       "         0.78027196],\n",
       "        [0.78027196, 0.78091949, 0.77962443, 0.78091949, 0.78027196,\n",
       "         0.78027196],\n",
       "        [0.78027196, 0.78070365, 0.78286208, 0.78156702, 0.78091949,\n",
       "         0.78005612]],\n",
       "\n",
       "       [[0.78027196, 0.77940859, 0.79905029, 0.78372545, 0.77962443,\n",
       "         0.78113533],\n",
       "        [0.78070365, 0.78113533, 0.79667602, 0.77919275, 0.78091949,\n",
       "         0.78070365],\n",
       "        [0.77984028, 0.77962443, 0.79710771, 0.78221455, 0.77832938,\n",
       "         0.78156702],\n",
       "        ...,\n",
       "        [0.78070365, 0.77876106, 0.79948198, 0.78350961, 0.77962443,\n",
       "         0.78113533],\n",
       "        [0.77962443, 0.78178286, 0.79516512, 0.77703432, 0.77725016,\n",
       "         0.78221455],\n",
       "        [0.77940859, 0.77854522, 0.79926613, 0.78415713, 0.77768185,\n",
       "         0.7804878 ]],\n",
       "\n",
       "       [[0.78502051, 0.77725016, 0.78264623, 0.78631556, 0.78696309,\n",
       "         0.7804878 ],\n",
       "        [0.78588388, 0.78005612, 0.78717893, 0.78243039, 0.78890568,\n",
       "         0.77984028],\n",
       "        [0.78653141, 0.77876106, 0.78027196, 0.78480466, 0.78933736,\n",
       "         0.78027196],\n",
       "        ...,\n",
       "        [0.78005612, 0.78135118, 0.77962443, 0.7804878 , 0.77962443,\n",
       "         0.77962443],\n",
       "        [0.78005612, 0.78091949, 0.7789769 , 0.78091949, 0.78027196,\n",
       "         0.77962443],\n",
       "        [0.7804878 , 0.78091949, 0.78005612, 0.78156702, 0.78070365,\n",
       "         0.77962443]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.78005612, 0.78070365, 0.79689186, 0.77919275, 0.77660263,\n",
       "         0.77984028],\n",
       "        [0.77962443, 0.77832938, 0.79883445, 0.78307792, 0.77617095,\n",
       "         0.77811353],\n",
       "        [0.78005612, 0.78264623, 0.79516512, 0.77487589, 0.77681848,\n",
       "         0.7789769 ],\n",
       "        ...,\n",
       "        [0.7804878 , 0.77832938, 0.79969782, 0.78307792, 0.777466  ,\n",
       "         0.77854522],\n",
       "        [0.77940859, 0.77984028, 0.79710771, 0.77962443, 0.77573926,\n",
       "         0.77984028],\n",
       "        [0.77940859, 0.78243039, 0.79710771, 0.77530758, 0.77617095,\n",
       "         0.77940859]],\n",
       "\n",
       "       [[0.77077488, 0.79494928, 0.77617095, 0.75588172, 0.77832938,\n",
       "         0.7804878 ],\n",
       "        [0.7653788 , 0.78135118, 0.78243039, 0.777466  , 0.7638679 ,\n",
       "         0.78027196],\n",
       "        [0.76365206, 0.78264623, 0.78350961, 0.78005612, 0.75674509,\n",
       "         0.78027196],\n",
       "        ...,\n",
       "        [0.77984028, 0.78113533, 0.78243039, 0.78113533, 0.78005612,\n",
       "         0.78005612],\n",
       "        [0.78027196, 0.78113533, 0.78350961, 0.78091949, 0.78070365,\n",
       "         0.78027196],\n",
       "        [0.7804878 , 0.78091949, 0.78480466, 0.78221455, 0.78156702,\n",
       "         0.78005612]],\n",
       "\n",
       "       [[0.77789769, 0.77789769, 0.7744442 , 0.78696309, 0.78653141,\n",
       "         0.77789769],\n",
       "        [0.77832938, 0.77811353, 0.77422836, 0.78631556, 0.78868983,\n",
       "         0.7789769 ],\n",
       "        [0.77832938, 0.77789769, 0.77466005, 0.78696309, 0.78804231,\n",
       "         0.77768185],\n",
       "        ...,\n",
       "        [0.67882581, 0.70472696, 0.09842435, 0.7759551 , 0.85732787,\n",
       "         0.74940643],\n",
       "        [0.69933089, 0.73796676, 0.34448521, 0.77099072, 0.81674941,\n",
       "         0.77530758],\n",
       "        [0.72199439, 0.73170732, 0.7155191 , 0.81804446, 0.69156054,\n",
       "         0.77012735]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1  2  3  4  5\n",
       "84   0  0  1  0  0\n",
       "2    1  0  0  0  0\n",
       "94   0  1  0  0  0\n",
       "45   0  0  1  0  0\n",
       "42   0  0  1  0  0\n",
       "..  .. .. .. .. ..\n",
       "71   0  0  1  0  0\n",
       "106  0  0  0  1  0\n",
       "14   1  0  0  0  0\n",
       "92   0  1  0  0  0\n",
       "102  0  0  0  0  1\n",
       "\n",
       "[131 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes_dict = {'normal':'1 0 0 0 0', #1\n",
    "        'collision_in_tool':'0 1 0 0 0', #2\n",
    "        'collision_in_part':'0 0 1 0 0', #3\n",
    "        'bottom_collision':'0 0 0 1 0', #4\n",
    "        'bottom_obstruction':'0 0 0 0 1'} #5\n",
    "\n",
    "labels_df = labels_df.replace({'labels':classes_dict})\n",
    "labels_df[['1', '2', '3', '4', '5']] = labels_df['labels'].str.split(' ', 4, expand= True)\n",
    "labels_df = labels_df.loc[:,['1', '2', '3', '4', '5']]\n",
    "labels_df[['1', '2', '3', '4', '5']]=labels_df[['1', '2', '3', '4', '5']].astype(str).astype(int)\n",
    "display(labels_df)\n",
    "\n",
    "def norm(x):\n",
    "    x_min = x.min()\n",
    "    x_max = x.max()\n",
    "    range = x_max - x_min  #min max entre 0 y 1\n",
    "    return((x-x_min)/(range))\n",
    "\n",
    "norm_features = norm(features)\n",
    "#split para entrenamiento y validacion\n",
    "train_features, test_features, train_labels, test_labels  = train_test_split(norm_features, labels_df, test_size=0.2, random_state= 42)\n",
    "display(train_features)\n",
    "display(train_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_48 (Conv2D)          (None, 13, 4, 16)         160       \n",
      "                                                                 \n",
      " max_pooling2d_48 (MaxPoolin  (None, 4, 1, 16)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4, 1, 16)          0         \n",
      "                                                                 \n",
      " flatten_47 (Flatten)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_94 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,645\n",
      "Trainable params: 4,645\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def my_model(learning_rate):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape = (15,6,1)), # #de feature maps, dimensiones del kernel, kernel entre más pequeño mejor y se prefiere un número impar\n",
    "        tf.keras.layers.MaxPooling2D((3,3)), # dimensiones del pooling\n",
    "        tf.keras.layers.Dropout(.2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(5, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy','mean_squared_error'])\n",
    "    \n",
    "    return model\n",
    "# input shape es 15 filas, 6 columnas y 1 canal de color\n",
    "model = my_model(0.01)\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, features, labels, epochs, batch_size):\n",
    "    history = model.fit(\n",
    "        x = features,\n",
    "        y = labels,\n",
    "        epochs= epochs,\n",
    "        batch_size= batch_size,\n",
    "        validation_split= 0.25\n",
    "    )\n",
    "    hist= pd.DataFrame(history.history) #se guardan los valores de errores y metricas en un diccionario\n",
    "    hist['epoch'] = history.epoch #los epochs se deben añadir aparte\n",
    "    mse = hist['mean_squared_error']\n",
    "    return hist, mse"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizaciones\n",
    "### Pasos para visualizar los filtros:\n",
    "##### 1. Iterar por todas las capas del modelo usando model.layers\n",
    "##### 2. Si la capa actual es de convolucion se extraen los pesos y sesgos usando get_weights()\n",
    "##### 3. Se normalizan los pesos de los filtros entre 0 y 1\n",
    "##### 4. Se plotean los filtros para cada capa convolutional y todos los canales de color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualización de los filtros\n",
    "\n",
    "def view_filters(model):\n",
    "    for layer in model.layers:\n",
    "        if 'conv' in layer.name:\n",
    "            filters, bias= layer.get_weights()\n",
    "            print(layer.name, filters.shape)\n",
    "        #normalize filter values between  0 and 1 for visualization\n",
    "            f_min, f_max = filters.min(), filters.max()\n",
    "            filters = (filters - f_min) / (f_max - f_min)  \n",
    "            print(filters.shape[3])\n",
    "            axis_x=1\n",
    "        #plotting all the filters\n",
    "            for i in range(filters.shape[3]):\n",
    "        #for i in range(6):\n",
    "            #get the filters\n",
    "                filt=filters[:,:,:, i]\n",
    "                plotFilters(filt)\n",
    "                \n",
    "def plotFilters(conv_filter):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(5,5))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( conv_filter, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "   #plt.savefig('filters.jpg')\n",
    "    plt.show()\n",
    "## Visualización de las curvas de pérdida\n",
    "\n",
    "def loss_curves(history):\n",
    "    hist = history\n",
    "    labels = {\"mean_squared_error\":\"Training Loss\", \"val_mean_squared_error\":\"Validation Loss\"}\n",
    "    hist.rename(columns = labels, inplace = True)\n",
    "    \n",
    "    fig = px.line(hist, x='epoch', y=['Training Loss', 'Validation Loss'],\n",
    "                title='Gráficas de Pérdida de Entrenamiento y Evaluación',\n",
    "                labels={\"epoch\": \"Epoch\", \"value\":\"Mean Square Error\", \"variable\":\"Curvas de Pérdida\"},\n",
    "                color_discrete_map={ # replaces default color mapping by value\n",
    "                \"Training Loss\": \"#46039f\", \"Validation Loss\": \"#fb9f3a\"})\n",
    "    fig.update_layout(template='plotly_white')\n",
    "    fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se corren las funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dave4\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\backend.py:5676: UserWarning:\n",
      "\n",
      "\"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 1s 3ms/step - loss: 0.5766 - accuracy: 0.1939 - mean_squared_error: 0.1615 - val_loss: 0.4894 - val_accuracy: 0.2727 - val_mean_squared_error: 0.1563\n",
      "Epoch 2/100\n",
      "47/98 [=============>................] - ETA: 0s - loss: 0.4911 - accuracy: 0.3191 - mean_squared_error: 0.1563"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dave4\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\backend.py:5676: UserWarning:\n",
      "\n",
      "\"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.3163 - mean_squared_error: 0.1571 - val_loss: 0.4921 - val_accuracy: 0.2727 - val_mean_squared_error: 0.1579\n",
      "Epoch 3/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4920 - accuracy: 0.2857 - mean_squared_error: 0.1566 - val_loss: 0.4917 - val_accuracy: 0.2727 - val_mean_squared_error: 0.1599\n",
      "Epoch 4/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4930 - accuracy: 0.2959 - mean_squared_error: 0.1592 - val_loss: 0.4952 - val_accuracy: 0.2727 - val_mean_squared_error: 0.1576\n",
      "Epoch 5/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4920 - accuracy: 0.2857 - mean_squared_error: 0.1574 - val_loss: 0.4910 - val_accuracy: 0.2727 - val_mean_squared_error: 0.1568\n",
      "Epoch 6/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4842 - accuracy: 0.2959 - mean_squared_error: 0.1545 - val_loss: 0.5050 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1612\n",
      "Epoch 7/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4915 - accuracy: 0.2959 - mean_squared_error: 0.1569 - val_loss: 0.4890 - val_accuracy: 0.2727 - val_mean_squared_error: 0.1564\n",
      "Epoch 8/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4863 - accuracy: 0.3776 - mean_squared_error: 0.1555 - val_loss: 0.4825 - val_accuracy: 0.2727 - val_mean_squared_error: 0.1557\n",
      "Epoch 9/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4793 - accuracy: 0.3367 - mean_squared_error: 0.1528 - val_loss: 0.4774 - val_accuracy: 0.2727 - val_mean_squared_error: 0.1543\n",
      "Epoch 10/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4665 - accuracy: 0.3265 - mean_squared_error: 0.1473 - val_loss: 0.4722 - val_accuracy: 0.2727 - val_mean_squared_error: 0.1550\n",
      "Epoch 11/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4676 - accuracy: 0.3776 - mean_squared_error: 0.1489 - val_loss: 0.4831 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1527\n",
      "Epoch 12/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4606 - accuracy: 0.4286 - mean_squared_error: 0.1443 - val_loss: 0.4712 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1490\n",
      "Epoch 13/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4507 - accuracy: 0.4286 - mean_squared_error: 0.1410 - val_loss: 0.4595 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1492\n",
      "Epoch 14/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4468 - accuracy: 0.4082 - mean_squared_error: 0.1400 - val_loss: 0.4570 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1465\n",
      "Epoch 15/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4434 - accuracy: 0.4388 - mean_squared_error: 0.1385 - val_loss: 0.4527 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1446\n",
      "Epoch 16/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4370 - accuracy: 0.4286 - mean_squared_error: 0.1361 - val_loss: 0.4521 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1454\n",
      "Epoch 17/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4288 - accuracy: 0.4388 - mean_squared_error: 0.1342 - val_loss: 0.4471 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1447\n",
      "Epoch 18/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.4184 - mean_squared_error: 0.1357 - val_loss: 0.4565 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1464\n",
      "Epoch 19/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4261 - accuracy: 0.3980 - mean_squared_error: 0.1346 - val_loss: 0.4440 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1435\n",
      "Epoch 20/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4231 - accuracy: 0.4592 - mean_squared_error: 0.1323 - val_loss: 0.4449 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1475\n",
      "Epoch 21/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4216 - accuracy: 0.4184 - mean_squared_error: 0.1351 - val_loss: 0.4405 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1444\n",
      "Epoch 22/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4188 - accuracy: 0.4388 - mean_squared_error: 0.1325 - val_loss: 0.4583 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1503\n",
      "Epoch 23/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4152 - accuracy: 0.4388 - mean_squared_error: 0.1321 - val_loss: 0.4360 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1436\n",
      "Epoch 24/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4132 - accuracy: 0.4388 - mean_squared_error: 0.1329 - val_loss: 0.4396 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1448\n",
      "Epoch 25/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4082 - accuracy: 0.4082 - mean_squared_error: 0.1291 - val_loss: 0.4377 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1467\n",
      "Epoch 26/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4060 - accuracy: 0.4490 - mean_squared_error: 0.1299 - val_loss: 0.4379 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1450\n",
      "Epoch 27/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.4388 - mean_squared_error: 0.1324 - val_loss: 0.4440 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1495\n",
      "Epoch 28/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4090 - accuracy: 0.4490 - mean_squared_error: 0.1295 - val_loss: 0.4407 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1482\n",
      "Epoch 29/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4011 - accuracy: 0.4490 - mean_squared_error: 0.1297 - val_loss: 0.4328 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1448\n",
      "Epoch 30/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4047 - accuracy: 0.4490 - mean_squared_error: 0.1296 - val_loss: 0.4325 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1422\n",
      "Epoch 31/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4049 - accuracy: 0.4592 - mean_squared_error: 0.1300 - val_loss: 0.4324 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1451\n",
      "Epoch 32/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4063 - accuracy: 0.4490 - mean_squared_error: 0.1305 - val_loss: 0.4335 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1448\n",
      "Epoch 33/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4036 - accuracy: 0.4490 - mean_squared_error: 0.1295 - val_loss: 0.4306 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1432\n",
      "Epoch 34/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4009 - accuracy: 0.4592 - mean_squared_error: 0.1285 - val_loss: 0.4318 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1437\n",
      "Epoch 35/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.3973 - accuracy: 0.4490 - mean_squared_error: 0.1282 - val_loss: 0.4369 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1471\n",
      "Epoch 36/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4002 - accuracy: 0.4490 - mean_squared_error: 0.1280 - val_loss: 0.4364 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1485\n",
      "Epoch 37/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4055 - accuracy: 0.4490 - mean_squared_error: 0.1317 - val_loss: 0.4337 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1433\n",
      "Epoch 38/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.4286 - mean_squared_error: 0.1320 - val_loss: 0.4302 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1416\n",
      "Epoch 39/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4026 - accuracy: 0.4490 - mean_squared_error: 0.1301 - val_loss: 0.4331 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1454\n",
      "Epoch 40/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4089 - accuracy: 0.4388 - mean_squared_error: 0.1315 - val_loss: 0.4370 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1471\n",
      "Epoch 41/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.3988 - accuracy: 0.4490 - mean_squared_error: 0.1284 - val_loss: 0.4313 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1445\n",
      "Epoch 42/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.3990 - accuracy: 0.4490 - mean_squared_error: 0.1302 - val_loss: 0.4308 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1438\n",
      "Epoch 43/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.3975 - accuracy: 0.4490 - mean_squared_error: 0.1285 - val_loss: 0.4328 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1457\n",
      "Epoch 44/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4003 - accuracy: 0.4490 - mean_squared_error: 0.1289 - val_loss: 0.4374 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1494\n",
      "Epoch 45/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.3965 - accuracy: 0.4490 - mean_squared_error: 0.1284 - val_loss: 0.4343 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1492\n",
      "Epoch 46/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4018 - accuracy: 0.4286 - mean_squared_error: 0.1304 - val_loss: 0.4284 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1447\n",
      "Epoch 47/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.3987 - accuracy: 0.4490 - mean_squared_error: 0.1288 - val_loss: 0.4275 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1427\n",
      "Epoch 48/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.3997 - accuracy: 0.4490 - mean_squared_error: 0.1307 - val_loss: 0.4341 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1472\n",
      "Epoch 49/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3960 - accuracy: 0.4388 - mean_squared_error: 0.1284 - val_loss: 0.4325 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1489\n",
      "Epoch 50/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4019 - accuracy: 0.4490 - mean_squared_error: 0.1318 - val_loss: 0.4354 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1462\n",
      "Epoch 51/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3996 - accuracy: 0.4388 - mean_squared_error: 0.1295 - val_loss: 0.4253 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1427\n",
      "Epoch 52/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3953 - accuracy: 0.4490 - mean_squared_error: 0.1288 - val_loss: 0.4285 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1457\n",
      "Epoch 53/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4019 - accuracy: 0.4490 - mean_squared_error: 0.1264 - val_loss: 0.4274 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1441\n",
      "Epoch 54/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4009 - accuracy: 0.4490 - mean_squared_error: 0.1295 - val_loss: 0.4336 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1483\n",
      "Epoch 55/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.3963 - accuracy: 0.4490 - mean_squared_error: 0.1283 - val_loss: 0.4285 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1449\n",
      "Epoch 56/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3978 - accuracy: 0.4490 - mean_squared_error: 0.1282 - val_loss: 0.4291 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1469\n",
      "Epoch 57/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.3989 - accuracy: 0.4490 - mean_squared_error: 0.1307 - val_loss: 0.4316 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1480\n",
      "Epoch 58/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.3995 - accuracy: 0.4490 - mean_squared_error: 0.1288 - val_loss: 0.4270 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1432\n",
      "Epoch 59/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4072 - accuracy: 0.4286 - mean_squared_error: 0.1315 - val_loss: 0.4338 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1459\n",
      "Epoch 60/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3953 - accuracy: 0.4490 - mean_squared_error: 0.1276 - val_loss: 0.4267 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1451\n",
      "Epoch 61/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.3950 - accuracy: 0.4490 - mean_squared_error: 0.1295 - val_loss: 0.4295 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1484\n",
      "Epoch 62/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.3996 - accuracy: 0.4490 - mean_squared_error: 0.1288 - val_loss: 0.4385 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1507\n",
      "Epoch 63/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4024 - accuracy: 0.4490 - mean_squared_error: 0.1294 - val_loss: 0.4371 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1482\n",
      "Epoch 64/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.3975 - accuracy: 0.4490 - mean_squared_error: 0.1289 - val_loss: 0.4352 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1481\n",
      "Epoch 65/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.3943 - accuracy: 0.4490 - mean_squared_error: 0.1284 - val_loss: 0.4435 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1508\n",
      "Epoch 66/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.3962 - accuracy: 0.4490 - mean_squared_error: 0.1289 - val_loss: 0.4239 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1421\n",
      "Epoch 67/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.3965 - accuracy: 0.4490 - mean_squared_error: 0.1277 - val_loss: 0.4311 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1470\n",
      "Epoch 68/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.3956 - accuracy: 0.4490 - mean_squared_error: 0.1281 - val_loss: 0.4274 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1451\n",
      "Epoch 69/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.3978 - accuracy: 0.4490 - mean_squared_error: 0.1286 - val_loss: 0.4309 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1469\n",
      "Epoch 70/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.3956 - accuracy: 0.4490 - mean_squared_error: 0.1286 - val_loss: 0.4317 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1475\n",
      "Epoch 71/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.3953 - accuracy: 0.4490 - mean_squared_error: 0.1275 - val_loss: 0.4300 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1479\n",
      "Epoch 72/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.3947 - accuracy: 0.4490 - mean_squared_error: 0.1273 - val_loss: 0.4280 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1453\n",
      "Epoch 73/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.3930 - accuracy: 0.4490 - mean_squared_error: 0.1271 - val_loss: 0.4225 - val_accuracy: 0.3636 - val_mean_squared_error: 0.1420\n",
      "Epoch 74/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4003 - accuracy: 0.4388 - mean_squared_error: 0.1303 - val_loss: 0.4214 - val_accuracy: 0.3636 - val_mean_squared_error: 0.1414\n",
      "Epoch 75/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.3954 - accuracy: 0.4490 - mean_squared_error: 0.1277 - val_loss: 0.4254 - val_accuracy: 0.3636 - val_mean_squared_error: 0.1456\n",
      "Epoch 76/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.3988 - accuracy: 0.4490 - mean_squared_error: 0.1295 - val_loss: 0.4248 - val_accuracy: 0.3636 - val_mean_squared_error: 0.1422\n",
      "Epoch 77/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.3926 - accuracy: 0.4592 - mean_squared_error: 0.1276 - val_loss: 0.4284 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1460\n",
      "Epoch 78/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.3935 - accuracy: 0.4490 - mean_squared_error: 0.1276 - val_loss: 0.4263 - val_accuracy: 0.3636 - val_mean_squared_error: 0.1451\n",
      "Epoch 79/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.3954 - accuracy: 0.4490 - mean_squared_error: 0.1287 - val_loss: 0.4268 - val_accuracy: 0.3636 - val_mean_squared_error: 0.1458\n",
      "Epoch 80/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4051 - accuracy: 0.4490 - mean_squared_error: 0.1323 - val_loss: 0.4268 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1440\n",
      "Epoch 81/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4003 - accuracy: 0.4490 - mean_squared_error: 0.1302 - val_loss: 0.4244 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1398\n",
      "Epoch 82/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.3981 - accuracy: 0.4490 - mean_squared_error: 0.1285 - val_loss: 0.4232 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1412\n",
      "Epoch 83/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.3967 - accuracy: 0.4490 - mean_squared_error: 0.1284 - val_loss: 0.4329 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1477\n",
      "Epoch 84/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3944 - accuracy: 0.4490 - mean_squared_error: 0.1285 - val_loss: 0.4250 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1427\n",
      "Epoch 85/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.3955 - accuracy: 0.4490 - mean_squared_error: 0.1283 - val_loss: 0.4253 - val_accuracy: 0.3636 - val_mean_squared_error: 0.1432\n",
      "Epoch 86/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.3919 - accuracy: 0.4490 - mean_squared_error: 0.1274 - val_loss: 0.4235 - val_accuracy: 0.3636 - val_mean_squared_error: 0.1443\n",
      "Epoch 87/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4011 - accuracy: 0.4388 - mean_squared_error: 0.1307 - val_loss: 0.4278 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1453\n",
      "Epoch 88/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.3937 - accuracy: 0.4490 - mean_squared_error: 0.1272 - val_loss: 0.4346 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1485\n",
      "Epoch 89/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.3941 - accuracy: 0.4490 - mean_squared_error: 0.1284 - val_loss: 0.4248 - val_accuracy: 0.3636 - val_mean_squared_error: 0.1441\n",
      "Epoch 90/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.3927 - accuracy: 0.4490 - mean_squared_error: 0.1272 - val_loss: 0.4367 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1489\n",
      "Epoch 91/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.3917 - accuracy: 0.4490 - mean_squared_error: 0.1274 - val_loss: 0.4213 - val_accuracy: 0.3636 - val_mean_squared_error: 0.1428\n",
      "Epoch 92/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.3910 - accuracy: 0.4490 - mean_squared_error: 0.1270 - val_loss: 0.4218 - val_accuracy: 0.3636 - val_mean_squared_error: 0.1429\n",
      "Epoch 93/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.3926 - accuracy: 0.4490 - mean_squared_error: 0.1270 - val_loss: 0.4322 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1471\n",
      "Epoch 94/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.3939 - accuracy: 0.4490 - mean_squared_error: 0.1275 - val_loss: 0.4313 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1479\n",
      "Epoch 95/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.3941 - accuracy: 0.4490 - mean_squared_error: 0.1295 - val_loss: 0.4395 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1471\n",
      "Epoch 96/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4006 - accuracy: 0.4490 - mean_squared_error: 0.1297 - val_loss: 0.4278 - val_accuracy: 0.3333 - val_mean_squared_error: 0.1457\n",
      "Epoch 97/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.3927 - accuracy: 0.4490 - mean_squared_error: 0.1269 - val_loss: 0.4243 - val_accuracy: 0.3636 - val_mean_squared_error: 0.1439\n",
      "Epoch 98/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.3924 - accuracy: 0.4490 - mean_squared_error: 0.1282 - val_loss: 0.4261 - val_accuracy: 0.3636 - val_mean_squared_error: 0.1453\n",
      "Epoch 99/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.3941 - accuracy: 0.4490 - mean_squared_error: 0.1286 - val_loss: 0.4200 - val_accuracy: 0.3939 - val_mean_squared_error: 0.1397\n",
      "Epoch 100/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.3949 - accuracy: 0.4490 - mean_squared_error: 0.1285 - val_loss: 0.4214 - val_accuracy: 0.3636 - val_mean_squared_error: 0.1415\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Curvas de Pérdida=Training Loss<br>Epoch=%{x}<br>Mean Square Error=%{y}<extra></extra>",
         "legendgroup": "Training Loss",
         "line": {
          "color": "#46039f",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "Training Loss",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99
         ],
         "xaxis": "x",
         "y": [
          0.16147014498710632,
          0.15707217156887054,
          0.15655598044395447,
          0.15922214090824127,
          0.15744808316230774,
          0.1544651836156845,
          0.15685608983039856,
          0.15552981197834015,
          0.15276655554771423,
          0.14733393490314484,
          0.14888431131839752,
          0.14425623416900635,
          0.14104175567626953,
          0.13998493552207947,
          0.13853637874126434,
          0.13605426251888275,
          0.1342279314994812,
          0.13574017584323883,
          0.13461029529571533,
          0.13228313624858856,
          0.13508769869804382,
          0.13252848386764526,
          0.13211582601070404,
          0.1329057514667511,
          0.1291336864233017,
          0.1299290806055069,
          0.13240477442741394,
          0.1294810026884079,
          0.12973663210868835,
          0.1295953243970871,
          0.1300084888935089,
          0.13046090304851532,
          0.1295001059770584,
          0.12852990627288818,
          0.12819041311740875,
          0.12802939116954803,
          0.13172286748886108,
          0.13200612366199493,
          0.13010679185390472,
          0.1315436065196991,
          0.1283801943063736,
          0.130227193236351,
          0.12853051722049713,
          0.12894509732723236,
          0.12840920686721802,
          0.13037069141864777,
          0.128806471824646,
          0.13068807125091553,
          0.1284092515707016,
          0.13180945813655853,
          0.12946385145187378,
          0.1288154274225235,
          0.1264410763978958,
          0.12950941920280457,
          0.12828552722930908,
          0.1281638890504837,
          0.13068121671676636,
          0.1287527233362198,
          0.13147954642772675,
          0.12760478258132935,
          0.12947359681129456,
          0.12884974479675293,
          0.12942929565906525,
          0.12885159254074097,
          0.1284155249595642,
          0.1289425939321518,
          0.12774716317653656,
          0.12809345126152039,
          0.1285715103149414,
          0.1285637766122818,
          0.12746305763721466,
          0.1272607296705246,
          0.12713183462619781,
          0.1303451955318451,
          0.1277429759502411,
          0.12951914966106415,
          0.12756292521953583,
          0.12761130928993225,
          0.1287441998720169,
          0.1323404461145401,
          0.1302417814731598,
          0.12853945791721344,
          0.1283615529537201,
          0.1285192370414734,
          0.12825655937194824,
          0.1273552030324936,
          0.13071338832378387,
          0.12718068063259125,
          0.1284354329109192,
          0.12720657885074615,
          0.12741412222385406,
          0.12699945271015167,
          0.12697428464889526,
          0.12746019661426544,
          0.12948612868785858,
          0.12972143292427063,
          0.12689198553562164,
          0.1281595677137375,
          0.12857608497142792,
          0.12852992117404938
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "Curvas de Pérdida=Validation Loss<br>Epoch=%{x}<br>Mean Square Error=%{y}<extra></extra>",
         "legendgroup": "Validation Loss",
         "line": {
          "color": "#fb9f3a",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "Validation Loss",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99
         ],
         "xaxis": "x",
         "y": [
          0.1563209444284439,
          0.15785080194473267,
          0.1598927080631256,
          0.15757666528224945,
          0.1568160504102707,
          0.16120080649852753,
          0.1564367115497589,
          0.15566030144691467,
          0.15425364673137665,
          0.15501035749912262,
          0.1526889055967331,
          0.148978129029274,
          0.149233877658844,
          0.1464662253856659,
          0.14464862644672394,
          0.14542381465435028,
          0.14468418061733246,
          0.1464473456144333,
          0.14351876080036163,
          0.14751991629600525,
          0.14441660046577454,
          0.15032100677490234,
          0.1436295211315155,
          0.14484141767024994,
          0.14666329324245453,
          0.14498770236968994,
          0.1494874507188797,
          0.14816057682037354,
          0.14475136995315552,
          0.14215083420276642,
          0.14508534967899323,
          0.14483585953712463,
          0.14324577152729034,
          0.14369988441467285,
          0.14711911976337433,
          0.14850781857967377,
          0.1433352679014206,
          0.14159104228019714,
          0.14541420340538025,
          0.14713051915168762,
          0.144456684589386,
          0.1438281238079071,
          0.1456834226846695,
          0.14936521649360657,
          0.14915569126605988,
          0.1446688026189804,
          0.1426786482334137,
          0.1472044289112091,
          0.1488889902830124,
          0.14616230130195618,
          0.1427016705274582,
          0.14574725925922394,
          0.14410871267318726,
          0.14834152162075043,
          0.14488546550273895,
          0.14689084887504578,
          0.14802157878875732,
          0.14319175481796265,
          0.1459367275238037,
          0.14508461952209473,
          0.14835509657859802,
          0.1507190465927124,
          0.14815880358219147,
          0.14805586636066437,
          0.1508466750383377,
          0.1421116292476654,
          0.14701148867607117,
          0.14506599307060242,
          0.14691124856472015,
          0.14746661484241486,
          0.147939994931221,
          0.1453397125005722,
          0.14202982187271118,
          0.14144925773143768,
          0.14560866355895996,
          0.14219702780246735,
          0.1459738314151764,
          0.145091250538826,
          0.14577673375606537,
          0.14398859441280365,
          0.13976632058620453,
          0.14116224646568298,
          0.14765095710754395,
          0.1426606923341751,
          0.14315225183963776,
          0.14429663121700287,
          0.1453479528427124,
          0.14846502244472504,
          0.14405721426010132,
          0.1488671749830246,
          0.14277924597263336,
          0.14291830360889435,
          0.1470862478017807,
          0.14794132113456726,
          0.14707064628601074,
          0.14571282267570496,
          0.14387297630310059,
          0.14528298377990723,
          0.1396738439798355,
          0.1415431946516037
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "Curvas de Pérdida"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Gráficas de Pérdida de Entrenamiento y Evaluación"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Epoch"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Mean Square Error"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.576560</td>\n",
       "      <td>0.193878</td>\n",
       "      <td>0.161470</td>\n",
       "      <td>0.489359</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.156321</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.491835</td>\n",
       "      <td>0.316327</td>\n",
       "      <td>0.157072</td>\n",
       "      <td>0.492089</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.157851</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.492022</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.156556</td>\n",
       "      <td>0.491707</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.159893</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.493001</td>\n",
       "      <td>0.295918</td>\n",
       "      <td>0.159222</td>\n",
       "      <td>0.495187</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.157577</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.491985</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.157448</td>\n",
       "      <td>0.490992</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.156816</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.400571</td>\n",
       "      <td>0.448980</td>\n",
       "      <td>0.129721</td>\n",
       "      <td>0.427839</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.145713</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.392696</td>\n",
       "      <td>0.448980</td>\n",
       "      <td>0.126892</td>\n",
       "      <td>0.424281</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.143873</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.392371</td>\n",
       "      <td>0.448980</td>\n",
       "      <td>0.128160</td>\n",
       "      <td>0.426094</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.145283</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.394066</td>\n",
       "      <td>0.448980</td>\n",
       "      <td>0.128576</td>\n",
       "      <td>0.420024</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.139674</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.394931</td>\n",
       "      <td>0.448980</td>\n",
       "      <td>0.128530</td>\n",
       "      <td>0.421395</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.141543</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy  Training Loss  val_loss  val_accuracy  \\\n",
       "0   0.576560  0.193878       0.161470  0.489359      0.272727   \n",
       "1   0.491835  0.316327       0.157072  0.492089      0.272727   \n",
       "2   0.492022  0.285714       0.156556  0.491707      0.272727   \n",
       "3   0.493001  0.295918       0.159222  0.495187      0.272727   \n",
       "4   0.491985  0.285714       0.157448  0.490992      0.272727   \n",
       "..       ...       ...            ...       ...           ...   \n",
       "95  0.400571  0.448980       0.129721  0.427839      0.333333   \n",
       "96  0.392696  0.448980       0.126892  0.424281      0.363636   \n",
       "97  0.392371  0.448980       0.128160  0.426094      0.363636   \n",
       "98  0.394066  0.448980       0.128576  0.420024      0.393939   \n",
       "99  0.394931  0.448980       0.128530  0.421395      0.363636   \n",
       "\n",
       "    Validation Loss  epoch  \n",
       "0          0.156321      0  \n",
       "1          0.157851      1  \n",
       "2          0.159893      2  \n",
       "3          0.157577      3  \n",
       "4          0.156816      4  \n",
       "..              ...    ...  \n",
       "95         0.145713     95  \n",
       "96         0.143873     96  \n",
       "97         0.145283     97  \n",
       "98         0.139674     98  \n",
       "99         0.141543     99  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learning_rate = 0.03\n",
    "epochs = 100\n",
    "batch_size = 1\n",
    "model = my_model(learning_rate)\n",
    "history, mse= train_model(model, train_features, train_labels, epochs, batch_size)\n",
    "loss_curves(history)\n",
    "#view_filters(model)\n",
    "display(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
