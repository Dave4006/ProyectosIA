{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar Modulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import plotly.express as px\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import display\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importación de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>normal</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>normal</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normal</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>normal</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>normal</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>collision_in_tool</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>collision_in_tool</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>collision_in_tool</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>collision_in_tool</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>collision_in_tool</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                labels 1  2  3  4  5 \n",
       "0               normal               \n",
       "1               normal               \n",
       "2               normal               \n",
       "3               normal               \n",
       "4               normal               \n",
       "..                 ... .. .. .. .. ..\n",
       "159  collision_in_tool               \n",
       "160  collision_in_tool               \n",
       "161  collision_in_tool               \n",
       "162  collision_in_tool               \n",
       "163  collision_in_tool               \n",
       "\n",
       "[164 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[[ -2.,  -1.,  81.,   0.,  -5.,   0.],\n",
       "        [ -2.,  -1.,  79.,   0.,  -4.,   0.],\n",
       "        [ -2.,  -1.,  79.,   0.,  -4.,   0.],\n",
       "        ...,\n",
       "        [ -2.,  -1.,  78.,   0.,  -5.,   0.],\n",
       "        [ -3.,  -1.,  80.,   1.,  -4.,   1.],\n",
       "        [ -2.,  -1.,  79.,   0.,  -4.,   0.]],\n",
       "\n",
       "       [[  6.,  -1.,  79.,  -2.,   4.,  -3.],\n",
       "        [ 42.,  -3.,  80.,   5.,  53.,   3.],\n",
       "        [ -5.,   4.,  74., -15., -10.,  -1.],\n",
       "        ...,\n",
       "        [ -1.,  -5.,  80.,   6.,  -6.,   0.],\n",
       "        [ -4.,   5.,  78., -14.,  -9.,  -4.],\n",
       "        [ -4.,   1.,  80.,  -3., -12.,   5.]],\n",
       "\n",
       "       [[ -2.,  -6.,  85.,  14.,  -5.,   2.],\n",
       "        [  0.,   2.,  74.,  -7.,   1.,   0.],\n",
       "        [ -4.,  -5.,  76.,   7., -11.,   4.],\n",
       "        ...,\n",
       "        [  0.,  -9.,  87.,  13.,  -5.,   2.],\n",
       "        [ -5.,   5.,  67., -17., -16.,   7.],\n",
       "        [ -6., -10.,  86.,  16., -14.,  -1.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-12.,  17.,   3., -19., -10.,  -4.],\n",
       "        [-12.,  12.,  11., -13., -16.,  -4.],\n",
       "        [ -8.,   3.,   6.,   2., -11.,  -4.],\n",
       "        ...,\n",
       "        [  0.,   1.,   3.,   1.,   1.,  -3.],\n",
       "        [  1.,   2.,   9.,   0.,   3.,  -4.],\n",
       "        [  1.,   2.,   9.,   0.,   3.,  -4.]],\n",
       "\n",
       "       [[-41.,  21.,  -5., -23., -59.,  -4.],\n",
       "        [-32.,  21.,  -6., -25., -45.,  -4.],\n",
       "        [-21.,  12.,  -6., -14., -31.,  -4.],\n",
       "        ...,\n",
       "        [ -4.,   4.,   3.,   0.,  -1.,  -3.],\n",
       "        [ -4.,   3.,   2.,   2.,  -3.,  -3.],\n",
       "        [ -2.,   3.,   5.,   0.,  -2.,  -3.]],\n",
       "\n",
       "       [[  9., -10., -11.,  17.,   7.,  -4.],\n",
       "        [  5.,   0.,   4.,   0.,   7.,  -4.],\n",
       "        [ -3.,   6.,  -2.,  -8.,  -8.,  -4.],\n",
       "        ...,\n",
       "        [ -1.,   1.,  -3.,  -3.,  -2.,  -3.],\n",
       "        [  0.,  -1.,  -5.,  -1.,   1.,  -3.],\n",
       "        [ -1.,   1.,   4.,   0.,  -1.,  -3.]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = \"{:.3f}\".format\n",
    "\n",
    "data = np.loadtxt(\"lp5.csv\", delimiter=\",\", dtype=str)\n",
    "data_copy = data #va de 0 a 2623 o sea 2624 datos\n",
    "cont = 16\n",
    "labels = []\n",
    "numbers = []\n",
    "features= np.zeros((164,15,6))\n",
    "\n",
    "for i in range(len(data_copy)):\n",
    "    if(cont == 16):\n",
    "        labels.append(data_copy[i])\n",
    "    if(cont<16):\n",
    "        numbers.append(data_copy[i])\n",
    "    cont -= 1\n",
    "    if(cont == 0):\n",
    "        cont = 16\n",
    "        \n",
    "cont = 0\n",
    "for i in range(164):\n",
    "    for j in range(15):\n",
    "        for z in range(6):\n",
    "            features[i][j][z] = numbers[cont][z]\n",
    "        cont += 1\n",
    "        \n",
    "labels_df = pd.DataFrame(labels, columns=['labels','1','2','3','4','5'])\n",
    "#labels_df = labels_df.loc[:,['labels']]\n",
    "display(labels_df)\n",
    "display(features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manejo de Datos y Normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dave4\\AppData\\Local\\Temp\\ipykernel_19480\\1747463221.py:8: FutureWarning:\n",
      "\n",
      "In a future version of pandas all arguments of StringMethods.split except for the argument 'pat' will be keyword-only.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0.77660263, 0.78156702, 0.79084826, 0.77055903, 0.7684006 ,\n",
       "         0.77422836],\n",
       "        [0.77466005, 0.78739478, 0.78717893, 0.75156486, 0.7638679 ,\n",
       "         0.77206993],\n",
       "        [0.77401252, 0.78804231, 0.79041658, 0.74465789, 0.76106195,\n",
       "         0.77012735],\n",
       "        ...,\n",
       "        [0.78005612, 0.7804878 , 0.78437298, 0.78135118, 0.78113533,\n",
       "         0.78027196],\n",
       "        [0.78027196, 0.78091949, 0.77962443, 0.78091949, 0.78027196,\n",
       "         0.78027196],\n",
       "        [0.78027196, 0.78070365, 0.78286208, 0.78156702, 0.78091949,\n",
       "         0.78005612]],\n",
       "\n",
       "       [[0.78027196, 0.77940859, 0.79905029, 0.78372545, 0.77962443,\n",
       "         0.78113533],\n",
       "        [0.78070365, 0.78113533, 0.79667602, 0.77919275, 0.78091949,\n",
       "         0.78070365],\n",
       "        [0.77984028, 0.77962443, 0.79710771, 0.78221455, 0.77832938,\n",
       "         0.78156702],\n",
       "        ...,\n",
       "        [0.78070365, 0.77876106, 0.79948198, 0.78350961, 0.77962443,\n",
       "         0.78113533],\n",
       "        [0.77962443, 0.78178286, 0.79516512, 0.77703432, 0.77725016,\n",
       "         0.78221455],\n",
       "        [0.77940859, 0.77854522, 0.79926613, 0.78415713, 0.77768185,\n",
       "         0.7804878 ]],\n",
       "\n",
       "       [[0.78502051, 0.77725016, 0.78264623, 0.78631556, 0.78696309,\n",
       "         0.7804878 ],\n",
       "        [0.78588388, 0.78005612, 0.78717893, 0.78243039, 0.78890568,\n",
       "         0.77984028],\n",
       "        [0.78653141, 0.77876106, 0.78027196, 0.78480466, 0.78933736,\n",
       "         0.78027196],\n",
       "        ...,\n",
       "        [0.78005612, 0.78135118, 0.77962443, 0.7804878 , 0.77962443,\n",
       "         0.77962443],\n",
       "        [0.78005612, 0.78091949, 0.7789769 , 0.78091949, 0.78027196,\n",
       "         0.77962443],\n",
       "        [0.7804878 , 0.78091949, 0.78005612, 0.78156702, 0.78070365,\n",
       "         0.77962443]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.78005612, 0.78070365, 0.79689186, 0.77919275, 0.77660263,\n",
       "         0.77984028],\n",
       "        [0.77962443, 0.77832938, 0.79883445, 0.78307792, 0.77617095,\n",
       "         0.77811353],\n",
       "        [0.78005612, 0.78264623, 0.79516512, 0.77487589, 0.77681848,\n",
       "         0.7789769 ],\n",
       "        ...,\n",
       "        [0.7804878 , 0.77832938, 0.79969782, 0.78307792, 0.777466  ,\n",
       "         0.77854522],\n",
       "        [0.77940859, 0.77984028, 0.79710771, 0.77962443, 0.77573926,\n",
       "         0.77984028],\n",
       "        [0.77940859, 0.78243039, 0.79710771, 0.77530758, 0.77617095,\n",
       "         0.77940859]],\n",
       "\n",
       "       [[0.77077488, 0.79494928, 0.77617095, 0.75588172, 0.77832938,\n",
       "         0.7804878 ],\n",
       "        [0.7653788 , 0.78135118, 0.78243039, 0.777466  , 0.7638679 ,\n",
       "         0.78027196],\n",
       "        [0.76365206, 0.78264623, 0.78350961, 0.78005612, 0.75674509,\n",
       "         0.78027196],\n",
       "        ...,\n",
       "        [0.77984028, 0.78113533, 0.78243039, 0.78113533, 0.78005612,\n",
       "         0.78005612],\n",
       "        [0.78027196, 0.78113533, 0.78350961, 0.78091949, 0.78070365,\n",
       "         0.78027196],\n",
       "        [0.7804878 , 0.78091949, 0.78480466, 0.78221455, 0.78156702,\n",
       "         0.78005612]],\n",
       "\n",
       "       [[0.77789769, 0.77789769, 0.7744442 , 0.78696309, 0.78653141,\n",
       "         0.77789769],\n",
       "        [0.77832938, 0.77811353, 0.77422836, 0.78631556, 0.78868983,\n",
       "         0.7789769 ],\n",
       "        [0.77832938, 0.77789769, 0.77466005, 0.78696309, 0.78804231,\n",
       "         0.77768185],\n",
       "        ...,\n",
       "        [0.67882581, 0.70472696, 0.09842435, 0.7759551 , 0.85732787,\n",
       "         0.74940643],\n",
       "        [0.69933089, 0.73796676, 0.34448521, 0.77099072, 0.81674941,\n",
       "         0.77530758],\n",
       "        [0.72199439, 0.73170732, 0.7155191 , 0.81804446, 0.69156054,\n",
       "         0.77012735]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1  2  3  4  5\n",
       "84   0  0  1  0  0\n",
       "2    1  0  0  0  0\n",
       "94   0  1  0  0  0\n",
       "45   0  0  1  0  0\n",
       "42   0  0  1  0  0\n",
       "..  .. .. .. .. ..\n",
       "71   0  0  1  0  0\n",
       "106  0  0  0  1  0\n",
       "14   1  0  0  0  0\n",
       "92   0  1  0  0  0\n",
       "102  0  0  0  0  1\n",
       "\n",
       "[131 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes_dict = {'normal':'1 0 0 0 0', #1\n",
    "        'collision_in_tool':'0 1 0 0 0', #2\n",
    "        'collision_in_part':'0 0 1 0 0', #3\n",
    "        'bottom_collision':'0 0 0 1 0', #4\n",
    "        'bottom_obstruction':'0 0 0 0 1'} #5\n",
    "\n",
    "labels_df = labels_df.replace({'labels':classes_dict})\n",
    "labels_df[['1', '2', '3', '4', '5']] = labels_df['labels'].str.split(' ', 4, expand= True)\n",
    "labels_df = labels_df.loc[:,['1', '2', '3', '4', '5']]\n",
    "labels_df[['1', '2', '3', '4', '5']]=labels_df[['1', '2', '3', '4', '5']].astype(str).astype(int)\n",
    "\n",
    "def norm(x):\n",
    "    x_min = x.min()\n",
    "    x_max = x.max()\n",
    "    range = x_max - x_min  #min max entre 0 y 1\n",
    "    return((x-x_min)/(range))\n",
    "\n",
    "norm_features = norm(features)\n",
    "#split para entrenamiento y validacion\n",
    "train_features, test_features, train_labels, test_labels  = train_test_split(norm_features, labels_df, test_size=0.2, random_state= 42)\n",
    "display(train_features)\n",
    "display(train_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_model(learning_rate):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(8, (3,3), activation='relu', input_shape = (15,6,1), padding='same'), # #de feature maps, dimensiones del kernel, kernel entre más pequeño mejor y se prefiere un número impar\n",
    "        tf.keras.layers.Conv2D(8, (3,3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.MaxPooling2D((2,2), strides= 2, padding= 'valid'), # dimensiones del pooling\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Conv2D(16, (3,3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.Conv2D(16, (3,3), activation='relu', padding='same'),# #de feature maps, dimensiones del kernel, kernel entre más pequeño mejor y se prefiere un número impar\n",
    "        tf.keras.layers.MaxPooling2D((2,2), strides= 2, padding='valid'), # dimensiones del pooling\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(24, activation='relu'),\n",
    "        tf.keras.layers.Dense(5, activation='softmax')])\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate), loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "# input shape es 15 filas, 6 columnas y 1 canal de color\n",
    "#model = model = my_model(0.01)\n",
    "#model.summary()\n",
    "\n",
    "# initialize tuner to run the model.\n",
    "# using the Hyperband search algorithm\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, features, labels, epochs, batch_size):\n",
    "    history = model.fit(\n",
    "        x = features,\n",
    "        y = labels,\n",
    "        epochs= epochs,\n",
    "        batch_size= batch_size,\n",
    "        validation_split= 0.25\n",
    "    )\n",
    "    hist= pd.DataFrame(history.history) #se guardan los valores de errores y metricas en un diccionario\n",
    "    hist['epoch'] = history.epoch #los epochs se deben añadir aparte\n",
    "    return hist"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizaciones\n",
    "### Pasos para visualizar los filtros:\n",
    "##### 1. Iterar por todas las capas del modelo usando model.layers\n",
    "##### 2. Si la capa actual es de convolucion se extraen los pesos y sesgos usando get_weights()\n",
    "##### 3. Se normalizan los pesos de los filtros entre 0 y 1\n",
    "##### 4. Se plotean los filtros para cada capa convolutional y todos los canales de color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_curves(history):\n",
    "    hist = history\n",
    "    labels = {\"loss\":\"Training Loss\", \"val_loss\":\"Validation Loss\"}\n",
    "    hist.rename(columns = labels, inplace = True)\n",
    "    \n",
    "    fig = px.line(hist, x='epoch', y=['Training Loss', 'Validation Loss'],\n",
    "                title='Gráficas de Pérdida de Entrenamiento y Evaluación',\n",
    "                labels={\"epoch\": \"Epoch\", \"value\":\"Binary Cross Entropy\", \"variable\":\"Curvas de Pérdida\"},\n",
    "                color_discrete_map={ # replaces default color mapping by value\n",
    "                \"Training Loss\": \"#46039f\", \"Validation Loss\": \"#fb9f3a\"})\n",
    "    fig.update_layout(template='plotly_white')\n",
    "    fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se corren las funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dave4\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\backend.py:5703: UserWarning:\n",
      "\n",
      "\"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 1s 3ms/step - loss: 0.5939 - accuracy: 0.2347 - val_loss: 0.5339 - val_accuracy: 0.2727\n",
      "Epoch 2/200\n",
      "32/98 [========>.....................] - ETA: 0s - loss: 0.5243 - accuracy: 0.3125"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dave4\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\backend.py:5703: UserWarning:\n",
      "\n",
      "\"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.2755 - val_loss: 0.4942 - val_accuracy: 0.2727\n",
      "Epoch 3/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.2755 - val_loss: 0.4946 - val_accuracy: 0.2727\n",
      "Epoch 4/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5002 - accuracy: 0.2551 - val_loss: 0.5015 - val_accuracy: 0.2727\n",
      "Epoch 5/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4937 - accuracy: 0.3163 - val_loss: 0.4962 - val_accuracy: 0.2727\n",
      "Epoch 6/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4990 - accuracy: 0.2449 - val_loss: 0.4964 - val_accuracy: 0.2727\n",
      "Epoch 7/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4989 - accuracy: 0.2755 - val_loss: 0.4976 - val_accuracy: 0.2727\n",
      "Epoch 8/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.2959 - val_loss: 0.4937 - val_accuracy: 0.2727\n",
      "Epoch 9/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4943 - accuracy: 0.3367 - val_loss: 0.5002 - val_accuracy: 0.2727\n",
      "Epoch 10/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.2959 - val_loss: 0.4916 - val_accuracy: 0.2727\n",
      "Epoch 11/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.3061 - val_loss: 0.4945 - val_accuracy: 0.2727\n",
      "Epoch 12/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4897 - accuracy: 0.2857 - val_loss: 0.4982 - val_accuracy: 0.2727\n",
      "Epoch 13/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4878 - accuracy: 0.3163 - val_loss: 0.4916 - val_accuracy: 0.2727\n",
      "Epoch 14/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4934 - accuracy: 0.3367 - val_loss: 0.4938 - val_accuracy: 0.2727\n",
      "Epoch 15/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.2857 - val_loss: 0.4909 - val_accuracy: 0.2727\n",
      "Epoch 16/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.3265 - val_loss: 0.4938 - val_accuracy: 0.2727\n",
      "Epoch 17/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4968 - accuracy: 0.3163 - val_loss: 0.5014 - val_accuracy: 0.2727\n",
      "Epoch 18/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.3367 - val_loss: 0.5031 - val_accuracy: 0.2727\n",
      "Epoch 19/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4931 - accuracy: 0.3061 - val_loss: 0.4921 - val_accuracy: 0.2727\n",
      "Epoch 20/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.3163 - val_loss: 0.4931 - val_accuracy: 0.2727\n",
      "Epoch 21/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4905 - accuracy: 0.3367 - val_loss: 0.4939 - val_accuracy: 0.2727\n",
      "Epoch 22/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.3061 - val_loss: 0.4914 - val_accuracy: 0.2727\n",
      "Epoch 23/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.3061 - val_loss: 0.4908 - val_accuracy: 0.2727\n",
      "Epoch 24/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.3163 - val_loss: 0.4916 - val_accuracy: 0.2727\n",
      "Epoch 25/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.3163 - val_loss: 0.4930 - val_accuracy: 0.2727\n",
      "Epoch 26/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4906 - accuracy: 0.3163 - val_loss: 0.4911 - val_accuracy: 0.2727\n",
      "Epoch 27/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4950 - accuracy: 0.2857 - val_loss: 0.4952 - val_accuracy: 0.2727\n",
      "Epoch 28/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.3163 - val_loss: 0.4942 - val_accuracy: 0.2727\n",
      "Epoch 29/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4939 - accuracy: 0.3265 - val_loss: 0.4942 - val_accuracy: 0.2727\n",
      "Epoch 30/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.3163 - val_loss: 0.4901 - val_accuracy: 0.2727\n",
      "Epoch 31/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.3061 - val_loss: 0.4912 - val_accuracy: 0.2727\n",
      "Epoch 32/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.3163 - val_loss: 0.4893 - val_accuracy: 0.2727\n",
      "Epoch 33/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.3163 - val_loss: 0.4882 - val_accuracy: 0.2727\n",
      "Epoch 34/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.2959 - val_loss: 0.4896 - val_accuracy: 0.2727\n",
      "Epoch 35/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.3061 - val_loss: 0.4885 - val_accuracy: 0.2727\n",
      "Epoch 36/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4872 - accuracy: 0.3367 - val_loss: 0.4860 - val_accuracy: 0.2727\n",
      "Epoch 37/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.3265 - val_loss: 0.4873 - val_accuracy: 0.2727\n",
      "Epoch 38/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.3367 - val_loss: 0.4822 - val_accuracy: 0.3030\n",
      "Epoch 39/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.4592 - val_loss: 0.4639 - val_accuracy: 0.3333\n",
      "Epoch 40/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.3980 - val_loss: 0.4568 - val_accuracy: 0.3333\n",
      "Epoch 41/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.4286 - val_loss: 0.4511 - val_accuracy: 0.3333\n",
      "Epoch 42/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.4286 - val_loss: 0.4532 - val_accuracy: 0.3333\n",
      "Epoch 43/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 0.4388 - val_loss: 0.4886 - val_accuracy: 0.3333\n",
      "Epoch 44/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.4388 - val_loss: 0.4521 - val_accuracy: 0.3333\n",
      "Epoch 45/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4045 - accuracy: 0.4490 - val_loss: 0.4787 - val_accuracy: 0.3333\n",
      "Epoch 46/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.4286 - val_loss: 0.4474 - val_accuracy: 0.3333\n",
      "Epoch 47/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.4286 - val_loss: 0.4652 - val_accuracy: 0.3333\n",
      "Epoch 48/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.4388 - val_loss: 0.4406 - val_accuracy: 0.3333\n",
      "Epoch 49/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.4592 - val_loss: 0.4463 - val_accuracy: 0.3333\n",
      "Epoch 50/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.4490 - val_loss: 0.4337 - val_accuracy: 0.3333\n",
      "Epoch 51/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4010 - accuracy: 0.3980 - val_loss: 0.4306 - val_accuracy: 0.3333\n",
      "Epoch 52/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4048 - accuracy: 0.4286 - val_loss: 0.4339 - val_accuracy: 0.3333\n",
      "Epoch 53/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3953 - accuracy: 0.4490 - val_loss: 0.4725 - val_accuracy: 0.3333\n",
      "Epoch 54/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3961 - accuracy: 0.4490 - val_loss: 0.4592 - val_accuracy: 0.3333\n",
      "Epoch 55/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4050 - accuracy: 0.4286 - val_loss: 0.4293 - val_accuracy: 0.3333\n",
      "Epoch 56/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3963 - accuracy: 0.4490 - val_loss: 0.4641 - val_accuracy: 0.3333\n",
      "Epoch 57/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3997 - accuracy: 0.4490 - val_loss: 0.4646 - val_accuracy: 0.3333\n",
      "Epoch 58/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3915 - accuracy: 0.4388 - val_loss: 0.4959 - val_accuracy: 0.3333\n",
      "Epoch 59/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3968 - accuracy: 0.4490 - val_loss: 0.4604 - val_accuracy: 0.3333\n",
      "Epoch 60/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3949 - accuracy: 0.4490 - val_loss: 0.4270 - val_accuracy: 0.3333\n",
      "Epoch 61/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4100 - accuracy: 0.4286 - val_loss: 0.4446 - val_accuracy: 0.3333\n",
      "Epoch 62/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3988 - accuracy: 0.4388 - val_loss: 0.4270 - val_accuracy: 0.3333\n",
      "Epoch 63/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3945 - accuracy: 0.4490 - val_loss: 0.4248 - val_accuracy: 0.3333\n",
      "Epoch 64/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4024 - accuracy: 0.4388 - val_loss: 0.4312 - val_accuracy: 0.3333\n",
      "Epoch 65/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3917 - accuracy: 0.4490 - val_loss: 0.4231 - val_accuracy: 0.3636\n",
      "Epoch 66/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3957 - accuracy: 0.4490 - val_loss: 0.4662 - val_accuracy: 0.3333\n",
      "Epoch 67/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4105 - accuracy: 0.4490 - val_loss: 0.4292 - val_accuracy: 0.3333\n",
      "Epoch 68/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4022 - accuracy: 0.4388 - val_loss: 0.4239 - val_accuracy: 0.3333\n",
      "Epoch 69/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3899 - accuracy: 0.4694 - val_loss: 0.4509 - val_accuracy: 0.3333\n",
      "Epoch 70/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3895 - accuracy: 0.4592 - val_loss: 0.4346 - val_accuracy: 0.3333\n",
      "Epoch 71/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3921 - accuracy: 0.4490 - val_loss: 0.4191 - val_accuracy: 0.3333\n",
      "Epoch 72/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4017 - accuracy: 0.4490 - val_loss: 0.4222 - val_accuracy: 0.3333\n",
      "Epoch 73/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3968 - accuracy: 0.4388 - val_loss: 0.4286 - val_accuracy: 0.3333\n",
      "Epoch 74/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3897 - accuracy: 0.4694 - val_loss: 0.4451 - val_accuracy: 0.3333\n",
      "Epoch 75/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3878 - accuracy: 0.4592 - val_loss: 0.4132 - val_accuracy: 0.3333\n",
      "Epoch 76/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3939 - accuracy: 0.4592 - val_loss: 0.4489 - val_accuracy: 0.3333\n",
      "Epoch 77/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3885 - accuracy: 0.4694 - val_loss: 0.4214 - val_accuracy: 0.3333\n",
      "Epoch 78/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3804 - accuracy: 0.4898 - val_loss: 0.4392 - val_accuracy: 0.3333\n",
      "Epoch 79/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.3763 - accuracy: 0.4694 - val_loss: 0.4528 - val_accuracy: 0.3333\n",
      "Epoch 80/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3896 - accuracy: 0.4592 - val_loss: 0.4197 - val_accuracy: 0.3333\n",
      "Epoch 81/200\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.3885 - accuracy: 0.4898 - val_loss: 0.4721 - val_accuracy: 0.3333\n",
      "Epoch 82/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4011 - accuracy: 0.4490 - val_loss: 0.4173 - val_accuracy: 0.3333\n",
      "Epoch 83/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3931 - accuracy: 0.4592 - val_loss: 0.4162 - val_accuracy: 0.3939\n",
      "Epoch 84/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3948 - accuracy: 0.4592 - val_loss: 0.4384 - val_accuracy: 0.3333\n",
      "Epoch 85/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3822 - accuracy: 0.4694 - val_loss: 0.4159 - val_accuracy: 0.3333\n",
      "Epoch 86/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3930 - accuracy: 0.4694 - val_loss: 0.4344 - val_accuracy: 0.3333\n",
      "Epoch 87/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3869 - accuracy: 0.4490 - val_loss: 0.4423 - val_accuracy: 0.3939\n",
      "Epoch 88/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3814 - accuracy: 0.5000 - val_loss: 0.4250 - val_accuracy: 0.3939\n",
      "Epoch 89/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3780 - accuracy: 0.4694 - val_loss: 0.4158 - val_accuracy: 0.3333\n",
      "Epoch 90/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.5000 - val_loss: 0.4109 - val_accuracy: 0.3333\n",
      "Epoch 91/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3784 - accuracy: 0.4898 - val_loss: 0.4071 - val_accuracy: 0.3333\n",
      "Epoch 92/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3703 - accuracy: 0.4796 - val_loss: 0.3995 - val_accuracy: 0.3939\n",
      "Epoch 93/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3728 - accuracy: 0.4898 - val_loss: 0.4126 - val_accuracy: 0.3636\n",
      "Epoch 94/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3871 - accuracy: 0.4490 - val_loss: 0.4462 - val_accuracy: 0.3636\n",
      "Epoch 95/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3790 - accuracy: 0.4898 - val_loss: 0.4185 - val_accuracy: 0.3939\n",
      "Epoch 96/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3693 - accuracy: 0.4898 - val_loss: 0.4313 - val_accuracy: 0.3333\n",
      "Epoch 97/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3698 - accuracy: 0.4898 - val_loss: 0.3975 - val_accuracy: 0.3939\n",
      "Epoch 98/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3856 - accuracy: 0.4796 - val_loss: 0.4050 - val_accuracy: 0.3636\n",
      "Epoch 99/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3848 - accuracy: 0.4592 - val_loss: 0.4094 - val_accuracy: 0.3939\n",
      "Epoch 100/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3633 - accuracy: 0.5204 - val_loss: 0.3908 - val_accuracy: 0.4545\n",
      "Epoch 101/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3686 - accuracy: 0.5204 - val_loss: 0.4210 - val_accuracy: 0.3939\n",
      "Epoch 102/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3680 - accuracy: 0.5000 - val_loss: 0.4124 - val_accuracy: 0.3939\n",
      "Epoch 103/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3634 - accuracy: 0.5000 - val_loss: 0.4023 - val_accuracy: 0.4848\n",
      "Epoch 104/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.3680 - accuracy: 0.5102 - val_loss: 0.3956 - val_accuracy: 0.4545\n",
      "Epoch 105/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3622 - accuracy: 0.5204 - val_loss: 0.3856 - val_accuracy: 0.4242\n",
      "Epoch 106/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3692 - accuracy: 0.5000 - val_loss: 0.3814 - val_accuracy: 0.4848\n",
      "Epoch 107/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3806 - accuracy: 0.4286 - val_loss: 0.3802 - val_accuracy: 0.4242\n",
      "Epoch 108/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.4694 - val_loss: 0.3801 - val_accuracy: 0.4242\n",
      "Epoch 109/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 0.5102 - val_loss: 0.4218 - val_accuracy: 0.3939\n",
      "Epoch 110/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3863 - accuracy: 0.4490 - val_loss: 0.4486 - val_accuracy: 0.4545\n",
      "Epoch 111/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.5102 - val_loss: 0.4911 - val_accuracy: 0.4545\n",
      "Epoch 112/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.3639 - accuracy: 0.5204 - val_loss: 0.3734 - val_accuracy: 0.4242\n",
      "Epoch 113/200\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 0.3607 - accuracy: 0.5000 - val_loss: 0.3820 - val_accuracy: 0.4242\n",
      "Epoch 114/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.3507 - accuracy: 0.4898 - val_loss: 0.3693 - val_accuracy: 0.4242\n",
      "Epoch 115/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.3674 - accuracy: 0.4796 - val_loss: 0.3838 - val_accuracy: 0.4848\n",
      "Epoch 116/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.3517 - accuracy: 0.5204 - val_loss: 0.3424 - val_accuracy: 0.4848\n",
      "Epoch 117/200\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 0.3546 - accuracy: 0.4898 - val_loss: 0.3524 - val_accuracy: 0.4545\n",
      "Epoch 118/200\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.3659 - accuracy: 0.4694 - val_loss: 0.3474 - val_accuracy: 0.4848\n",
      "Epoch 119/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3512 - accuracy: 0.4898 - val_loss: 0.3716 - val_accuracy: 0.5152\n",
      "Epoch 120/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3611 - accuracy: 0.4898 - val_loss: 0.4570 - val_accuracy: 0.4242\n",
      "Epoch 121/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.5000 - val_loss: 0.3629 - val_accuracy: 0.5152\n",
      "Epoch 122/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.5102 - val_loss: 0.3591 - val_accuracy: 0.4242\n",
      "Epoch 123/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3452 - accuracy: 0.5306 - val_loss: 0.3457 - val_accuracy: 0.5152\n",
      "Epoch 124/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3400 - accuracy: 0.5204 - val_loss: 0.3390 - val_accuracy: 0.5455\n",
      "Epoch 125/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3449 - accuracy: 0.5000 - val_loss: 0.3630 - val_accuracy: 0.5152\n",
      "Epoch 126/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3388 - accuracy: 0.5000 - val_loss: 0.3461 - val_accuracy: 0.4545\n",
      "Epoch 127/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3417 - accuracy: 0.5306 - val_loss: 0.3478 - val_accuracy: 0.4848\n",
      "Epoch 128/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3380 - accuracy: 0.5204 - val_loss: 0.3390 - val_accuracy: 0.4848\n",
      "Epoch 129/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3519 - accuracy: 0.5000 - val_loss: 0.3514 - val_accuracy: 0.4545\n",
      "Epoch 130/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3663 - accuracy: 0.5204 - val_loss: 0.3860 - val_accuracy: 0.3939\n",
      "Epoch 131/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3455 - accuracy: 0.5000 - val_loss: 0.3949 - val_accuracy: 0.4545\n",
      "Epoch 132/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3369 - accuracy: 0.5102 - val_loss: 0.3384 - val_accuracy: 0.5152\n",
      "Epoch 133/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3515 - accuracy: 0.4796 - val_loss: 0.3831 - val_accuracy: 0.4848\n",
      "Epoch 134/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3429 - accuracy: 0.4898 - val_loss: 0.3681 - val_accuracy: 0.3939\n",
      "Epoch 135/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3470 - accuracy: 0.5204 - val_loss: 0.3522 - val_accuracy: 0.4242\n",
      "Epoch 136/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.5102 - val_loss: 0.3387 - val_accuracy: 0.4848\n",
      "Epoch 137/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.5204 - val_loss: 0.3604 - val_accuracy: 0.4545\n",
      "Epoch 138/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3408 - accuracy: 0.4898 - val_loss: 0.3458 - val_accuracy: 0.5455\n",
      "Epoch 139/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3497 - accuracy: 0.4694 - val_loss: 0.3278 - val_accuracy: 0.5758\n",
      "Epoch 140/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3334 - accuracy: 0.4694 - val_loss: 0.3629 - val_accuracy: 0.3939\n",
      "Epoch 141/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3567 - accuracy: 0.4694 - val_loss: 0.4060 - val_accuracy: 0.5152\n",
      "Epoch 142/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3475 - accuracy: 0.4694 - val_loss: 0.3257 - val_accuracy: 0.5152\n",
      "Epoch 143/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3359 - accuracy: 0.4592 - val_loss: 0.3644 - val_accuracy: 0.4242\n",
      "Epoch 144/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3400 - accuracy: 0.5102 - val_loss: 0.3245 - val_accuracy: 0.5152\n",
      "Epoch 145/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3340 - accuracy: 0.5306 - val_loss: 0.3249 - val_accuracy: 0.5152\n",
      "Epoch 146/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3190 - accuracy: 0.5612 - val_loss: 0.3623 - val_accuracy: 0.4545\n",
      "Epoch 147/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3360 - accuracy: 0.5000 - val_loss: 0.3216 - val_accuracy: 0.6061\n",
      "Epoch 148/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3427 - accuracy: 0.4592 - val_loss: 0.3095 - val_accuracy: 0.5152\n",
      "Epoch 149/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3327 - accuracy: 0.5306 - val_loss: 0.3264 - val_accuracy: 0.5455\n",
      "Epoch 150/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3228 - accuracy: 0.5408 - val_loss: 0.3316 - val_accuracy: 0.4848\n",
      "Epoch 151/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.5204 - val_loss: 0.3250 - val_accuracy: 0.3636\n",
      "Epoch 152/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.5102 - val_loss: 0.3227 - val_accuracy: 0.4848\n",
      "Epoch 153/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3251 - accuracy: 0.5306 - val_loss: 0.3421 - val_accuracy: 0.5455\n",
      "Epoch 154/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3338 - accuracy: 0.5000 - val_loss: 0.3217 - val_accuracy: 0.5455\n",
      "Epoch 155/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.5408 - val_loss: 0.3459 - val_accuracy: 0.4545\n",
      "Epoch 156/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3406 - accuracy: 0.5000 - val_loss: 0.3267 - val_accuracy: 0.5455\n",
      "Epoch 157/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3208 - accuracy: 0.5204 - val_loss: 0.3213 - val_accuracy: 0.5455\n",
      "Epoch 158/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3338 - accuracy: 0.4694 - val_loss: 0.3185 - val_accuracy: 0.6667\n",
      "Epoch 159/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.5612 - val_loss: 0.3185 - val_accuracy: 0.4545\n",
      "Epoch 160/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.5000 - val_loss: 0.3084 - val_accuracy: 0.7273\n",
      "Epoch 161/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3419 - accuracy: 0.5408 - val_loss: 0.4342 - val_accuracy: 0.6364\n",
      "Epoch 162/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3406 - accuracy: 0.5102 - val_loss: 0.3365 - val_accuracy: 0.3333\n",
      "Epoch 163/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3261 - accuracy: 0.5306 - val_loss: 0.3213 - val_accuracy: 0.7273\n",
      "Epoch 164/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.5714 - val_loss: 0.3148 - val_accuracy: 0.6061\n",
      "Epoch 165/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3230 - accuracy: 0.4898 - val_loss: 0.3216 - val_accuracy: 0.6667\n",
      "Epoch 166/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3181 - accuracy: 0.5408 - val_loss: 0.3481 - val_accuracy: 0.4242\n",
      "Epoch 167/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3248 - accuracy: 0.4898 - val_loss: 0.3287 - val_accuracy: 0.5455\n",
      "Epoch 168/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3167 - accuracy: 0.4898 - val_loss: 0.3028 - val_accuracy: 0.6061\n",
      "Epoch 169/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.4796 - val_loss: 0.3082 - val_accuracy: 0.4848\n",
      "Epoch 170/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.5102 - val_loss: 0.3025 - val_accuracy: 0.5455\n",
      "Epoch 171/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3214 - accuracy: 0.5102 - val_loss: 0.3097 - val_accuracy: 0.5455\n",
      "Epoch 172/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3255 - accuracy: 0.5612 - val_loss: 0.4083 - val_accuracy: 0.4848\n",
      "Epoch 173/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3106 - accuracy: 0.5714 - val_loss: 0.3281 - val_accuracy: 0.4848\n",
      "Epoch 174/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3219 - accuracy: 0.5306 - val_loss: 0.3096 - val_accuracy: 0.6667\n",
      "Epoch 175/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3195 - accuracy: 0.5714 - val_loss: 0.3118 - val_accuracy: 0.5152\n",
      "Epoch 176/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3149 - accuracy: 0.5510 - val_loss: 0.3039 - val_accuracy: 0.6667\n",
      "Epoch 177/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3127 - accuracy: 0.5408 - val_loss: 0.3094 - val_accuracy: 0.5455\n",
      "Epoch 178/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3105 - accuracy: 0.5714 - val_loss: 0.3045 - val_accuracy: 0.5152\n",
      "Epoch 179/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.2997 - accuracy: 0.5714 - val_loss: 0.3037 - val_accuracy: 0.5455\n",
      "Epoch 180/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3190 - accuracy: 0.5102 - val_loss: 0.3060 - val_accuracy: 0.5455\n",
      "Epoch 181/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3062 - accuracy: 0.5612 - val_loss: 0.3073 - val_accuracy: 0.5455\n",
      "Epoch 182/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3145 - accuracy: 0.5408 - val_loss: 0.3273 - val_accuracy: 0.5758\n",
      "Epoch 183/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.5408 - val_loss: 0.3065 - val_accuracy: 0.6364\n",
      "Epoch 184/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3096 - accuracy: 0.6122 - val_loss: 0.2961 - val_accuracy: 0.6667\n",
      "Epoch 185/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3125 - accuracy: 0.5510 - val_loss: 0.3069 - val_accuracy: 0.4545\n",
      "Epoch 186/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.5306 - val_loss: 0.3307 - val_accuracy: 0.5152\n",
      "Epoch 187/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.5408 - val_loss: 0.3121 - val_accuracy: 0.5758\n",
      "Epoch 188/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.4490 - val_loss: 0.3067 - val_accuracy: 0.6061\n",
      "Epoch 189/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3231 - accuracy: 0.5612 - val_loss: 0.3007 - val_accuracy: 0.6970\n",
      "Epoch 190/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.2973 - accuracy: 0.5816 - val_loss: 0.2998 - val_accuracy: 0.6667\n",
      "Epoch 191/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3029 - accuracy: 0.6122 - val_loss: 0.2990 - val_accuracy: 0.6667\n",
      "Epoch 192/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3101 - accuracy: 0.6020 - val_loss: 0.4025 - val_accuracy: 0.6061\n",
      "Epoch 193/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3346 - accuracy: 0.5204 - val_loss: 0.3007 - val_accuracy: 0.6364\n",
      "Epoch 194/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3026 - accuracy: 0.5510 - val_loss: 0.3009 - val_accuracy: 0.6667\n",
      "Epoch 195/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3071 - accuracy: 0.6020 - val_loss: 0.2987 - val_accuracy: 0.6970\n",
      "Epoch 196/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3056 - accuracy: 0.5102 - val_loss: 0.2937 - val_accuracy: 0.6364\n",
      "Epoch 197/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3067 - accuracy: 0.5714 - val_loss: 0.2959 - val_accuracy: 0.5758\n",
      "Epoch 198/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.2952 - accuracy: 0.6429 - val_loss: 0.2972 - val_accuracy: 0.6667\n",
      "Epoch 199/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3127 - accuracy: 0.5408 - val_loss: 0.3015 - val_accuracy: 0.6667\n",
      "Epoch 200/200\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.3397 - accuracy: 0.5612 - val_loss: 0.3490 - val_accuracy: 0.5152\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.594</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.512</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.506</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.273</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.273</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.494</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.273</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.306</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.636</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.307</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.576</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.295</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.667</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.313</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.667</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.340</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.515</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     loss  accuracy  val_loss  val_accuracy  epoch\n",
       "0   0.594     0.235     0.534         0.273      0\n",
       "1   0.512     0.276     0.494         0.273      1\n",
       "2   0.506     0.276     0.495         0.273      2\n",
       "3   0.500     0.255     0.502         0.273      3\n",
       "4   0.494     0.316     0.496         0.273      4\n",
       "..    ...       ...       ...           ...    ...\n",
       "195 0.306     0.510     0.294         0.636    195\n",
       "196 0.307     0.571     0.296         0.576    196\n",
       "197 0.295     0.643     0.297         0.667    197\n",
       "198 0.313     0.541     0.302         0.667    198\n",
       "199 0.340     0.561     0.349         0.515    199\n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Curvas de Pérdida=Training Loss<br>Epoch=%{x}<br>Binary Cross Entropy=%{y}<extra></extra>",
         "legendgroup": "Training Loss",
         "line": {
          "color": "#46039f",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "Training Loss",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199
         ],
         "xaxis": "x",
         "y": [
          0.5939350724220276,
          0.5117135047912598,
          0.5059324502944946,
          0.5002155900001526,
          0.4937499165534973,
          0.4989975094795227,
          0.4989304840564728,
          0.4937637448310852,
          0.494286447763443,
          0.4922325313091278,
          0.4887838065624237,
          0.4896831810474396,
          0.4878314137458801,
          0.49340128898620605,
          0.4953775703907013,
          0.49017563462257385,
          0.4968445301055908,
          0.49585989117622375,
          0.4931190013885498,
          0.490906298160553,
          0.49046528339385986,
          0.49224787950515747,
          0.4891190528869629,
          0.4885970950126648,
          0.4909289479255676,
          0.49055978655815125,
          0.4950081706047058,
          0.49227777123451233,
          0.49388593435287476,
          0.4918491840362549,
          0.4913594424724579,
          0.4884118139743805,
          0.48886650800704956,
          0.48584750294685364,
          0.4865359961986542,
          0.48719102144241333,
          0.4859178364276886,
          0.4818708896636963,
          0.4513494670391083,
          0.44705259799957275,
          0.4254852533340454,
          0.42566657066345215,
          0.4157216250896454,
          0.41466978192329407,
          0.40449878573417664,
          0.41156524419784546,
          0.4097069203853607,
          0.4101218283176422,
          0.41316625475883484,
          0.40743905305862427,
          0.4009632170200348,
          0.4048087000846863,
          0.39527058601379395,
          0.3961189389228821,
          0.4050234854221344,
          0.39628130197525024,
          0.3996849060058594,
          0.39147278666496277,
          0.39681878685951233,
          0.39486151933670044,
          0.41004103422164917,
          0.39879897236824036,
          0.3945096433162689,
          0.4023507833480835,
          0.39168673753738403,
          0.39572420716285706,
          0.41053643822669983,
          0.4022076725959778,
          0.3898620903491974,
          0.3894944190979004,
          0.39209991693496704,
          0.4017292261123657,
          0.3968128561973572,
          0.38968947529792786,
          0.3877808451652527,
          0.39393460750579834,
          0.38845980167388916,
          0.38037800788879395,
          0.3762519359588623,
          0.3896147310733795,
          0.38845592737197876,
          0.4011472463607788,
          0.3931366801261902,
          0.3948195278644562,
          0.38216325640678406,
          0.39296388626098633,
          0.3868548274040222,
          0.3814146816730499,
          0.3780081570148468,
          0.3788081109523773,
          0.3783515691757202,
          0.3702826499938965,
          0.37281036376953125,
          0.38709235191345215,
          0.3789893686771393,
          0.36925140023231506,
          0.36980098485946655,
          0.3856024444103241,
          0.3847626745700836,
          0.36326178908348083,
          0.3686273992061615,
          0.36803215742111206,
          0.363400936126709,
          0.36799877882003784,
          0.3621719479560852,
          0.36919939517974854,
          0.3806282877922058,
          0.36486712098121643,
          0.35926491022109985,
          0.38634684681892395,
          0.3570227324962616,
          0.3639400899410248,
          0.3606716990470886,
          0.35069507360458374,
          0.36736035346984863,
          0.35169628262519836,
          0.354647159576416,
          0.3659423589706421,
          0.3511643409729004,
          0.3610956370830536,
          0.3641938269138336,
          0.3528819680213928,
          0.3452213704586029,
          0.34000611305236816,
          0.3448764383792877,
          0.3388447165489197,
          0.3416738212108612,
          0.3379855155944824,
          0.35190433263778687,
          0.3663496971130371,
          0.34551239013671875,
          0.3369278311729431,
          0.35150694847106934,
          0.3428851068019867,
          0.34697064757347107,
          0.3291323781013489,
          0.3322887718677521,
          0.34078219532966614,
          0.34969478845596313,
          0.3333542048931122,
          0.35671934485435486,
          0.3475363552570343,
          0.33589494228363037,
          0.3399520814418793,
          0.3339948356151581,
          0.3189918100833893,
          0.3359500765800476,
          0.34270793199539185,
          0.33265355229377747,
          0.32276806235313416,
          0.3235067129135132,
          0.3284040093421936,
          0.32508817315101624,
          0.33376607298851013,
          0.32807043194770813,
          0.340554416179657,
          0.32076215744018555,
          0.33376920223236084,
          0.3301849663257599,
          0.3310772776603699,
          0.34190085530281067,
          0.3405579626560211,
          0.326096773147583,
          0.3266051113605499,
          0.323005735874176,
          0.3181350827217102,
          0.3247535228729248,
          0.3167248070240021,
          0.3323597013950348,
          0.32886987924575806,
          0.3213733434677124,
          0.3254663944244385,
          0.3105909526348114,
          0.32191938161849976,
          0.3194844722747803,
          0.31488656997680664,
          0.31270933151245117,
          0.3104702830314636,
          0.2996966242790222,
          0.3189740777015686,
          0.30620458722114563,
          0.3145473599433899,
          0.33054786920547485,
          0.3096223771572113,
          0.3124939799308777,
          0.30767178535461426,
          0.30843082070350647,
          0.3291124701499939,
          0.3231017589569092,
          0.29728442430496216,
          0.3028756082057953,
          0.31011509895324707,
          0.3346473276615143,
          0.30261996388435364,
          0.3071322739124298,
          0.3056167960166931,
          0.306740939617157,
          0.29524263739585876,
          0.3127269446849823,
          0.3396570384502411
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "Curvas de Pérdida=Validation Loss<br>Epoch=%{x}<br>Binary Cross Entropy=%{y}<extra></extra>",
         "legendgroup": "Validation Loss",
         "line": {
          "color": "#fb9f3a",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "Validation Loss",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199
         ],
         "xaxis": "x",
         "y": [
          0.5339335799217224,
          0.49420061707496643,
          0.49455296993255615,
          0.5015018582344055,
          0.49619224667549133,
          0.4963906705379486,
          0.4976080656051636,
          0.49366968870162964,
          0.5002159476280212,
          0.49158230423927307,
          0.4945187568664551,
          0.4982072710990906,
          0.4915849566459656,
          0.493841290473938,
          0.49092888832092285,
          0.4938020408153534,
          0.501388430595398,
          0.5031415820121765,
          0.49211016297340393,
          0.49311360716819763,
          0.4939047396183014,
          0.49139004945755005,
          0.4908292889595032,
          0.49155375361442566,
          0.49300408363342285,
          0.4910801351070404,
          0.4951925575733185,
          0.49424219131469727,
          0.4941805601119995,
          0.4901082515716553,
          0.49121585488319397,
          0.4893490672111511,
          0.4881797432899475,
          0.489627480506897,
          0.4885144531726837,
          0.485973596572876,
          0.4873083829879761,
          0.4821891784667969,
          0.4639240503311157,
          0.45677125453948975,
          0.4510815739631653,
          0.45317342877388,
          0.4885529577732086,
          0.4521469175815582,
          0.4786596894264221,
          0.4474449157714844,
          0.46521875262260437,
          0.4405856132507324,
          0.4463314712047577,
          0.43365591764450073,
          0.43062448501586914,
          0.4338880479335785,
          0.4725048840045929,
          0.45918434858322144,
          0.42927059531211853,
          0.46406981348991394,
          0.46460604667663574,
          0.4958879351615906,
          0.46036043763160706,
          0.4269864857196808,
          0.4445655047893524,
          0.4270291328430176,
          0.4248284697532654,
          0.43119436502456665,
          0.4231164753437042,
          0.46621307730674744,
          0.4291982650756836,
          0.4238715171813965,
          0.4509483277797699,
          0.43456771969795227,
          0.4191157817840576,
          0.4221617579460144,
          0.4285649061203003,
          0.44505447149276733,
          0.41315457224845886,
          0.4488542377948761,
          0.4213617146015167,
          0.4392094314098358,
          0.45283663272857666,
          0.419679194688797,
          0.47210073471069336,
          0.4173162877559662,
          0.4161892831325531,
          0.43836510181427,
          0.41589319705963135,
          0.43441101908683777,
          0.4423392415046692,
          0.4250401556491852,
          0.41579821705818176,
          0.41086745262145996,
          0.40711942315101624,
          0.39951953291893005,
          0.4125590920448303,
          0.44616785645484924,
          0.41851913928985596,
          0.4313173294067383,
          0.3975273668766022,
          0.4049978256225586,
          0.4094223976135254,
          0.39075326919555664,
          0.42096221446990967,
          0.412436306476593,
          0.40234246850013733,
          0.3956087529659271,
          0.385585218667984,
          0.38139307498931885,
          0.38021570444107056,
          0.380062997341156,
          0.4217592477798462,
          0.44861745834350586,
          0.4911406636238098,
          0.37338393926620483,
          0.3819965124130249,
          0.36930885910987854,
          0.3838019371032715,
          0.3424152433872223,
          0.35235539078712463,
          0.34737128019332886,
          0.3716171383857727,
          0.4569690227508545,
          0.36294442415237427,
          0.35907649993896484,
          0.3457469642162323,
          0.3390432894229889,
          0.3630359470844269,
          0.34606900811195374,
          0.34778067469596863,
          0.3389677405357361,
          0.3514109253883362,
          0.3859807550907135,
          0.39486032724380493,
          0.3383883535861969,
          0.3831101059913635,
          0.36814960837364197,
          0.3522409498691559,
          0.3386760652065277,
          0.3604098856449127,
          0.3457847535610199,
          0.32780560851097107,
          0.36290672421455383,
          0.4059971272945404,
          0.3256528973579407,
          0.3643966317176819,
          0.32448557019233704,
          0.3249463438987732,
          0.3623347282409668,
          0.3216477930545807,
          0.3095262944698334,
          0.326413631439209,
          0.3316356837749481,
          0.32501694560050964,
          0.3227464556694031,
          0.3421439528465271,
          0.32173556089401245,
          0.34585338830947876,
          0.3266848027706146,
          0.32126614451408386,
          0.3184552490711212,
          0.318494975566864,
          0.3084450662136078,
          0.4342157542705536,
          0.336450457572937,
          0.3213149905204773,
          0.31476327776908875,
          0.3216100037097931,
          0.3480985462665558,
          0.32871177792549133,
          0.30282971262931824,
          0.30820485949516296,
          0.30253085494041443,
          0.3096897006034851,
          0.40830132365226746,
          0.32813581824302673,
          0.30959776043891907,
          0.31177282333374023,
          0.30388301610946655,
          0.30944541096687317,
          0.3044980466365814,
          0.30368393659591675,
          0.3060021996498108,
          0.3072536587715149,
          0.32730549573898315,
          0.30654144287109375,
          0.29607975482940674,
          0.30688533186912537,
          0.33067041635513306,
          0.312093585729599,
          0.3067198097705841,
          0.30065619945526123,
          0.2998022139072418,
          0.2989657521247864,
          0.4025498628616333,
          0.3007480204105377,
          0.3009241223335266,
          0.29869186878204346,
          0.2937024235725403,
          0.2959192097187042,
          0.2972005009651184,
          0.3015432357788086,
          0.34897199273109436
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "Curvas de Pérdida"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Gráficas de Pérdida de Entrenamiento y Evaluación"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Epoch"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Binary Cross Entropy"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.594</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.512</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.506</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.273</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.273</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.494</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.273</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.306</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.636</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.307</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.576</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.295</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.667</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.313</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.667</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.340</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.515</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Training Loss  accuracy  Validation Loss  val_accuracy  epoch\n",
       "0            0.594     0.235            0.534         0.273      0\n",
       "1            0.512     0.276            0.494         0.273      1\n",
       "2            0.506     0.276            0.495         0.273      2\n",
       "3            0.500     0.255            0.502         0.273      3\n",
       "4            0.494     0.316            0.496         0.273      4\n",
       "..             ...       ...              ...           ...    ...\n",
       "195          0.306     0.510            0.294         0.636    195\n",
       "196          0.307     0.571            0.296         0.576    196\n",
       "197          0.295     0.643            0.297         0.667    197\n",
       "198          0.313     0.541            0.302         0.667    198\n",
       "199          0.340     0.561            0.349         0.515    199\n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "epochs = 200\n",
    "batch_size = 1\n",
    "model = my_model(learning_rate)\n",
    "history= train_model(model, train_features, train_labels, epochs, batch_size)\n",
    "display(history)\n",
    "loss_curves(history)\n",
    "#view_filters(model)\n",
    "display(history)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normal</th>\n",
       "      <th>collision_in_tool</th>\n",
       "      <th>collision_in_part</th>\n",
       "      <th>bottom_collision</th>\n",
       "      <th>bottom_obstruction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.239</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.239</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.239</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.239</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.239</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.239</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.239</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.239</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.239</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.239</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    normal  collision_in_tool  collision_in_part  bottom_collision  \\\n",
       "0    0.239              0.129              0.358             0.133   \n",
       "1    0.239              0.129              0.358             0.133   \n",
       "2    0.239              0.129              0.358             0.133   \n",
       "3    0.239              0.129              0.358             0.133   \n",
       "4    0.239              0.129              0.358             0.133   \n",
       "..     ...                ...                ...               ...   \n",
       "28   0.239              0.129              0.358             0.133   \n",
       "29   0.239              0.129              0.358             0.133   \n",
       "30   0.239              0.129              0.358             0.133   \n",
       "31   0.239              0.129              0.358             0.133   \n",
       "32   0.239              0.129              0.358             0.133   \n",
       "\n",
       "    bottom_obstruction  \n",
       "0                0.141  \n",
       "1                0.141  \n",
       "2                0.141  \n",
       "3                0.141  \n",
       "4                0.141  \n",
       "..                 ...  \n",
       "28               0.141  \n",
       "29               0.141  \n",
       "30               0.141  \n",
       "31               0.141  \n",
       "32               0.141  \n",
       "\n",
       "[33 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1  2  3  4  5\n",
       "135  0  0  0  1  0\n",
       "115  0  0  0  0  1\n",
       "131  0  0  0  0  1\n",
       "55   1  0  0  0  0\n",
       "95   0  1  0  0  0\n",
       "..  .. .. .. .. ..\n",
       "134  0  0  0  1  0\n",
       "160  0  1  0  0  0\n",
       "139  0  0  0  1  0\n",
       "78   0  0  1  0  0\n",
       "60   1  0  0  0  0\n",
       "\n",
       "[33 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = model.predict(test_features)\n",
    "predictions_df = pd.DataFrame(predictions, columns=['normal', 'collision_in_tool', 'collision_in_part', 'bottom_collision', 'bottom_obstruction'])\n",
    "display(predictions_df)\n",
    "display(test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
