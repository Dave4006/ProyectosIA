{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar Modulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import plotly.express as px\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import display\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importación de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>normal</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>normal</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normal</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>normal</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>normal</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>collision_in_tool</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>collision_in_tool</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>collision_in_tool</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>collision_in_tool</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>collision_in_tool</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                labels 1  2  3  4  5 \n",
       "0               normal               \n",
       "1               normal               \n",
       "2               normal               \n",
       "3               normal               \n",
       "4               normal               \n",
       "..                 ... .. .. .. .. ..\n",
       "159  collision_in_tool               \n",
       "160  collision_in_tool               \n",
       "161  collision_in_tool               \n",
       "162  collision_in_tool               \n",
       "163  collision_in_tool               \n",
       "\n",
       "[164 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[[ -2.,  -1.,  81.,   0.,  -5.,   0.],\n",
       "        [ -2.,  -1.,  79.,   0.,  -4.,   0.],\n",
       "        [ -2.,  -1.,  79.,   0.,  -4.,   0.],\n",
       "        ...,\n",
       "        [ -2.,  -1.,  78.,   0.,  -5.,   0.],\n",
       "        [ -3.,  -1.,  80.,   1.,  -4.,   1.],\n",
       "        [ -2.,  -1.,  79.,   0.,  -4.,   0.]],\n",
       "\n",
       "       [[  6.,  -1.,  79.,  -2.,   4.,  -3.],\n",
       "        [ 42.,  -3.,  80.,   5.,  53.,   3.],\n",
       "        [ -5.,   4.,  74., -15., -10.,  -1.],\n",
       "        ...,\n",
       "        [ -1.,  -5.,  80.,   6.,  -6.,   0.],\n",
       "        [ -4.,   5.,  78., -14.,  -9.,  -4.],\n",
       "        [ -4.,   1.,  80.,  -3., -12.,   5.]],\n",
       "\n",
       "       [[ -2.,  -6.,  85.,  14.,  -5.,   2.],\n",
       "        [  0.,   2.,  74.,  -7.,   1.,   0.],\n",
       "        [ -4.,  -5.,  76.,   7., -11.,   4.],\n",
       "        ...,\n",
       "        [  0.,  -9.,  87.,  13.,  -5.,   2.],\n",
       "        [ -5.,   5.,  67., -17., -16.,   7.],\n",
       "        [ -6., -10.,  86.,  16., -14.,  -1.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-12.,  17.,   3., -19., -10.,  -4.],\n",
       "        [-12.,  12.,  11., -13., -16.,  -4.],\n",
       "        [ -8.,   3.,   6.,   2., -11.,  -4.],\n",
       "        ...,\n",
       "        [  0.,   1.,   3.,   1.,   1.,  -3.],\n",
       "        [  1.,   2.,   9.,   0.,   3.,  -4.],\n",
       "        [  1.,   2.,   9.,   0.,   3.,  -4.]],\n",
       "\n",
       "       [[-41.,  21.,  -5., -23., -59.,  -4.],\n",
       "        [-32.,  21.,  -6., -25., -45.,  -4.],\n",
       "        [-21.,  12.,  -6., -14., -31.,  -4.],\n",
       "        ...,\n",
       "        [ -4.,   4.,   3.,   0.,  -1.,  -3.],\n",
       "        [ -4.,   3.,   2.,   2.,  -3.,  -3.],\n",
       "        [ -2.,   3.,   5.,   0.,  -2.,  -3.]],\n",
       "\n",
       "       [[  9., -10., -11.,  17.,   7.,  -4.],\n",
       "        [  5.,   0.,   4.,   0.,   7.,  -4.],\n",
       "        [ -3.,   6.,  -2.,  -8.,  -8.,  -4.],\n",
       "        ...,\n",
       "        [ -1.,   1.,  -3.,  -3.,  -2.,  -3.],\n",
       "        [  0.,  -1.,  -5.,  -1.,   1.,  -3.],\n",
       "        [ -1.,   1.,   4.,   0.,  -1.,  -3.]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = \"{:.3f}\".format\n",
    "\n",
    "data = np.loadtxt(\"lp5.csv\", delimiter=\",\", dtype=str)\n",
    "data_copy = data #va de 0 a 2623 o sea 2624 datos\n",
    "cont = 16\n",
    "labels = []\n",
    "numbers = []\n",
    "features= np.zeros((164,15,6))\n",
    "\n",
    "for i in range(len(data_copy)):\n",
    "    if(cont == 16):\n",
    "        labels.append(data_copy[i])\n",
    "    if(cont<16):\n",
    "        numbers.append(data_copy[i])\n",
    "    cont -= 1\n",
    "    if(cont == 0):\n",
    "        cont = 16\n",
    "        \n",
    "cont = 0\n",
    "for i in range(164):\n",
    "    for j in range(15):\n",
    "        for z in range(6):\n",
    "            features[i][j][z] = numbers[cont][z]\n",
    "        cont += 1\n",
    "        \n",
    "labels_df = pd.DataFrame(labels, columns=['labels','1','2','3','4','5'])\n",
    "#labels_df = labels_df.loc[:,['labels']]\n",
    "display(labels_df)\n",
    "display(features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manejo de Datos y Normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dave4\\AppData\\Local\\Temp\\ipykernel_6092\\1747463221.py:8: FutureWarning: In a future version of pandas all arguments of StringMethods.split except for the argument 'pat' will be keyword-only.\n",
      "  labels_df[['1', '2', '3', '4', '5']] = labels_df['labels'].str.split(' ', 4, expand= True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0.77660263, 0.78156702, 0.79084826, 0.77055903, 0.7684006 ,\n",
       "         0.77422836],\n",
       "        [0.77466005, 0.78739478, 0.78717893, 0.75156486, 0.7638679 ,\n",
       "         0.77206993],\n",
       "        [0.77401252, 0.78804231, 0.79041658, 0.74465789, 0.76106195,\n",
       "         0.77012735],\n",
       "        ...,\n",
       "        [0.78005612, 0.7804878 , 0.78437298, 0.78135118, 0.78113533,\n",
       "         0.78027196],\n",
       "        [0.78027196, 0.78091949, 0.77962443, 0.78091949, 0.78027196,\n",
       "         0.78027196],\n",
       "        [0.78027196, 0.78070365, 0.78286208, 0.78156702, 0.78091949,\n",
       "         0.78005612]],\n",
       "\n",
       "       [[0.78027196, 0.77940859, 0.79905029, 0.78372545, 0.77962443,\n",
       "         0.78113533],\n",
       "        [0.78070365, 0.78113533, 0.79667602, 0.77919275, 0.78091949,\n",
       "         0.78070365],\n",
       "        [0.77984028, 0.77962443, 0.79710771, 0.78221455, 0.77832938,\n",
       "         0.78156702],\n",
       "        ...,\n",
       "        [0.78070365, 0.77876106, 0.79948198, 0.78350961, 0.77962443,\n",
       "         0.78113533],\n",
       "        [0.77962443, 0.78178286, 0.79516512, 0.77703432, 0.77725016,\n",
       "         0.78221455],\n",
       "        [0.77940859, 0.77854522, 0.79926613, 0.78415713, 0.77768185,\n",
       "         0.7804878 ]],\n",
       "\n",
       "       [[0.78502051, 0.77725016, 0.78264623, 0.78631556, 0.78696309,\n",
       "         0.7804878 ],\n",
       "        [0.78588388, 0.78005612, 0.78717893, 0.78243039, 0.78890568,\n",
       "         0.77984028],\n",
       "        [0.78653141, 0.77876106, 0.78027196, 0.78480466, 0.78933736,\n",
       "         0.78027196],\n",
       "        ...,\n",
       "        [0.78005612, 0.78135118, 0.77962443, 0.7804878 , 0.77962443,\n",
       "         0.77962443],\n",
       "        [0.78005612, 0.78091949, 0.7789769 , 0.78091949, 0.78027196,\n",
       "         0.77962443],\n",
       "        [0.7804878 , 0.78091949, 0.78005612, 0.78156702, 0.78070365,\n",
       "         0.77962443]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.78005612, 0.78070365, 0.79689186, 0.77919275, 0.77660263,\n",
       "         0.77984028],\n",
       "        [0.77962443, 0.77832938, 0.79883445, 0.78307792, 0.77617095,\n",
       "         0.77811353],\n",
       "        [0.78005612, 0.78264623, 0.79516512, 0.77487589, 0.77681848,\n",
       "         0.7789769 ],\n",
       "        ...,\n",
       "        [0.7804878 , 0.77832938, 0.79969782, 0.78307792, 0.777466  ,\n",
       "         0.77854522],\n",
       "        [0.77940859, 0.77984028, 0.79710771, 0.77962443, 0.77573926,\n",
       "         0.77984028],\n",
       "        [0.77940859, 0.78243039, 0.79710771, 0.77530758, 0.77617095,\n",
       "         0.77940859]],\n",
       "\n",
       "       [[0.77077488, 0.79494928, 0.77617095, 0.75588172, 0.77832938,\n",
       "         0.7804878 ],\n",
       "        [0.7653788 , 0.78135118, 0.78243039, 0.777466  , 0.7638679 ,\n",
       "         0.78027196],\n",
       "        [0.76365206, 0.78264623, 0.78350961, 0.78005612, 0.75674509,\n",
       "         0.78027196],\n",
       "        ...,\n",
       "        [0.77984028, 0.78113533, 0.78243039, 0.78113533, 0.78005612,\n",
       "         0.78005612],\n",
       "        [0.78027196, 0.78113533, 0.78350961, 0.78091949, 0.78070365,\n",
       "         0.78027196],\n",
       "        [0.7804878 , 0.78091949, 0.78480466, 0.78221455, 0.78156702,\n",
       "         0.78005612]],\n",
       "\n",
       "       [[0.77789769, 0.77789769, 0.7744442 , 0.78696309, 0.78653141,\n",
       "         0.77789769],\n",
       "        [0.77832938, 0.77811353, 0.77422836, 0.78631556, 0.78868983,\n",
       "         0.7789769 ],\n",
       "        [0.77832938, 0.77789769, 0.77466005, 0.78696309, 0.78804231,\n",
       "         0.77768185],\n",
       "        ...,\n",
       "        [0.67882581, 0.70472696, 0.09842435, 0.7759551 , 0.85732787,\n",
       "         0.74940643],\n",
       "        [0.69933089, 0.73796676, 0.34448521, 0.77099072, 0.81674941,\n",
       "         0.77530758],\n",
       "        [0.72199439, 0.73170732, 0.7155191 , 0.81804446, 0.69156054,\n",
       "         0.77012735]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1  2  3  4  5\n",
       "84   0  0  1  0  0\n",
       "2    1  0  0  0  0\n",
       "94   0  1  0  0  0\n",
       "45   0  0  1  0  0\n",
       "42   0  0  1  0  0\n",
       "..  .. .. .. .. ..\n",
       "71   0  0  1  0  0\n",
       "106  0  0  0  1  0\n",
       "14   1  0  0  0  0\n",
       "92   0  1  0  0  0\n",
       "102  0  0  0  0  1\n",
       "\n",
       "[131 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes_dict = {'normal':'1 0 0 0 0', #1\n",
    "        'collision_in_tool':'0 1 0 0 0', #2\n",
    "        'collision_in_part':'0 0 1 0 0', #3\n",
    "        'bottom_collision':'0 0 0 1 0', #4\n",
    "        'bottom_obstruction':'0 0 0 0 1'} #5\n",
    "\n",
    "labels_df = labels_df.replace({'labels':classes_dict})\n",
    "labels_df[['1', '2', '3', '4', '5']] = labels_df['labels'].str.split(' ', 4, expand= True)\n",
    "labels_df = labels_df.loc[:,['1', '2', '3', '4', '5']]\n",
    "labels_df[['1', '2', '3', '4', '5']]=labels_df[['1', '2', '3', '4', '5']].astype(str).astype(int)\n",
    "\n",
    "def norm(x):\n",
    "    x_min = x.min()\n",
    "    x_max = x.max()\n",
    "    range = x_max - x_min  #min max entre 0 y 1\n",
    "    return((x-x_min)/(range))\n",
    "\n",
    "norm_features = norm(features)\n",
    "#split para entrenamiento y validacion\n",
    "train_features, test_features, train_labels, test_labels  = train_test_split(norm_features, labels_df, test_size=0.2, random_state= 42)\n",
    "display(train_features)\n",
    "display(train_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_model(learning_rate):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(8, (3,3), activation='relu', input_shape = (15,6,1), padding='same'), # #de feature maps, dimensiones del kernel, kernel entre más pequeño mejor y se prefiere un número impar\n",
    "        tf.keras.layers.Conv2D(8, (3,3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.MaxPooling2D((2,2), strides= 2, padding= 'valid'), # dimensiones del pooling\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Conv2D(16, (3,3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.Conv2D(16, (3,3), activation='relu', padding='same'),# #de feature maps, dimensiones del kernel, kernel entre más pequeño mejor y se prefiere un número impar\n",
    "        tf.keras.layers.MaxPooling2D((2,2), strides= 2, padding='valid'), # dimensiones del pooling\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(24, activation='relu'),\n",
    "        tf.keras.layers.Dense(5, activation='softmax')])\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate), loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "# input shape es 15 filas, 6 columnas y 1 canal de color\n",
    "#model = model = my_model(0.01)\n",
    "#model.summary()\n",
    "\n",
    "# initialize tuner to run the model.\n",
    "# using the Hyperband search algorithm\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, features, labels, epochs, batch_size):\n",
    "    history = model.fit(\n",
    "        x = features,\n",
    "        y = labels,\n",
    "        epochs= epochs,\n",
    "        batch_size= batch_size,\n",
    "        validation_split= 0.25\n",
    "    )\n",
    "    hist= pd.DataFrame(history.history) #se guardan los valores de errores y metricas en un diccionario\n",
    "    hist['epoch'] = history.epoch #los epochs se deben añadir aparte\n",
    "    return hist"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizaciones\n",
    "### Pasos para visualizar los filtros:\n",
    "##### 1. Iterar por todas las capas del modelo usando model.layers\n",
    "##### 2. Si la capa actual es de convolucion se extraen los pesos y sesgos usando get_weights()\n",
    "##### 3. Se normalizan los pesos de los filtros entre 0 y 1\n",
    "##### 4. Se plotean los filtros para cada capa convolutional y todos los canales de color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_curves(history):\n",
    "    hist = history\n",
    "    labels = {\"loss\":\"Training Loss\", \"val_loss\":\"Validation Loss\"}\n",
    "    hist.rename(columns = labels, inplace = True)\n",
    "    \n",
    "    fig = px.line(hist, x='epoch', y=['Training Loss', 'Validation Loss'],\n",
    "                title='Gráficas de Pérdida de Entrenamiento y Evaluación',\n",
    "                labels={\"epoch\": \"Epoch\", \"value\":\"Binary Cross Entropy\", \"variable\":\"Curvas de Pérdida\"},\n",
    "                color_discrete_map={ # replaces default color mapping by value\n",
    "                \"Training Loss\": \"#46039f\", \"Validation Loss\": \"#fb9f3a\"})\n",
    "    fig.update_layout(template='plotly_white')\n",
    "    fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se corren las funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dave4\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\backend.py:5703: UserWarning:\n",
      "\n",
      "\"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 10ms/step - loss: 0.5920 - accuracy: 0.1429 - val_loss: 0.4854 - val_accuracy: 0.2121\n",
      "Epoch 2/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.2653 - val_loss: 0.4935 - val_accuracy: 0.2727\n",
      "Epoch 3/275\n",
      " 1/20 [>.............................] - ETA: 0s - loss: 0.5773 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dave4\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\backend.py:5703: UserWarning:\n",
      "\n",
      "\"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4990 - accuracy: 0.3061 - val_loss: 0.4973 - val_accuracy: 0.2727\n",
      "Epoch 4/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4880 - accuracy: 0.3265 - val_loss: 0.4896 - val_accuracy: 0.2727\n",
      "Epoch 5/275\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4967 - accuracy: 0.3163 - val_loss: 0.4979 - val_accuracy: 0.2727\n",
      "Epoch 6/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4923 - accuracy: 0.3061 - val_loss: 0.5074 - val_accuracy: 0.2727\n",
      "Epoch 7/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4944 - accuracy: 0.3163 - val_loss: 0.5013 - val_accuracy: 0.2727\n",
      "Epoch 8/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4895 - accuracy: 0.3163 - val_loss: 0.4995 - val_accuracy: 0.2727\n",
      "Epoch 9/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4938 - accuracy: 0.2959 - val_loss: 0.4972 - val_accuracy: 0.2727\n",
      "Epoch 10/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4897 - accuracy: 0.3265 - val_loss: 0.4939 - val_accuracy: 0.2727\n",
      "Epoch 11/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4929 - accuracy: 0.2755 - val_loss: 0.4972 - val_accuracy: 0.2727\n",
      "Epoch 12/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4960 - accuracy: 0.3265 - val_loss: 0.5142 - val_accuracy: 0.2727\n",
      "Epoch 13/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4932 - accuracy: 0.3163 - val_loss: 0.4984 - val_accuracy: 0.2727\n",
      "Epoch 14/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4900 - accuracy: 0.3265 - val_loss: 0.4973 - val_accuracy: 0.2727\n",
      "Epoch 15/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4894 - accuracy: 0.3163 - val_loss: 0.4913 - val_accuracy: 0.2727\n",
      "Epoch 16/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4936 - accuracy: 0.3163 - val_loss: 0.4945 - val_accuracy: 0.2727\n",
      "Epoch 17/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4927 - accuracy: 0.3163 - val_loss: 0.4940 - val_accuracy: 0.2727\n",
      "Epoch 18/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4892 - accuracy: 0.3265 - val_loss: 0.5017 - val_accuracy: 0.2727\n",
      "Epoch 19/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4887 - accuracy: 0.3061 - val_loss: 0.4931 - val_accuracy: 0.2727\n",
      "Epoch 20/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4887 - accuracy: 0.3163 - val_loss: 0.4945 - val_accuracy: 0.2727\n",
      "Epoch 21/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4880 - accuracy: 0.3163 - val_loss: 0.4926 - val_accuracy: 0.2727\n",
      "Epoch 22/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4818 - accuracy: 0.3163 - val_loss: 0.4921 - val_accuracy: 0.2727\n",
      "Epoch 23/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4782 - accuracy: 0.3367 - val_loss: 0.4811 - val_accuracy: 0.3030\n",
      "Epoch 24/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4818 - accuracy: 0.2959 - val_loss: 0.4798 - val_accuracy: 0.2727\n",
      "Epoch 25/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.3469 - val_loss: 0.4740 - val_accuracy: 0.3030\n",
      "Epoch 26/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4546 - accuracy: 0.3980 - val_loss: 0.4586 - val_accuracy: 0.3333\n",
      "Epoch 27/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.4388 - val_loss: 0.4466 - val_accuracy: 0.3333\n",
      "Epoch 28/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.4490 - val_loss: 0.4484 - val_accuracy: 0.3333\n",
      "Epoch 29/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4024 - accuracy: 0.4490 - val_loss: 0.4386 - val_accuracy: 0.3333\n",
      "Epoch 30/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3949 - accuracy: 0.4490 - val_loss: 0.4367 - val_accuracy: 0.3333\n",
      "Epoch 31/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3973 - accuracy: 0.4490 - val_loss: 0.4650 - val_accuracy: 0.3333\n",
      "Epoch 32/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4026 - accuracy: 0.4490 - val_loss: 0.4282 - val_accuracy: 0.3333\n",
      "Epoch 33/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3972 - accuracy: 0.4490 - val_loss: 0.4311 - val_accuracy: 0.3333\n",
      "Epoch 34/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3946 - accuracy: 0.4592 - val_loss: 0.4642 - val_accuracy: 0.3333\n",
      "Epoch 35/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3983 - accuracy: 0.4388 - val_loss: 0.4299 - val_accuracy: 0.3333\n",
      "Epoch 36/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3999 - accuracy: 0.4490 - val_loss: 0.4761 - val_accuracy: 0.3333\n",
      "Epoch 37/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4027 - accuracy: 0.4490 - val_loss: 0.4203 - val_accuracy: 0.3636\n",
      "Epoch 38/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4023 - accuracy: 0.4388 - val_loss: 0.4408 - val_accuracy: 0.3333\n",
      "Epoch 39/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3932 - accuracy: 0.4490 - val_loss: 0.4524 - val_accuracy: 0.3333\n",
      "Epoch 40/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3941 - accuracy: 0.4694 - val_loss: 0.4592 - val_accuracy: 0.3333\n",
      "Epoch 41/275\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3961 - accuracy: 0.4592 - val_loss: 0.4406 - val_accuracy: 0.3333\n",
      "Epoch 42/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3948 - accuracy: 0.4388 - val_loss: 0.4420 - val_accuracy: 0.3333\n",
      "Epoch 43/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4032 - accuracy: 0.4388 - val_loss: 0.4242 - val_accuracy: 0.3333\n",
      "Epoch 44/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.4388 - val_loss: 0.4286 - val_accuracy: 0.3636\n",
      "Epoch 45/275\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3919 - accuracy: 0.4490 - val_loss: 0.4460 - val_accuracy: 0.3333\n",
      "Epoch 46/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3991 - accuracy: 0.4388 - val_loss: 0.4261 - val_accuracy: 0.3333\n",
      "Epoch 47/275\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3993 - accuracy: 0.4388 - val_loss: 0.4180 - val_accuracy: 0.3636\n",
      "Epoch 48/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3964 - accuracy: 0.4490 - val_loss: 0.4247 - val_accuracy: 0.3333\n",
      "Epoch 49/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4028 - accuracy: 0.4286 - val_loss: 0.4251 - val_accuracy: 0.3333\n",
      "Epoch 50/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3984 - accuracy: 0.4490 - val_loss: 0.4234 - val_accuracy: 0.3333\n",
      "Epoch 51/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4058 - accuracy: 0.4388 - val_loss: 0.4195 - val_accuracy: 0.3939\n",
      "Epoch 52/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4028 - accuracy: 0.4388 - val_loss: 0.4323 - val_accuracy: 0.3333\n",
      "Epoch 53/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3953 - accuracy: 0.4490 - val_loss: 0.4212 - val_accuracy: 0.3333\n",
      "Epoch 54/275\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3939 - accuracy: 0.4490 - val_loss: 0.4280 - val_accuracy: 0.3333\n",
      "Epoch 55/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3979 - accuracy: 0.4490 - val_loss: 0.4320 - val_accuracy: 0.3333\n",
      "Epoch 56/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3993 - accuracy: 0.4490 - val_loss: 0.4245 - val_accuracy: 0.3333\n",
      "Epoch 57/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3980 - accuracy: 0.4490 - val_loss: 0.4298 - val_accuracy: 0.3333\n",
      "Epoch 58/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3924 - accuracy: 0.4490 - val_loss: 0.4380 - val_accuracy: 0.3333\n",
      "Epoch 59/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3918 - accuracy: 0.4592 - val_loss: 0.4498 - val_accuracy: 0.3333\n",
      "Epoch 60/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3955 - accuracy: 0.4490 - val_loss: 0.4258 - val_accuracy: 0.3333\n",
      "Epoch 61/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3938 - accuracy: 0.4490 - val_loss: 0.4280 - val_accuracy: 0.3333\n",
      "Epoch 62/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3924 - accuracy: 0.4490 - val_loss: 0.4281 - val_accuracy: 0.3333\n",
      "Epoch 63/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3973 - accuracy: 0.4490 - val_loss: 0.4265 - val_accuracy: 0.3333\n",
      "Epoch 64/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3912 - accuracy: 0.4490 - val_loss: 0.4198 - val_accuracy: 0.3636\n",
      "Epoch 65/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3963 - accuracy: 0.4490 - val_loss: 0.4609 - val_accuracy: 0.3333\n",
      "Epoch 66/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3901 - accuracy: 0.4490 - val_loss: 0.4668 - val_accuracy: 0.3333\n",
      "Epoch 67/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4164 - accuracy: 0.4490 - val_loss: 0.5293 - val_accuracy: 0.3333\n",
      "Epoch 68/275\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3942 - accuracy: 0.4592 - val_loss: 0.4264 - val_accuracy: 0.3333\n",
      "Epoch 69/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4027 - accuracy: 0.4490 - val_loss: 0.4259 - val_accuracy: 0.3333\n",
      "Epoch 70/275\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3968 - accuracy: 0.4490 - val_loss: 0.4168 - val_accuracy: 0.3939\n",
      "Epoch 71/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3971 - accuracy: 0.4490 - val_loss: 0.4268 - val_accuracy: 0.3333\n",
      "Epoch 72/275\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3900 - accuracy: 0.4490 - val_loss: 0.4208 - val_accuracy: 0.3333\n",
      "Epoch 73/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3871 - accuracy: 0.4592 - val_loss: 0.4240 - val_accuracy: 0.3636\n",
      "Epoch 74/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3976 - accuracy: 0.4286 - val_loss: 0.4145 - val_accuracy: 0.3636\n",
      "Epoch 75/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3918 - accuracy: 0.4490 - val_loss: 0.4228 - val_accuracy: 0.3333\n",
      "Epoch 76/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3847 - accuracy: 0.4694 - val_loss: 0.4579 - val_accuracy: 0.3939\n",
      "Epoch 77/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3870 - accuracy: 0.4592 - val_loss: 0.4105 - val_accuracy: 0.3636\n",
      "Epoch 78/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4009 - accuracy: 0.4388 - val_loss: 0.4157 - val_accuracy: 0.3636\n",
      "Epoch 79/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3867 - accuracy: 0.4694 - val_loss: 0.4070 - val_accuracy: 0.3636\n",
      "Epoch 80/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3790 - accuracy: 0.4898 - val_loss: 0.4241 - val_accuracy: 0.4242\n",
      "Epoch 81/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3921 - accuracy: 0.4388 - val_loss: 0.4164 - val_accuracy: 0.3636\n",
      "Epoch 82/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3759 - accuracy: 0.4796 - val_loss: 0.4189 - val_accuracy: 0.3939\n",
      "Epoch 83/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3765 - accuracy: 0.4796 - val_loss: 0.3950 - val_accuracy: 0.3636\n",
      "Epoch 84/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3755 - accuracy: 0.5102 - val_loss: 0.3890 - val_accuracy: 0.4242\n",
      "Epoch 85/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3772 - accuracy: 0.5000 - val_loss: 0.4051 - val_accuracy: 0.4848\n",
      "Epoch 86/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3730 - accuracy: 0.4592 - val_loss: 0.3774 - val_accuracy: 0.4242\n",
      "Epoch 87/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3698 - accuracy: 0.5000 - val_loss: 0.3761 - val_accuracy: 0.5152\n",
      "Epoch 88/275\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3645 - accuracy: 0.5204 - val_loss: 0.4056 - val_accuracy: 0.3939\n",
      "Epoch 89/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3665 - accuracy: 0.4898 - val_loss: 0.4043 - val_accuracy: 0.3939\n",
      "Epoch 90/275\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3967 - accuracy: 0.4592 - val_loss: 0.4036 - val_accuracy: 0.3939\n",
      "Epoch 91/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3844 - accuracy: 0.4694 - val_loss: 0.4091 - val_accuracy: 0.3636\n",
      "Epoch 92/275\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3725 - accuracy: 0.4796 - val_loss: 0.3743 - val_accuracy: 0.4242\n",
      "Epoch 93/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3710 - accuracy: 0.4898 - val_loss: 0.3745 - val_accuracy: 0.4545\n",
      "Epoch 94/275\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3591 - accuracy: 0.5102 - val_loss: 0.3536 - val_accuracy: 0.4545\n",
      "Epoch 95/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3575 - accuracy: 0.4898 - val_loss: 0.3980 - val_accuracy: 0.3939\n",
      "Epoch 96/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3807 - accuracy: 0.4796 - val_loss: 0.3822 - val_accuracy: 0.4242\n",
      "Epoch 97/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3790 - accuracy: 0.4694 - val_loss: 0.4045 - val_accuracy: 0.3939\n",
      "Epoch 98/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3856 - accuracy: 0.4694 - val_loss: 0.3605 - val_accuracy: 0.4848\n",
      "Epoch 99/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3532 - accuracy: 0.4694 - val_loss: 0.3661 - val_accuracy: 0.4545\n",
      "Epoch 100/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3567 - accuracy: 0.4694 - val_loss: 0.3408 - val_accuracy: 0.5152\n",
      "Epoch 101/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3620 - accuracy: 0.4796 - val_loss: 0.3312 - val_accuracy: 0.5455\n",
      "Epoch 102/275\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3517 - accuracy: 0.5204 - val_loss: 0.3844 - val_accuracy: 0.4242\n",
      "Epoch 103/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3530 - accuracy: 0.4388 - val_loss: 0.3936 - val_accuracy: 0.3939\n",
      "Epoch 104/275\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3557 - accuracy: 0.5000 - val_loss: 0.3359 - val_accuracy: 0.5455\n",
      "Epoch 105/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3552 - accuracy: 0.4898 - val_loss: 0.3710 - val_accuracy: 0.4545\n",
      "Epoch 106/275\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3516 - accuracy: 0.5000 - val_loss: 0.3449 - val_accuracy: 0.4545\n",
      "Epoch 107/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3398 - accuracy: 0.5102 - val_loss: 0.3859 - val_accuracy: 0.4242\n",
      "Epoch 108/275\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3492 - accuracy: 0.4388 - val_loss: 0.3489 - val_accuracy: 0.5152\n",
      "Epoch 109/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3485 - accuracy: 0.5102 - val_loss: 0.3333 - val_accuracy: 0.4848\n",
      "Epoch 110/275\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3435 - accuracy: 0.4898 - val_loss: 0.3415 - val_accuracy: 0.4848\n",
      "Epoch 111/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3442 - accuracy: 0.4898 - val_loss: 0.3380 - val_accuracy: 0.5455\n",
      "Epoch 112/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3481 - accuracy: 0.4592 - val_loss: 0.3507 - val_accuracy: 0.6667\n",
      "Epoch 113/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3445 - accuracy: 0.5510 - val_loss: 0.3562 - val_accuracy: 0.5152\n",
      "Epoch 114/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3537 - accuracy: 0.5612 - val_loss: 0.3516 - val_accuracy: 0.4848\n",
      "Epoch 115/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3610 - accuracy: 0.4796 - val_loss: 0.3853 - val_accuracy: 0.4242\n",
      "Epoch 116/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3519 - accuracy: 0.4898 - val_loss: 0.3274 - val_accuracy: 0.5455\n",
      "Epoch 117/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3515 - accuracy: 0.4898 - val_loss: 0.3556 - val_accuracy: 0.4242\n",
      "Epoch 118/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3406 - accuracy: 0.5510 - val_loss: 0.3387 - val_accuracy: 0.4848\n",
      "Epoch 119/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3941 - accuracy: 0.4082 - val_loss: 0.4090 - val_accuracy: 0.3939\n",
      "Epoch 120/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3733 - accuracy: 0.4796 - val_loss: 0.3616 - val_accuracy: 0.4848\n",
      "Epoch 121/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3678 - accuracy: 0.4694 - val_loss: 0.3640 - val_accuracy: 0.4545\n",
      "Epoch 122/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3515 - accuracy: 0.5510 - val_loss: 0.3372 - val_accuracy: 0.5455\n",
      "Epoch 123/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3319 - accuracy: 0.5510 - val_loss: 0.3177 - val_accuracy: 0.5455\n",
      "Epoch 124/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3308 - accuracy: 0.5204 - val_loss: 0.3164 - val_accuracy: 0.6061\n",
      "Epoch 125/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3363 - accuracy: 0.5612 - val_loss: 0.3371 - val_accuracy: 0.4848\n",
      "Epoch 126/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3545 - accuracy: 0.5000 - val_loss: 0.3176 - val_accuracy: 0.6061\n",
      "Epoch 127/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3537 - accuracy: 0.4694 - val_loss: 0.3669 - val_accuracy: 0.5152\n",
      "Epoch 128/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3415 - accuracy: 0.5408 - val_loss: 0.3381 - val_accuracy: 0.4848\n",
      "Epoch 129/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3401 - accuracy: 0.5612 - val_loss: 0.3020 - val_accuracy: 0.6364\n",
      "Epoch 130/275\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3334 - accuracy: 0.5510 - val_loss: 0.3303 - val_accuracy: 0.4848\n",
      "Epoch 131/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3309 - accuracy: 0.5510 - val_loss: 0.3130 - val_accuracy: 0.6970\n",
      "Epoch 132/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3296 - accuracy: 0.5816 - val_loss: 0.3048 - val_accuracy: 0.7273\n",
      "Epoch 133/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3316 - accuracy: 0.6020 - val_loss: 0.3051 - val_accuracy: 0.7273\n",
      "Epoch 134/275\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3265 - accuracy: 0.6224 - val_loss: 0.3085 - val_accuracy: 0.6364\n",
      "Epoch 135/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3252 - accuracy: 0.5816 - val_loss: 0.3150 - val_accuracy: 0.7273\n",
      "Epoch 136/275\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3160 - accuracy: 0.5714 - val_loss: 0.3280 - val_accuracy: 0.6061\n",
      "Epoch 137/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3303 - accuracy: 0.5204 - val_loss: 0.3073 - val_accuracy: 0.6364\n",
      "Epoch 138/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3479 - accuracy: 0.5204 - val_loss: 0.3396 - val_accuracy: 0.4848\n",
      "Epoch 139/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3674 - accuracy: 0.5306 - val_loss: 0.3428 - val_accuracy: 0.4848\n",
      "Epoch 140/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3463 - accuracy: 0.5306 - val_loss: 0.3234 - val_accuracy: 0.6364\n",
      "Epoch 141/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3254 - accuracy: 0.5714 - val_loss: 0.3177 - val_accuracy: 0.7576\n",
      "Epoch 142/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3292 - accuracy: 0.6122 - val_loss: 0.2890 - val_accuracy: 0.6970\n",
      "Epoch 143/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3172 - accuracy: 0.5714 - val_loss: 0.2893 - val_accuracy: 0.6970\n",
      "Epoch 144/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3147 - accuracy: 0.6122 - val_loss: 0.2961 - val_accuracy: 0.6667\n",
      "Epoch 145/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3229 - accuracy: 0.5918 - val_loss: 0.2927 - val_accuracy: 0.6970\n",
      "Epoch 146/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3207 - accuracy: 0.6531 - val_loss: 0.3035 - val_accuracy: 0.6667\n",
      "Epoch 147/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3217 - accuracy: 0.6122 - val_loss: 0.2859 - val_accuracy: 0.7273\n",
      "Epoch 148/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3239 - accuracy: 0.5918 - val_loss: 0.3646 - val_accuracy: 0.6061\n",
      "Epoch 149/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3196 - accuracy: 0.5714 - val_loss: 0.3060 - val_accuracy: 0.5455\n",
      "Epoch 150/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3179 - accuracy: 0.6122 - val_loss: 0.2832 - val_accuracy: 0.7273\n",
      "Epoch 151/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3038 - accuracy: 0.6020 - val_loss: 0.2838 - val_accuracy: 0.6667\n",
      "Epoch 152/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3073 - accuracy: 0.6429 - val_loss: 0.2849 - val_accuracy: 0.6667\n",
      "Epoch 153/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3074 - accuracy: 0.6531 - val_loss: 0.3051 - val_accuracy: 0.6061\n",
      "Epoch 154/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3169 - accuracy: 0.5816 - val_loss: 0.2852 - val_accuracy: 0.6970\n",
      "Epoch 155/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3131 - accuracy: 0.5714 - val_loss: 0.2921 - val_accuracy: 0.6667\n",
      "Epoch 156/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3076 - accuracy: 0.6122 - val_loss: 0.2740 - val_accuracy: 0.7879\n",
      "Epoch 157/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3124 - accuracy: 0.6020 - val_loss: 0.2922 - val_accuracy: 0.6364\n",
      "Epoch 158/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3345 - accuracy: 0.4898 - val_loss: 0.2950 - val_accuracy: 0.6667\n",
      "Epoch 159/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3187 - accuracy: 0.5306 - val_loss: 0.2870 - val_accuracy: 0.6364\n",
      "Epoch 160/275\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3075 - accuracy: 0.6224 - val_loss: 0.2611 - val_accuracy: 0.7879\n",
      "Epoch 161/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3011 - accuracy: 0.6020 - val_loss: 0.2998 - val_accuracy: 0.6061\n",
      "Epoch 162/275\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3321 - accuracy: 0.5102 - val_loss: 0.2995 - val_accuracy: 0.7273\n",
      "Epoch 163/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3079 - accuracy: 0.5612 - val_loss: 0.2617 - val_accuracy: 0.7576\n",
      "Epoch 164/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3006 - accuracy: 0.6327 - val_loss: 0.3033 - val_accuracy: 0.5455\n",
      "Epoch 165/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3083 - accuracy: 0.6531 - val_loss: 0.5110 - val_accuracy: 0.7273\n",
      "Epoch 166/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3030 - accuracy: 0.5816 - val_loss: 0.3039 - val_accuracy: 0.7273\n",
      "Epoch 167/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3149 - accuracy: 0.6224 - val_loss: 0.2791 - val_accuracy: 0.6970\n",
      "Epoch 168/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3441 - accuracy: 0.5102 - val_loss: 0.3539 - val_accuracy: 0.4848\n",
      "Epoch 169/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3307 - accuracy: 0.5000 - val_loss: 0.3406 - val_accuracy: 0.5455\n",
      "Epoch 170/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3293 - accuracy: 0.5714 - val_loss: 0.3057 - val_accuracy: 0.5152\n",
      "Epoch 171/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3297 - accuracy: 0.5306 - val_loss: 0.2969 - val_accuracy: 0.5455\n",
      "Epoch 172/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2948 - accuracy: 0.6531 - val_loss: 0.2788 - val_accuracy: 0.6364\n",
      "Epoch 173/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2991 - accuracy: 0.6020 - val_loss: 0.2556 - val_accuracy: 0.7273\n",
      "Epoch 174/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2991 - accuracy: 0.6224 - val_loss: 0.2639 - val_accuracy: 0.6667\n",
      "Epoch 175/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3179 - accuracy: 0.5714 - val_loss: 0.2971 - val_accuracy: 0.6061\n",
      "Epoch 176/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3071 - accuracy: 0.6327 - val_loss: 0.2600 - val_accuracy: 0.7273\n",
      "Epoch 177/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3457 - accuracy: 0.5000 - val_loss: 0.2849 - val_accuracy: 0.6061\n",
      "Epoch 178/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3361 - accuracy: 0.5306 - val_loss: 0.2807 - val_accuracy: 0.6364\n",
      "Epoch 179/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3410 - accuracy: 0.5306 - val_loss: 0.3354 - val_accuracy: 0.5152\n",
      "Epoch 180/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3530 - accuracy: 0.5204 - val_loss: 0.3304 - val_accuracy: 0.5455\n",
      "Epoch 181/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3305 - accuracy: 0.6020 - val_loss: 0.3206 - val_accuracy: 0.7576\n",
      "Epoch 182/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3151 - accuracy: 0.5918 - val_loss: 0.3296 - val_accuracy: 0.6970\n",
      "Epoch 183/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2900 - accuracy: 0.6429 - val_loss: 0.3044 - val_accuracy: 0.6970\n",
      "Epoch 184/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2830 - accuracy: 0.6633 - val_loss: 0.3069 - val_accuracy: 0.6970\n",
      "Epoch 185/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2966 - accuracy: 0.6531 - val_loss: 0.2945 - val_accuracy: 0.6667\n",
      "Epoch 186/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2910 - accuracy: 0.6429 - val_loss: 0.2592 - val_accuracy: 0.7576\n",
      "Epoch 187/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2897 - accuracy: 0.6327 - val_loss: 0.2585 - val_accuracy: 0.6970\n",
      "Epoch 188/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2981 - accuracy: 0.6224 - val_loss: 0.2670 - val_accuracy: 0.7273\n",
      "Epoch 189/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2924 - accuracy: 0.6429 - val_loss: 0.2644 - val_accuracy: 0.6970\n",
      "Epoch 190/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2924 - accuracy: 0.6531 - val_loss: 0.2516 - val_accuracy: 0.7273\n",
      "Epoch 191/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2965 - accuracy: 0.6122 - val_loss: 0.2963 - val_accuracy: 0.5758\n",
      "Epoch 192/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3216 - accuracy: 0.5714 - val_loss: 0.2763 - val_accuracy: 0.7273\n",
      "Epoch 193/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2978 - accuracy: 0.6327 - val_loss: 0.2693 - val_accuracy: 0.6061\n",
      "Epoch 194/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3204 - accuracy: 0.6122 - val_loss: 0.2792 - val_accuracy: 0.6061\n",
      "Epoch 195/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2979 - accuracy: 0.6429 - val_loss: 0.2542 - val_accuracy: 0.7879\n",
      "Epoch 196/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2799 - accuracy: 0.6837 - val_loss: 0.2535 - val_accuracy: 0.6970\n",
      "Epoch 197/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3016 - accuracy: 0.6020 - val_loss: 0.2942 - val_accuracy: 0.6061\n",
      "Epoch 198/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3546 - accuracy: 0.4898 - val_loss: 0.4287 - val_accuracy: 0.3939\n",
      "Epoch 199/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3896 - accuracy: 0.4184 - val_loss: 0.3520 - val_accuracy: 0.4545\n",
      "Epoch 200/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3683 - accuracy: 0.4796 - val_loss: 0.3694 - val_accuracy: 0.7273\n",
      "Epoch 201/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3066 - accuracy: 0.5714 - val_loss: 0.3314 - val_accuracy: 0.5455\n",
      "Epoch 202/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3309 - accuracy: 0.5204 - val_loss: 0.5081 - val_accuracy: 0.3333\n",
      "Epoch 203/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3617 - accuracy: 0.4796 - val_loss: 0.3384 - val_accuracy: 0.4848\n",
      "Epoch 204/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3434 - accuracy: 0.4898 - val_loss: 0.3441 - val_accuracy: 0.5152\n",
      "Epoch 205/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2948 - accuracy: 0.6633 - val_loss: 0.2888 - val_accuracy: 0.6364\n",
      "Epoch 206/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3071 - accuracy: 0.6224 - val_loss: 0.2658 - val_accuracy: 0.7576\n",
      "Epoch 207/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2909 - accuracy: 0.6633 - val_loss: 0.2679 - val_accuracy: 0.7273\n",
      "Epoch 208/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2972 - accuracy: 0.6429 - val_loss: 0.2738 - val_accuracy: 0.7576\n",
      "Epoch 209/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2857 - accuracy: 0.6837 - val_loss: 0.2712 - val_accuracy: 0.6970\n",
      "Epoch 210/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2868 - accuracy: 0.6531 - val_loss: 0.2741 - val_accuracy: 0.7576\n",
      "Epoch 211/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2835 - accuracy: 0.6531 - val_loss: 0.2621 - val_accuracy: 0.7576\n",
      "Epoch 212/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2877 - accuracy: 0.6429 - val_loss: 0.2826 - val_accuracy: 0.6364\n",
      "Epoch 213/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2915 - accuracy: 0.6327 - val_loss: 0.2952 - val_accuracy: 0.6364\n",
      "Epoch 214/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2924 - accuracy: 0.6429 - val_loss: 0.2656 - val_accuracy: 0.6667\n",
      "Epoch 215/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3158 - accuracy: 0.6429 - val_loss: 0.3495 - val_accuracy: 0.6061\n",
      "Epoch 216/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2887 - accuracy: 0.6735 - val_loss: 0.2779 - val_accuracy: 0.7273\n",
      "Epoch 217/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2881 - accuracy: 0.6531 - val_loss: 0.2848 - val_accuracy: 0.6061\n",
      "Epoch 218/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2965 - accuracy: 0.5816 - val_loss: 0.2626 - val_accuracy: 0.7576\n",
      "Epoch 219/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2750 - accuracy: 0.6837 - val_loss: 0.2434 - val_accuracy: 0.7576\n",
      "Epoch 220/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2811 - accuracy: 0.6633 - val_loss: 0.2508 - val_accuracy: 0.6970\n",
      "Epoch 221/275\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3206 - accuracy: 0.6224 - val_loss: 0.2727 - val_accuracy: 0.7273\n",
      "Epoch 222/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2905 - accuracy: 0.6224 - val_loss: 0.2549 - val_accuracy: 0.7273\n",
      "Epoch 223/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2789 - accuracy: 0.6735 - val_loss: 0.2429 - val_accuracy: 0.6970\n",
      "Epoch 224/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2977 - accuracy: 0.6429 - val_loss: 0.2629 - val_accuracy: 0.6364\n",
      "Epoch 225/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2759 - accuracy: 0.6633 - val_loss: 0.2330 - val_accuracy: 0.7879\n",
      "Epoch 226/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2984 - accuracy: 0.6531 - val_loss: 0.2515 - val_accuracy: 0.7576\n",
      "Epoch 227/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2644 - accuracy: 0.6735 - val_loss: 0.2346 - val_accuracy: 0.7576\n",
      "Epoch 228/275\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.2678 - accuracy: 0.6939 - val_loss: 0.2270 - val_accuracy: 0.7273\n",
      "Epoch 229/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2664 - accuracy: 0.6939 - val_loss: 0.2459 - val_accuracy: 0.6970\n",
      "Epoch 230/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2699 - accuracy: 0.6837 - val_loss: 0.2237 - val_accuracy: 0.7879\n",
      "Epoch 231/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2881 - accuracy: 0.6531 - val_loss: 0.2327 - val_accuracy: 0.7879\n",
      "Epoch 232/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2762 - accuracy: 0.6735 - val_loss: 0.2349 - val_accuracy: 0.7576\n",
      "Epoch 233/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2705 - accuracy: 0.6939 - val_loss: 0.2482 - val_accuracy: 0.6667\n",
      "Epoch 234/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2944 - accuracy: 0.6531 - val_loss: 0.2368 - val_accuracy: 0.7879\n",
      "Epoch 235/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3055 - accuracy: 0.6429 - val_loss: 0.3139 - val_accuracy: 0.7273\n",
      "Epoch 236/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2802 - accuracy: 0.6939 - val_loss: 0.3058 - val_accuracy: 0.6364\n",
      "Epoch 237/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3015 - accuracy: 0.6122 - val_loss: 0.2436 - val_accuracy: 0.7273\n",
      "Epoch 238/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3053 - accuracy: 0.6327 - val_loss: 0.3405 - val_accuracy: 0.6061\n",
      "Epoch 239/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4098 - accuracy: 0.4184 - val_loss: 0.4162 - val_accuracy: 0.3939\n",
      "Epoch 240/275\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3886 - accuracy: 0.4694 - val_loss: 0.3977 - val_accuracy: 0.3939\n",
      "Epoch 241/275\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3851 - accuracy: 0.4592 - val_loss: 0.3956 - val_accuracy: 0.3939\n",
      "Epoch 242/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3829 - accuracy: 0.4694 - val_loss: 0.3903 - val_accuracy: 0.3939\n",
      "Epoch 243/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3773 - accuracy: 0.4694 - val_loss: 0.3808 - val_accuracy: 0.4242\n",
      "Epoch 244/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3143 - accuracy: 0.5918 - val_loss: 0.3132 - val_accuracy: 0.6364\n",
      "Epoch 245/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2857 - accuracy: 0.6429 - val_loss: 0.2483 - val_accuracy: 0.7576\n",
      "Epoch 246/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2844 - accuracy: 0.6633 - val_loss: 0.2392 - val_accuracy: 0.7576\n",
      "Epoch 247/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2793 - accuracy: 0.6633 - val_loss: 0.2470 - val_accuracy: 0.7576\n",
      "Epoch 248/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2624 - accuracy: 0.6633 - val_loss: 0.2360 - val_accuracy: 0.7576\n",
      "Epoch 249/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2843 - accuracy: 0.6224 - val_loss: 0.2425 - val_accuracy: 0.6970\n",
      "Epoch 250/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2756 - accuracy: 0.6633 - val_loss: 0.2454 - val_accuracy: 0.7273\n",
      "Epoch 251/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2683 - accuracy: 0.6633 - val_loss: 0.2484 - val_accuracy: 0.6667\n",
      "Epoch 252/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2763 - accuracy: 0.6939 - val_loss: 0.2462 - val_accuracy: 0.6667\n",
      "Epoch 253/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2758 - accuracy: 0.6837 - val_loss: 0.2352 - val_accuracy: 0.7879\n",
      "Epoch 254/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2738 - accuracy: 0.6939 - val_loss: 0.2557 - val_accuracy: 0.6667\n",
      "Epoch 255/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2713 - accuracy: 0.6327 - val_loss: 0.2711 - val_accuracy: 0.6667\n",
      "Epoch 256/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2964 - accuracy: 0.6224 - val_loss: 0.2295 - val_accuracy: 0.7879\n",
      "Epoch 257/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3141 - accuracy: 0.6429 - val_loss: 0.2780 - val_accuracy: 0.6364\n",
      "Epoch 258/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3013 - accuracy: 0.6327 - val_loss: 0.2670 - val_accuracy: 0.7576\n",
      "Epoch 259/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2955 - accuracy: 0.6020 - val_loss: 0.2790 - val_accuracy: 0.6364\n",
      "Epoch 260/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2883 - accuracy: 0.6122 - val_loss: 0.2654 - val_accuracy: 0.6364\n",
      "Epoch 261/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3113 - accuracy: 0.6020 - val_loss: 0.2597 - val_accuracy: 0.6970\n",
      "Epoch 262/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3003 - accuracy: 0.6224 - val_loss: 0.2805 - val_accuracy: 0.6364\n",
      "Epoch 263/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2833 - accuracy: 0.6224 - val_loss: 0.2554 - val_accuracy: 0.7576\n",
      "Epoch 264/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3024 - accuracy: 0.5918 - val_loss: 0.2544 - val_accuracy: 0.6970\n",
      "Epoch 265/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2816 - accuracy: 0.6633 - val_loss: 0.2405 - val_accuracy: 0.7576\n",
      "Epoch 266/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2849 - accuracy: 0.6735 - val_loss: 0.2517 - val_accuracy: 0.6970\n",
      "Epoch 267/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2767 - accuracy: 0.6633 - val_loss: 0.2384 - val_accuracy: 0.7273\n",
      "Epoch 268/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2739 - accuracy: 0.6837 - val_loss: 0.2479 - val_accuracy: 0.7273\n",
      "Epoch 269/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2774 - accuracy: 0.6531 - val_loss: 0.2584 - val_accuracy: 0.6364\n",
      "Epoch 270/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2603 - accuracy: 0.7143 - val_loss: 0.2389 - val_accuracy: 0.7576\n",
      "Epoch 271/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2788 - accuracy: 0.6633 - val_loss: 0.2369 - val_accuracy: 0.7273\n",
      "Epoch 272/275\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.2596 - accuracy: 0.6837 - val_loss: 0.2287 - val_accuracy: 0.7879\n",
      "Epoch 273/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2748 - accuracy: 0.6837 - val_loss: 0.2285 - val_accuracy: 0.7879\n",
      "Epoch 274/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2991 - accuracy: 0.6735 - val_loss: 0.2429 - val_accuracy: 0.6970\n",
      "Epoch 275/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2587 - accuracy: 0.7143 - val_loss: 0.2558 - val_accuracy: 0.6970\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.592</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.504</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.499</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.273</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.488</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.273</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.497</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.273</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>0.279</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.727</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>0.260</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.788</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>0.275</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.788</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>0.299</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.697</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>0.259</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.697</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>275 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     loss  accuracy  val_loss  val_accuracy  epoch\n",
       "0   0.592     0.143     0.485         0.212      0\n",
       "1   0.504     0.265     0.494         0.273      1\n",
       "2   0.499     0.306     0.497         0.273      2\n",
       "3   0.488     0.327     0.490         0.273      3\n",
       "4   0.497     0.316     0.498         0.273      4\n",
       "..    ...       ...       ...           ...    ...\n",
       "270 0.279     0.663     0.237         0.727    270\n",
       "271 0.260     0.684     0.229         0.788    271\n",
       "272 0.275     0.684     0.229         0.788    272\n",
       "273 0.299     0.673     0.243         0.697    273\n",
       "274 0.259     0.714     0.256         0.697    274\n",
       "\n",
       "[275 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Curvas de Pérdida=Training Loss<br>Epoch=%{x}<br>Binary Cross Entropy=%{y}<extra></extra>",
         "legendgroup": "Training Loss",
         "line": {
          "color": "#46039f",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "Training Loss",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274
         ],
         "xaxis": "x",
         "y": [
          0.5920207500457764,
          0.50424724817276,
          0.4990336298942566,
          0.48798662424087524,
          0.4967397153377533,
          0.49229130148887634,
          0.49442505836486816,
          0.4894770681858063,
          0.49384382367134094,
          0.4896678626537323,
          0.49289730191230774,
          0.4959554970264435,
          0.4932324290275574,
          0.4900493919849396,
          0.489403635263443,
          0.49358657002449036,
          0.49271976947784424,
          0.48922857642173767,
          0.4887186288833618,
          0.4886849820613861,
          0.48795169591903687,
          0.48178544640541077,
          0.47823405265808105,
          0.4818403720855713,
          0.4557275176048279,
          0.45458751916885376,
          0.4280414879322052,
          0.4107159674167633,
          0.4024466574192047,
          0.39491692185401917,
          0.3973286747932434,
          0.40262019634246826,
          0.397208034992218,
          0.3946171700954437,
          0.398330956697464,
          0.3999291658401489,
          0.40265846252441406,
          0.4023247957229614,
          0.39315441250801086,
          0.39410313963890076,
          0.3961215615272522,
          0.3948477804660797,
          0.4032003581523895,
          0.40390443801879883,
          0.39191317558288574,
          0.3990882635116577,
          0.399272620677948,
          0.39644211530685425,
          0.4028092622756958,
          0.3984455466270447,
          0.4057583808898926,
          0.4027545750141144,
          0.395340234041214,
          0.3939198851585388,
          0.3979165852069855,
          0.3993115723133087,
          0.3979625701904297,
          0.39241522550582886,
          0.39179039001464844,
          0.395525723695755,
          0.3937939703464508,
          0.39243772625923157,
          0.39727428555488586,
          0.39117664098739624,
          0.39626654982566833,
          0.39010101556777954,
          0.4164278209209442,
          0.39417245984077454,
          0.4026573598384857,
          0.39680609107017517,
          0.39710792899131775,
          0.38995981216430664,
          0.38707390427589417,
          0.39760854840278625,
          0.39178466796875,
          0.3847061097621918,
          0.38702377676963806,
          0.40093228220939636,
          0.38673487305641174,
          0.37903162837028503,
          0.39213547110557556,
          0.37589845061302185,
          0.37651726603507996,
          0.37554895877838135,
          0.3772152364253998,
          0.37297067046165466,
          0.3698209226131439,
          0.364487886428833,
          0.3664514124393463,
          0.3966868221759796,
          0.3843940794467926,
          0.37253203988075256,
          0.37096530199050903,
          0.35908329486846924,
          0.3574773371219635,
          0.3806668221950531,
          0.37897366285324097,
          0.3856141269207001,
          0.3531859517097473,
          0.35670703649520874,
          0.36199745535850525,
          0.35167452692985535,
          0.35300740599632263,
          0.3556785583496094,
          0.3551567494869232,
          0.35158246755599976,
          0.33980754017829895,
          0.34915050864219666,
          0.3484537899494171,
          0.34352660179138184,
          0.3442288935184479,
          0.34811314940452576,
          0.3445185720920563,
          0.35372304916381836,
          0.36098480224609375,
          0.3518626093864441,
          0.35151150822639465,
          0.34056130051612854,
          0.3940753638744354,
          0.3732560873031616,
          0.3678106665611267,
          0.3514549732208252,
          0.33186039328575134,
          0.3308003842830658,
          0.3363237679004669,
          0.3544820547103882,
          0.35371458530426025,
          0.34149065613746643,
          0.3401389718055725,
          0.33344408869743347,
          0.33093148469924927,
          0.329595685005188,
          0.3315505087375641,
          0.3264697790145874,
          0.3251829743385315,
          0.3159777522087097,
          0.33026552200317383,
          0.34785881638526917,
          0.36739295721054077,
          0.34625616669654846,
          0.3253675401210785,
          0.3292458951473236,
          0.3172217309474945,
          0.31466102600097656,
          0.32289132475852966,
          0.32065099477767944,
          0.321681946516037,
          0.32391709089279175,
          0.3196282684803009,
          0.31787896156311035,
          0.3038111627101898,
          0.3072696924209595,
          0.3074204921722412,
          0.31689509749412537,
          0.31311559677124023,
          0.30763089656829834,
          0.31239017844200134,
          0.33452388644218445,
          0.3186633884906769,
          0.30749914050102234,
          0.3011132776737213,
          0.33214861154556274,
          0.30792665481567383,
          0.30057278275489807,
          0.3083204925060272,
          0.3030187785625458,
          0.31488025188446045,
          0.3440793752670288,
          0.3307027220726013,
          0.32925328612327576,
          0.32970157265663147,
          0.294802188873291,
          0.2990562617778778,
          0.2990894317626953,
          0.31792187690734863,
          0.3070601522922516,
          0.34573855996131897,
          0.3360997140407562,
          0.34101203083992004,
          0.35302022099494934,
          0.33054351806640625,
          0.3151181638240814,
          0.29003438353538513,
          0.2830323278903961,
          0.2965520918369293,
          0.2909811735153198,
          0.2897343635559082,
          0.29811909794807434,
          0.29242074489593506,
          0.29242226481437683,
          0.2965182363986969,
          0.32160425186157227,
          0.29779183864593506,
          0.32043102383613586,
          0.2979298532009125,
          0.2799129784107208,
          0.3016260266304016,
          0.3545655310153961,
          0.3896343410015106,
          0.36825698614120483,
          0.30657529830932617,
          0.3309062719345093,
          0.36168786883354187,
          0.34342360496520996,
          0.29478585720062256,
          0.3071281909942627,
          0.2908954322338104,
          0.29721465706825256,
          0.28568994998931885,
          0.2868049442768097,
          0.2835087776184082,
          0.2877365052700043,
          0.29153433442115784,
          0.2924078702926636,
          0.3158261179924011,
          0.28865471482276917,
          0.2881184220314026,
          0.2964814305305481,
          0.2750107944011688,
          0.28111669421195984,
          0.3205656409263611,
          0.29053589701652527,
          0.27890685200691223,
          0.2976547181606293,
          0.2759162485599518,
          0.29837822914123535,
          0.2643960416316986,
          0.26778724789619446,
          0.2663712501525879,
          0.2699213922023773,
          0.28814834356307983,
          0.27617746591567993,
          0.2705467641353607,
          0.29435059428215027,
          0.3054973781108856,
          0.2802385091781616,
          0.30150163173675537,
          0.3052847981452942,
          0.40982502698898315,
          0.38864436745643616,
          0.3850588798522949,
          0.38288411498069763,
          0.3772693872451782,
          0.31431689858436584,
          0.28568482398986816,
          0.28440624475479126,
          0.27933308482170105,
          0.2624122202396393,
          0.2842505872249603,
          0.2755539119243622,
          0.2683471441268921,
          0.27634990215301514,
          0.27581942081451416,
          0.27379241585731506,
          0.2712765634059906,
          0.2963941693305969,
          0.3141498267650604,
          0.30128148198127747,
          0.2955421805381775,
          0.2882898151874542,
          0.31131434440612793,
          0.3003212511539459,
          0.2832980751991272,
          0.30242636799812317,
          0.2815913259983063,
          0.28489646315574646,
          0.27671197056770325,
          0.2738698124885559,
          0.27737361192703247,
          0.2602938115596771,
          0.2787778079509735,
          0.259589284658432,
          0.27480778098106384,
          0.2990652322769165,
          0.25870198011398315
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "Curvas de Pérdida=Validation Loss<br>Epoch=%{x}<br>Binary Cross Entropy=%{y}<extra></extra>",
         "legendgroup": "Validation Loss",
         "line": {
          "color": "#fb9f3a",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "Validation Loss",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274
         ],
         "xaxis": "x",
         "y": [
          0.4853861331939697,
          0.49353766441345215,
          0.49726831912994385,
          0.48959898948669434,
          0.49793583154678345,
          0.5073623657226562,
          0.5013090372085571,
          0.4994606375694275,
          0.49715662002563477,
          0.49393412470817566,
          0.49719446897506714,
          0.5141828060150146,
          0.4984167814254761,
          0.4972878694534302,
          0.4912767708301544,
          0.49453285336494446,
          0.49401530623435974,
          0.501683235168457,
          0.49313879013061523,
          0.49448162317276,
          0.49256521463394165,
          0.4921337366104126,
          0.4810587167739868,
          0.4798111319541931,
          0.47399190068244934,
          0.4585936665534973,
          0.4465559720993042,
          0.4483732581138611,
          0.43859627842903137,
          0.43669599294662476,
          0.4649806618690491,
          0.4282454550266266,
          0.43110761046409607,
          0.46421465277671814,
          0.4299406111240387,
          0.47606515884399414,
          0.4202527701854706,
          0.44076189398765564,
          0.452394038438797,
          0.45918068289756775,
          0.44055166840553284,
          0.4420244097709656,
          0.424196720123291,
          0.4285903573036194,
          0.446016788482666,
          0.4261194169521332,
          0.41797032952308655,
          0.4247463643550873,
          0.42509952187538147,
          0.4234224557876587,
          0.419450581073761,
          0.43228647112846375,
          0.42118898034095764,
          0.4279704689979553,
          0.43195849657058716,
          0.42453810572624207,
          0.4297538995742798,
          0.4379974603652954,
          0.44979506731033325,
          0.42577147483825684,
          0.4279613494873047,
          0.42813190817832947,
          0.42649415135383606,
          0.4198145270347595,
          0.46093642711639404,
          0.4668388366699219,
          0.5292875170707703,
          0.4263724088668823,
          0.42586666345596313,
          0.4168229103088379,
          0.4268421530723572,
          0.4207667112350464,
          0.42396050691604614,
          0.41454899311065674,
          0.42282378673553467,
          0.4578568637371063,
          0.4105496406555176,
          0.41573163866996765,
          0.4070204794406891,
          0.4241302013397217,
          0.4163970351219177,
          0.41890209913253784,
          0.3950101435184479,
          0.3890281319618225,
          0.40508127212524414,
          0.37738659977912903,
          0.3760799765586853,
          0.4056450426578522,
          0.4043129086494446,
          0.403592586517334,
          0.4090844392776489,
          0.3742944300174713,
          0.3745447099208832,
          0.35357415676116943,
          0.39800187945365906,
          0.38224631547927856,
          0.40449219942092896,
          0.3604973256587982,
          0.3660790026187897,
          0.3407509922981262,
          0.33123084902763367,
          0.3844092786312103,
          0.3935753107070923,
          0.33588698506355286,
          0.3709520101547241,
          0.3449184000492096,
          0.3859253525733948,
          0.3488561511039734,
          0.3333258032798767,
          0.3414803147315979,
          0.33797767758369446,
          0.3506951332092285,
          0.3561543822288513,
          0.3515996038913727,
          0.3853484094142914,
          0.3274311423301697,
          0.3556063175201416,
          0.33867764472961426,
          0.40903300046920776,
          0.3616473376750946,
          0.36404022574424744,
          0.3372437357902527,
          0.3177463710308075,
          0.3163825571537018,
          0.33706074953079224,
          0.3176269233226776,
          0.3669341206550598,
          0.3380632698535919,
          0.30197054147720337,
          0.3302651047706604,
          0.312950998544693,
          0.30475616455078125,
          0.3050629496574402,
          0.3085274398326874,
          0.3149850368499756,
          0.32799965143203735,
          0.30725815892219543,
          0.33964377641677856,
          0.34278181195259094,
          0.323411762714386,
          0.3177492618560791,
          0.2890121340751648,
          0.28928297758102417,
          0.296109676361084,
          0.2926814556121826,
          0.30350446701049805,
          0.28588730096817017,
          0.36462950706481934,
          0.30596911907196045,
          0.2832179069519043,
          0.2837541103363037,
          0.284854918718338,
          0.30506131052970886,
          0.2851734161376953,
          0.2920500338077545,
          0.27402809262275696,
          0.29221275448799133,
          0.2950490117073059,
          0.2869966924190521,
          0.2610751688480377,
          0.2997572720050812,
          0.29949331283569336,
          0.2616792619228363,
          0.3033237159252167,
          0.5110301375389099,
          0.3039402961730957,
          0.2790844142436981,
          0.3538747727870941,
          0.34057411551475525,
          0.3056853115558624,
          0.2969001829624176,
          0.2787569761276245,
          0.25555258989334106,
          0.26388120651245117,
          0.29709163308143616,
          0.2600451707839966,
          0.284914493560791,
          0.2806599736213684,
          0.33544301986694336,
          0.3303908705711365,
          0.3206303119659424,
          0.3296426236629486,
          0.3044326901435852,
          0.30694475769996643,
          0.2944715917110443,
          0.2591986656188965,
          0.25850605964660645,
          0.2669912874698639,
          0.2644391655921936,
          0.251632958650589,
          0.2963438630104065,
          0.27631133794784546,
          0.26929226517677307,
          0.2792336940765381,
          0.25420355796813965,
          0.25350362062454224,
          0.2942275106906891,
          0.42868363857269287,
          0.35202640295028687,
          0.36941713094711304,
          0.3314104676246643,
          0.5081233978271484,
          0.33835193514823914,
          0.34411635994911194,
          0.2888314723968506,
          0.2658485174179077,
          0.2678704559803009,
          0.2737807631492615,
          0.27122634649276733,
          0.2740800976753235,
          0.2620645761489868,
          0.2825683355331421,
          0.2951841652393341,
          0.26563796401023865,
          0.349458783864975,
          0.2779410481452942,
          0.28480154275894165,
          0.2626376748085022,
          0.2434021681547165,
          0.25084468722343445,
          0.27271389961242676,
          0.2548697590827942,
          0.24291223287582397,
          0.2628735601902008,
          0.23301395773887634,
          0.2514967918395996,
          0.234635129570961,
          0.22695118188858032,
          0.24594633281230927,
          0.22372502088546753,
          0.23266129195690155,
          0.2348848581314087,
          0.24818241596221924,
          0.23678728938102722,
          0.3139234185218811,
          0.305841863155365,
          0.2436296045780182,
          0.34051331877708435,
          0.41624975204467773,
          0.39766925573349,
          0.39557763934135437,
          0.3902684152126312,
          0.38082388043403625,
          0.31317880749702454,
          0.24832411110401154,
          0.23920632898807526,
          0.24701626598834991,
          0.2360144704580307,
          0.24253666400909424,
          0.2453984022140503,
          0.24839045107364655,
          0.24615487456321716,
          0.23517882823944092,
          0.2556891441345215,
          0.271099716424942,
          0.229459747672081,
          0.2779988646507263,
          0.2669801115989685,
          0.27901434898376465,
          0.26538726687431335,
          0.25973421335220337,
          0.28045031428337097,
          0.2553649842739105,
          0.2543829679489136,
          0.24045853316783905,
          0.25170671939849854,
          0.23842890560626984,
          0.2478596419095993,
          0.2584397792816162,
          0.23890554904937744,
          0.23687446117401123,
          0.22870515286922455,
          0.2285258024930954,
          0.24289146065711975,
          0.2557636797428131
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "Curvas de Pérdida"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Gráficas de Pérdida de Entrenamiento y Evaluación"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Epoch"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Binary Cross Entropy"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.592</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.504</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.499</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.273</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.488</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.273</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.497</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.273</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>0.279</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.727</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>0.260</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.788</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>0.275</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.788</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>0.299</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.697</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>0.259</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.697</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>275 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Training Loss  accuracy  Validation Loss  val_accuracy  epoch\n",
       "0            0.592     0.143            0.485         0.212      0\n",
       "1            0.504     0.265            0.494         0.273      1\n",
       "2            0.499     0.306            0.497         0.273      2\n",
       "3            0.488     0.327            0.490         0.273      3\n",
       "4            0.497     0.316            0.498         0.273      4\n",
       "..             ...       ...              ...           ...    ...\n",
       "270          0.279     0.663            0.237         0.727    270\n",
       "271          0.260     0.684            0.229         0.788    271\n",
       "272          0.275     0.684            0.229         0.788    272\n",
       "273          0.299     0.673            0.243         0.697    273\n",
       "274          0.259     0.714            0.256         0.697    274\n",
       "\n",
       "[275 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learning_rate = 0.002\n",
    "epochs = 275\n",
    "batch_size = 5\n",
    "model = my_model(learning_rate)\n",
    "history= train_model(model, train_features, train_labels, epochs, batch_size)\n",
    "display(history)\n",
    "loss_curves(history)\n",
    "#view_filters(model)\n",
    "display(history)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normal</th>\n",
       "      <th>collision_in_tool</th>\n",
       "      <th>collision_in_part</th>\n",
       "      <th>bottom_collision</th>\n",
       "      <th>bottom_obstruction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.260</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.414</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.275</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.009</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.329</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.028</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.280</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.407</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    normal  collision_in_tool  collision_in_part  bottom_collision  \\\n",
       "0    0.260              0.142              0.519             0.067   \n",
       "1    0.000              0.000              0.000             0.000   \n",
       "2    0.000              0.000              0.000             0.986   \n",
       "3    0.414              0.167              0.408             0.008   \n",
       "4    0.275              0.186              0.407             0.113   \n",
       "..     ...                ...                ...               ...   \n",
       "28   0.009              0.017              0.131             0.796   \n",
       "29   0.329              0.153              0.475             0.034   \n",
       "30   0.028              0.041              0.227             0.661   \n",
       "31   0.280              0.148              0.496             0.063   \n",
       "32   0.407              0.165              0.415             0.010   \n",
       "\n",
       "    bottom_obstruction  \n",
       "0                0.013  \n",
       "1                1.000  \n",
       "2                0.014  \n",
       "3                0.003  \n",
       "4                0.020  \n",
       "..                 ...  \n",
       "28               0.048  \n",
       "29               0.009  \n",
       "30               0.044  \n",
       "31               0.013  \n",
       "32               0.003  \n",
       "\n",
       "[33 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1  2  3  4  5\n",
       "135  0  0  0  1  0\n",
       "115  0  0  0  0  1\n",
       "131  0  0  0  0  1\n",
       "55   1  0  0  0  0\n",
       "95   0  1  0  0  0\n",
       "..  .. .. .. .. ..\n",
       "134  0  0  0  1  0\n",
       "160  0  1  0  0  0\n",
       "139  0  0  0  1  0\n",
       "78   0  0  1  0  0\n",
       "60   1  0  0  0  0\n",
       "\n",
       "[33 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = model.predict(test_features)\n",
    "predictions_df = pd.DataFrame(predictions, columns=['normal', 'collision_in_tool', 'collision_in_part', 'bottom_collision', 'bottom_obstruction'])\n",
    "display(predictions_df)\n",
    "display(test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
