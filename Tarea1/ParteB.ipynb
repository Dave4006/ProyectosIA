{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar Modulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import plotly.express as px\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import display\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importación de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>normal</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>normal</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normal</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>normal</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>normal</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>collision_in_tool</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>collision_in_tool</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>collision_in_tool</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>collision_in_tool</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>collision_in_tool</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                labels 1  2  3  4  5 \n",
       "0               normal               \n",
       "1               normal               \n",
       "2               normal               \n",
       "3               normal               \n",
       "4               normal               \n",
       "..                 ... .. .. .. .. ..\n",
       "159  collision_in_tool               \n",
       "160  collision_in_tool               \n",
       "161  collision_in_tool               \n",
       "162  collision_in_tool               \n",
       "163  collision_in_tool               \n",
       "\n",
       "[164 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[[ -2.,  -1.,  81.,   0.,  -5.,   0.],\n",
       "        [ -2.,  -1.,  79.,   0.,  -4.,   0.],\n",
       "        [ -2.,  -1.,  79.,   0.,  -4.,   0.],\n",
       "        ...,\n",
       "        [ -2.,  -1.,  78.,   0.,  -5.,   0.],\n",
       "        [ -3.,  -1.,  80.,   1.,  -4.,   1.],\n",
       "        [ -2.,  -1.,  79.,   0.,  -4.,   0.]],\n",
       "\n",
       "       [[  6.,  -1.,  79.,  -2.,   4.,  -3.],\n",
       "        [ 42.,  -3.,  80.,   5.,  53.,   3.],\n",
       "        [ -5.,   4.,  74., -15., -10.,  -1.],\n",
       "        ...,\n",
       "        [ -1.,  -5.,  80.,   6.,  -6.,   0.],\n",
       "        [ -4.,   5.,  78., -14.,  -9.,  -4.],\n",
       "        [ -4.,   1.,  80.,  -3., -12.,   5.]],\n",
       "\n",
       "       [[ -2.,  -6.,  85.,  14.,  -5.,   2.],\n",
       "        [  0.,   2.,  74.,  -7.,   1.,   0.],\n",
       "        [ -4.,  -5.,  76.,   7., -11.,   4.],\n",
       "        ...,\n",
       "        [  0.,  -9.,  87.,  13.,  -5.,   2.],\n",
       "        [ -5.,   5.,  67., -17., -16.,   7.],\n",
       "        [ -6., -10.,  86.,  16., -14.,  -1.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-12.,  17.,   3., -19., -10.,  -4.],\n",
       "        [-12.,  12.,  11., -13., -16.,  -4.],\n",
       "        [ -8.,   3.,   6.,   2., -11.,  -4.],\n",
       "        ...,\n",
       "        [  0.,   1.,   3.,   1.,   1.,  -3.],\n",
       "        [  1.,   2.,   9.,   0.,   3.,  -4.],\n",
       "        [  1.,   2.,   9.,   0.,   3.,  -4.]],\n",
       "\n",
       "       [[-41.,  21.,  -5., -23., -59.,  -4.],\n",
       "        [-32.,  21.,  -6., -25., -45.,  -4.],\n",
       "        [-21.,  12.,  -6., -14., -31.,  -4.],\n",
       "        ...,\n",
       "        [ -4.,   4.,   3.,   0.,  -1.,  -3.],\n",
       "        [ -4.,   3.,   2.,   2.,  -3.,  -3.],\n",
       "        [ -2.,   3.,   5.,   0.,  -2.,  -3.]],\n",
       "\n",
       "       [[  9., -10., -11.,  17.,   7.,  -4.],\n",
       "        [  5.,   0.,   4.,   0.,   7.,  -4.],\n",
       "        [ -3.,   6.,  -2.,  -8.,  -8.,  -4.],\n",
       "        ...,\n",
       "        [ -1.,   1.,  -3.,  -3.,  -2.,  -3.],\n",
       "        [  0.,  -1.,  -5.,  -1.,   1.,  -3.],\n",
       "        [ -1.,   1.,   4.,   0.,  -1.,  -3.]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = \"{:.3f}\".format\n",
    "\n",
    "data = np.loadtxt(\"lp5.csv\", delimiter=\",\", dtype=str)\n",
    "data_copy = data #va de 0 a 2623 o sea 2624 datos\n",
    "cont = 16\n",
    "labels = []\n",
    "numbers = []\n",
    "features= np.zeros((164,15,6))\n",
    "\n",
    "for i in range(len(data_copy)):\n",
    "    if(cont == 16):\n",
    "        labels.append(data_copy[i])\n",
    "    if(cont<16):\n",
    "        numbers.append(data_copy[i])\n",
    "    cont -= 1\n",
    "    if(cont == 0):\n",
    "        cont = 16\n",
    "        \n",
    "cont = 0\n",
    "for i in range(164):\n",
    "    for j in range(15):\n",
    "        for z in range(6):\n",
    "            features[i][j][z] = numbers[cont][z]\n",
    "        cont += 1\n",
    "        \n",
    "labels_df = pd.DataFrame(labels, columns=['labels','1','2','3','4','5'])\n",
    "#labels_df = labels_df.loc[:,['labels']]\n",
    "display(labels_df)\n",
    "display(features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manejo de Datos y Normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dave4\\AppData\\Local\\Temp\\ipykernel_23384\\1747463221.py:8: FutureWarning: In a future version of pandas all arguments of StringMethods.split except for the argument 'pat' will be keyword-only.\n",
      "  labels_df[['1', '2', '3', '4', '5']] = labels_df['labels'].str.split(' ', 4, expand= True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0.77660263, 0.78156702, 0.79084826, 0.77055903, 0.7684006 ,\n",
       "         0.77422836],\n",
       "        [0.77466005, 0.78739478, 0.78717893, 0.75156486, 0.7638679 ,\n",
       "         0.77206993],\n",
       "        [0.77401252, 0.78804231, 0.79041658, 0.74465789, 0.76106195,\n",
       "         0.77012735],\n",
       "        ...,\n",
       "        [0.78005612, 0.7804878 , 0.78437298, 0.78135118, 0.78113533,\n",
       "         0.78027196],\n",
       "        [0.78027196, 0.78091949, 0.77962443, 0.78091949, 0.78027196,\n",
       "         0.78027196],\n",
       "        [0.78027196, 0.78070365, 0.78286208, 0.78156702, 0.78091949,\n",
       "         0.78005612]],\n",
       "\n",
       "       [[0.78027196, 0.77940859, 0.79905029, 0.78372545, 0.77962443,\n",
       "         0.78113533],\n",
       "        [0.78070365, 0.78113533, 0.79667602, 0.77919275, 0.78091949,\n",
       "         0.78070365],\n",
       "        [0.77984028, 0.77962443, 0.79710771, 0.78221455, 0.77832938,\n",
       "         0.78156702],\n",
       "        ...,\n",
       "        [0.78070365, 0.77876106, 0.79948198, 0.78350961, 0.77962443,\n",
       "         0.78113533],\n",
       "        [0.77962443, 0.78178286, 0.79516512, 0.77703432, 0.77725016,\n",
       "         0.78221455],\n",
       "        [0.77940859, 0.77854522, 0.79926613, 0.78415713, 0.77768185,\n",
       "         0.7804878 ]],\n",
       "\n",
       "       [[0.78502051, 0.77725016, 0.78264623, 0.78631556, 0.78696309,\n",
       "         0.7804878 ],\n",
       "        [0.78588388, 0.78005612, 0.78717893, 0.78243039, 0.78890568,\n",
       "         0.77984028],\n",
       "        [0.78653141, 0.77876106, 0.78027196, 0.78480466, 0.78933736,\n",
       "         0.78027196],\n",
       "        ...,\n",
       "        [0.78005612, 0.78135118, 0.77962443, 0.7804878 , 0.77962443,\n",
       "         0.77962443],\n",
       "        [0.78005612, 0.78091949, 0.7789769 , 0.78091949, 0.78027196,\n",
       "         0.77962443],\n",
       "        [0.7804878 , 0.78091949, 0.78005612, 0.78156702, 0.78070365,\n",
       "         0.77962443]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.78005612, 0.78070365, 0.79689186, 0.77919275, 0.77660263,\n",
       "         0.77984028],\n",
       "        [0.77962443, 0.77832938, 0.79883445, 0.78307792, 0.77617095,\n",
       "         0.77811353],\n",
       "        [0.78005612, 0.78264623, 0.79516512, 0.77487589, 0.77681848,\n",
       "         0.7789769 ],\n",
       "        ...,\n",
       "        [0.7804878 , 0.77832938, 0.79969782, 0.78307792, 0.777466  ,\n",
       "         0.77854522],\n",
       "        [0.77940859, 0.77984028, 0.79710771, 0.77962443, 0.77573926,\n",
       "         0.77984028],\n",
       "        [0.77940859, 0.78243039, 0.79710771, 0.77530758, 0.77617095,\n",
       "         0.77940859]],\n",
       "\n",
       "       [[0.77077488, 0.79494928, 0.77617095, 0.75588172, 0.77832938,\n",
       "         0.7804878 ],\n",
       "        [0.7653788 , 0.78135118, 0.78243039, 0.777466  , 0.7638679 ,\n",
       "         0.78027196],\n",
       "        [0.76365206, 0.78264623, 0.78350961, 0.78005612, 0.75674509,\n",
       "         0.78027196],\n",
       "        ...,\n",
       "        [0.77984028, 0.78113533, 0.78243039, 0.78113533, 0.78005612,\n",
       "         0.78005612],\n",
       "        [0.78027196, 0.78113533, 0.78350961, 0.78091949, 0.78070365,\n",
       "         0.78027196],\n",
       "        [0.7804878 , 0.78091949, 0.78480466, 0.78221455, 0.78156702,\n",
       "         0.78005612]],\n",
       "\n",
       "       [[0.77789769, 0.77789769, 0.7744442 , 0.78696309, 0.78653141,\n",
       "         0.77789769],\n",
       "        [0.77832938, 0.77811353, 0.77422836, 0.78631556, 0.78868983,\n",
       "         0.7789769 ],\n",
       "        [0.77832938, 0.77789769, 0.77466005, 0.78696309, 0.78804231,\n",
       "         0.77768185],\n",
       "        ...,\n",
       "        [0.67882581, 0.70472696, 0.09842435, 0.7759551 , 0.85732787,\n",
       "         0.74940643],\n",
       "        [0.69933089, 0.73796676, 0.34448521, 0.77099072, 0.81674941,\n",
       "         0.77530758],\n",
       "        [0.72199439, 0.73170732, 0.7155191 , 0.81804446, 0.69156054,\n",
       "         0.77012735]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1  2  3  4  5\n",
       "84   0  0  1  0  0\n",
       "2    1  0  0  0  0\n",
       "94   0  1  0  0  0\n",
       "45   0  0  1  0  0\n",
       "42   0  0  1  0  0\n",
       "..  .. .. .. .. ..\n",
       "71   0  0  1  0  0\n",
       "106  0  0  0  1  0\n",
       "14   1  0  0  0  0\n",
       "92   0  1  0  0  0\n",
       "102  0  0  0  0  1\n",
       "\n",
       "[131 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes_dict = {'normal':'1 0 0 0 0', #1\n",
    "        'collision_in_tool':'0 1 0 0 0', #2\n",
    "        'collision_in_part':'0 0 1 0 0', #3\n",
    "        'bottom_collision':'0 0 0 1 0', #4\n",
    "        'bottom_obstruction':'0 0 0 0 1'} #5\n",
    "\n",
    "labels_df = labels_df.replace({'labels':classes_dict})\n",
    "labels_df[['1', '2', '3', '4', '5']] = labels_df['labels'].str.split(' ', 4, expand= True)\n",
    "labels_df = labels_df.loc[:,['1', '2', '3', '4', '5']]\n",
    "labels_df[['1', '2', '3', '4', '5']]=labels_df[['1', '2', '3', '4', '5']].astype(str).astype(int)\n",
    "\n",
    "def norm(x):\n",
    "    x_min = x.min()\n",
    "    x_max = x.max()\n",
    "    range = x_max - x_min  #min max entre 0 y 1\n",
    "    return((x-x_min)/(range))\n",
    "\n",
    "norm_features = norm(features)\n",
    "#split para entrenamiento y validacion\n",
    "train_features, test_features, train_labels, test_labels  = train_test_split(norm_features, labels_df, test_size=0.2, random_state= 42)\n",
    "display(train_features)\n",
    "display(train_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_model(learning_rate):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(8, (3,3), activation='relu', input_shape = (15,6,1), padding='same'), # #de feature maps, dimensiones del kernel, kernel entre más pequeño mejor y se prefiere un número impar\n",
    "        tf.keras.layers.Conv2D(8, (3,3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.MaxPooling2D((2,2), strides= 2, padding= 'valid'), # dimensiones del pooling\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Conv2D(16, (3,3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.Conv2D(16, (3,3), activation='relu', padding='same'),# #de feature maps, dimensiones del kernel, kernel entre más pequeño mejor y se prefiere un número impar\n",
    "        tf.keras.layers.MaxPooling2D((2,2), strides= 2, padding='valid'), # dimensiones del pooling\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(24, activation='relu'),\n",
    "        tf.keras.layers.Dense(5, activation='softmax')])\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate), loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "# input shape es 15 filas, 6 columnas y 1 canal de color\n",
    "#model = model = my_model(0.01)\n",
    "#model.summary()\n",
    "\n",
    "# initialize tuner to run the model.\n",
    "# using the Hyperband search algorithm\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, features, labels, epochs, batch_size):\n",
    "    history = model.fit(\n",
    "        x = features,\n",
    "        y = labels,\n",
    "        epochs= epochs,\n",
    "        batch_size= batch_size,\n",
    "        validation_split= 0.25\n",
    "    )\n",
    "    hist= pd.DataFrame(history.history) #se guardan los valores de errores y metricas en un diccionario\n",
    "    hist['epoch'] = history.epoch #los epochs se deben añadir aparte\n",
    "    return hist"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizaciones\n",
    "### Pasos para visualizar los filtros:\n",
    "##### 1. Iterar por todas las capas del modelo usando model.layers\n",
    "##### 2. Si la capa actual es de convolucion se extraen los pesos y sesgos usando get_weights()\n",
    "##### 3. Se normalizan los pesos de los filtros entre 0 y 1\n",
    "##### 4. Se plotean los filtros para cada capa convolutional y todos los canales de color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_curves(history):\n",
    "    hist = history\n",
    "    labels = {\"loss\":\"Training Loss\", \"val_loss\":\"Validation Loss\"}\n",
    "    hist.rename(columns = labels, inplace = True)\n",
    "    \n",
    "    fig = px.line(hist, x='epoch', y=['Training Loss', 'Validation Loss'],\n",
    "                title='Gráficas de Pérdida de Entrenamiento y Evaluación',\n",
    "                labels={\"epoch\": \"Epoch\", \"value\":\"Binary Cross Entropy\", \"variable\":\"Curvas de Pérdida\"},\n",
    "                color_discrete_map={ # replaces default color mapping by value\n",
    "                \"Training Loss\": \"#46039f\", \"Validation Loss\": \"#fb9f3a\"})\n",
    "    fig.update_layout(template='plotly_white')\n",
    "    fig.show()\n",
    "    \n",
    "def accuracy_curve(history):\n",
    "    hist = history\n",
    "    labels = {\"val_accuracy\":\"Exactitud de Validación\", \"accuracy\":\"Exactitud de Entrenamiento\"}\n",
    "    hist.rename(columns = labels, inplace = True)\n",
    "    \n",
    "    fig = px.line(hist, x='epoch', y=['Exactitud de Entrenamiento', 'Exactitud de Validación'],\n",
    "                title='Gráficas de Exactitud',\n",
    "                labels={\"epoch\": \"Epoch\", \"value\":\"Exactitud\", \"variable\":\"Curvas de Exactitud\"},\n",
    "                color_discrete_map={ # replaces default color mapping by value\n",
    "                \"Training Loss\": \"#46039f\", \"Validation Loss\": \"#fb9f3a\"})\n",
    "    fig.update_layout(template='plotly_white')\n",
    "    fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se corren las funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dave4\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\backend.py:5703: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 10ms/step - loss: 0.6738 - accuracy: 0.3061 - val_loss: 0.6224 - val_accuracy: 0.2727\n",
      "Epoch 2/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5797 - accuracy: 0.3061 - val_loss: 0.4985 - val_accuracy: 0.2727\n",
      "Epoch 3/275\n",
      " 1/20 [>.............................] - ETA: 0s - loss: 0.4895 - accuracy: 0.4000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dave4\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\backend.py:5703: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5170 - accuracy: 0.2755 - val_loss: 0.4937 - val_accuracy: 0.2727\n",
      "Epoch 4/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4940 - accuracy: 0.2959 - val_loss: 0.4948 - val_accuracy: 0.2727\n",
      "Epoch 5/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4973 - accuracy: 0.2653 - val_loss: 0.4912 - val_accuracy: 0.2727\n",
      "Epoch 6/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4916 - accuracy: 0.2755 - val_loss: 0.4981 - val_accuracy: 0.2727\n",
      "Epoch 7/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4928 - accuracy: 0.3061 - val_loss: 0.4948 - val_accuracy: 0.2727\n",
      "Epoch 8/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4992 - accuracy: 0.3163 - val_loss: 0.4890 - val_accuracy: 0.2727\n",
      "Epoch 9/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4989 - accuracy: 0.2959 - val_loss: 0.4957 - val_accuracy: 0.2727\n",
      "Epoch 10/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4943 - accuracy: 0.3265 - val_loss: 0.4955 - val_accuracy: 0.2727\n",
      "Epoch 11/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4918 - accuracy: 0.3061 - val_loss: 0.4890 - val_accuracy: 0.2727\n",
      "Epoch 12/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5001 - accuracy: 0.3061 - val_loss: 0.5023 - val_accuracy: 0.2727\n",
      "Epoch 13/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4935 - accuracy: 0.3061 - val_loss: 0.4904 - val_accuracy: 0.2727\n",
      "Epoch 14/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4906 - accuracy: 0.2755 - val_loss: 0.4862 - val_accuracy: 0.2727\n",
      "Epoch 15/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4909 - accuracy: 0.3163 - val_loss: 0.4922 - val_accuracy: 0.2727\n",
      "Epoch 16/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4855 - accuracy: 0.3163 - val_loss: 0.4840 - val_accuracy: 0.2727\n",
      "Epoch 17/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4894 - accuracy: 0.3265 - val_loss: 0.4851 - val_accuracy: 0.2727\n",
      "Epoch 18/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4920 - accuracy: 0.2857 - val_loss: 0.4866 - val_accuracy: 0.2727\n",
      "Epoch 19/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4798 - accuracy: 0.2857 - val_loss: 0.4918 - val_accuracy: 0.2727\n",
      "Epoch 20/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4822 - accuracy: 0.3469 - val_loss: 0.4831 - val_accuracy: 0.2727\n",
      "Epoch 21/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4803 - accuracy: 0.3673 - val_loss: 0.4712 - val_accuracy: 0.3333\n",
      "Epoch 22/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4613 - accuracy: 0.3776 - val_loss: 0.4772 - val_accuracy: 0.3333\n",
      "Epoch 23/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.4388 - val_loss: 0.4572 - val_accuracy: 0.3333\n",
      "Epoch 24/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4154 - accuracy: 0.4490 - val_loss: 0.4498 - val_accuracy: 0.3333\n",
      "Epoch 25/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.4490 - val_loss: 0.4453 - val_accuracy: 0.3333\n",
      "Epoch 26/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4153 - accuracy: 0.4490 - val_loss: 0.4313 - val_accuracy: 0.3333\n",
      "Epoch 27/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4067 - accuracy: 0.4490 - val_loss: 0.4569 - val_accuracy: 0.3333\n",
      "Epoch 28/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4085 - accuracy: 0.4388 - val_loss: 0.4280 - val_accuracy: 0.3333\n",
      "Epoch 29/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3925 - accuracy: 0.4796 - val_loss: 0.4524 - val_accuracy: 0.3333\n",
      "Epoch 30/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4060 - accuracy: 0.4592 - val_loss: 0.4319 - val_accuracy: 0.3939\n",
      "Epoch 31/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4085 - accuracy: 0.3980 - val_loss: 0.4305 - val_accuracy: 0.3333\n",
      "Epoch 32/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4021 - accuracy: 0.4184 - val_loss: 0.4307 - val_accuracy: 0.3333\n",
      "Epoch 33/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.4592 - val_loss: 0.4523 - val_accuracy: 0.3333\n",
      "Epoch 34/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4005 - accuracy: 0.4490 - val_loss: 0.4302 - val_accuracy: 0.3636\n",
      "Epoch 35/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3971 - accuracy: 0.4592 - val_loss: 0.4359 - val_accuracy: 0.3333\n",
      "Epoch 36/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3866 - accuracy: 0.4796 - val_loss: 0.4511 - val_accuracy: 0.3333\n",
      "Epoch 37/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3980 - accuracy: 0.4592 - val_loss: 0.4313 - val_accuracy: 0.3333\n",
      "Epoch 38/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3970 - accuracy: 0.4490 - val_loss: 0.4471 - val_accuracy: 0.4242\n",
      "Epoch 39/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3848 - accuracy: 0.4898 - val_loss: 0.4224 - val_accuracy: 0.3939\n",
      "Epoch 40/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3867 - accuracy: 0.4490 - val_loss: 0.4241 - val_accuracy: 0.3939\n",
      "Epoch 41/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3834 - accuracy: 0.4490 - val_loss: 0.4144 - val_accuracy: 0.3939\n",
      "Epoch 42/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3872 - accuracy: 0.4388 - val_loss: 0.4376 - val_accuracy: 0.3939\n",
      "Epoch 43/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3911 - accuracy: 0.4694 - val_loss: 0.4439 - val_accuracy: 0.3939\n",
      "Epoch 44/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3906 - accuracy: 0.4694 - val_loss: 0.4053 - val_accuracy: 0.3939\n",
      "Epoch 45/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3888 - accuracy: 0.4490 - val_loss: 0.4115 - val_accuracy: 0.3333\n",
      "Epoch 46/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3724 - accuracy: 0.4898 - val_loss: 0.4384 - val_accuracy: 0.4848\n",
      "Epoch 47/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.3673 - val_loss: 0.4316 - val_accuracy: 0.3939\n",
      "Epoch 48/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3864 - accuracy: 0.4898 - val_loss: 0.4189 - val_accuracy: 0.3333\n",
      "Epoch 49/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3853 - accuracy: 0.4898 - val_loss: 0.4149 - val_accuracy: 0.3636\n",
      "Epoch 50/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3922 - accuracy: 0.4490 - val_loss: 0.4038 - val_accuracy: 0.3939\n",
      "Epoch 51/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3785 - accuracy: 0.5000 - val_loss: 0.4016 - val_accuracy: 0.3636\n",
      "Epoch 52/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3825 - accuracy: 0.4796 - val_loss: 0.3852 - val_accuracy: 0.3939\n",
      "Epoch 53/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3697 - accuracy: 0.5102 - val_loss: 0.3780 - val_accuracy: 0.4242\n",
      "Epoch 54/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3680 - accuracy: 0.5102 - val_loss: 0.3718 - val_accuracy: 0.4242\n",
      "Epoch 55/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3685 - accuracy: 0.5000 - val_loss: 0.3772 - val_accuracy: 0.4242\n",
      "Epoch 56/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3749 - accuracy: 0.4694 - val_loss: 0.3973 - val_accuracy: 0.3939\n",
      "Epoch 57/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3678 - accuracy: 0.4898 - val_loss: 0.3830 - val_accuracy: 0.4545\n",
      "Epoch 58/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3715 - accuracy: 0.4796 - val_loss: 0.3797 - val_accuracy: 0.4545\n",
      "Epoch 59/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3964 - accuracy: 0.4796 - val_loss: 0.4042 - val_accuracy: 0.3939\n",
      "Epoch 60/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3973 - accuracy: 0.4490 - val_loss: 0.4307 - val_accuracy: 0.3939\n",
      "Epoch 61/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3881 - accuracy: 0.4592 - val_loss: 0.4006 - val_accuracy: 0.3939\n",
      "Epoch 62/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3715 - accuracy: 0.4796 - val_loss: 0.4083 - val_accuracy: 0.4848\n",
      "Epoch 63/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3750 - accuracy: 0.5102 - val_loss: 0.3820 - val_accuracy: 0.4242\n",
      "Epoch 64/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3730 - accuracy: 0.4490 - val_loss: 0.3748 - val_accuracy: 0.4545\n",
      "Epoch 65/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3663 - accuracy: 0.5000 - val_loss: 0.3816 - val_accuracy: 0.3939\n",
      "Epoch 66/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3959 - accuracy: 0.4388 - val_loss: 0.3926 - val_accuracy: 0.5152\n",
      "Epoch 67/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3720 - accuracy: 0.4796 - val_loss: 0.3901 - val_accuracy: 0.3939\n",
      "Epoch 68/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3750 - accuracy: 0.4592 - val_loss: 0.3774 - val_accuracy: 0.4545\n",
      "Epoch 69/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3727 - accuracy: 0.4592 - val_loss: 0.3942 - val_accuracy: 0.3939\n",
      "Epoch 70/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3478 - accuracy: 0.4898 - val_loss: 0.3587 - val_accuracy: 0.4848\n",
      "Epoch 71/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3642 - accuracy: 0.5000 - val_loss: 0.3978 - val_accuracy: 0.3939\n",
      "Epoch 72/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3833 - accuracy: 0.4796 - val_loss: 0.3839 - val_accuracy: 0.4242\n",
      "Epoch 73/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3499 - accuracy: 0.5408 - val_loss: 0.3389 - val_accuracy: 0.5152\n",
      "Epoch 74/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3576 - accuracy: 0.4694 - val_loss: 0.3496 - val_accuracy: 0.5152\n",
      "Epoch 75/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3645 - accuracy: 0.4796 - val_loss: 0.3390 - val_accuracy: 0.5455\n",
      "Epoch 76/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3556 - accuracy: 0.5000 - val_loss: 0.3276 - val_accuracy: 0.5152\n",
      "Epoch 77/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3544 - accuracy: 0.5408 - val_loss: 0.3642 - val_accuracy: 0.4545\n",
      "Epoch 78/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3500 - accuracy: 0.4796 - val_loss: 0.3685 - val_accuracy: 0.4242\n",
      "Epoch 79/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3631 - accuracy: 0.5408 - val_loss: 0.3586 - val_accuracy: 0.5455\n",
      "Epoch 80/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3842 - accuracy: 0.4796 - val_loss: 0.3965 - val_accuracy: 0.4242\n",
      "Epoch 81/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3807 - accuracy: 0.4592 - val_loss: 0.4203 - val_accuracy: 0.4848\n",
      "Epoch 82/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3648 - accuracy: 0.5306 - val_loss: 0.3895 - val_accuracy: 0.3939\n",
      "Epoch 83/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3757 - accuracy: 0.5000 - val_loss: 0.4025 - val_accuracy: 0.3939\n",
      "Epoch 84/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3740 - accuracy: 0.4388 - val_loss: 0.3460 - val_accuracy: 0.4848\n",
      "Epoch 85/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3674 - accuracy: 0.4796 - val_loss: 0.4124 - val_accuracy: 0.3939\n",
      "Epoch 86/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3644 - accuracy: 0.4592 - val_loss: 0.4142 - val_accuracy: 0.4848\n",
      "Epoch 87/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3781 - accuracy: 0.4592 - val_loss: 0.3713 - val_accuracy: 0.4545\n",
      "Epoch 88/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3656 - accuracy: 0.5102 - val_loss: 0.3762 - val_accuracy: 0.4242\n",
      "Epoch 89/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3558 - accuracy: 0.5510 - val_loss: 0.3504 - val_accuracy: 0.5455\n",
      "Epoch 90/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3495 - accuracy: 0.5306 - val_loss: 0.3517 - val_accuracy: 0.5152\n",
      "Epoch 91/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3457 - accuracy: 0.5306 - val_loss: 0.3525 - val_accuracy: 0.4545\n",
      "Epoch 92/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3458 - accuracy: 0.5102 - val_loss: 0.3352 - val_accuracy: 0.6061\n",
      "Epoch 93/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3390 - accuracy: 0.5714 - val_loss: 0.3352 - val_accuracy: 0.5758\n",
      "Epoch 94/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3451 - accuracy: 0.5102 - val_loss: 0.3274 - val_accuracy: 0.7576\n",
      "Epoch 95/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3375 - accuracy: 0.5306 - val_loss: 0.3224 - val_accuracy: 0.7576\n",
      "Epoch 96/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3544 - accuracy: 0.5408 - val_loss: 0.3558 - val_accuracy: 0.4545\n",
      "Epoch 97/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3553 - accuracy: 0.4796 - val_loss: 0.3434 - val_accuracy: 0.4848\n",
      "Epoch 98/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3491 - accuracy: 0.5408 - val_loss: 0.3264 - val_accuracy: 0.5758\n",
      "Epoch 99/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3464 - accuracy: 0.5204 - val_loss: 0.3595 - val_accuracy: 0.4545\n",
      "Epoch 100/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3384 - accuracy: 0.5612 - val_loss: 0.3352 - val_accuracy: 0.7273\n",
      "Epoch 101/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3334 - accuracy: 0.5000 - val_loss: 0.3192 - val_accuracy: 0.6061\n",
      "Epoch 102/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3390 - accuracy: 0.5204 - val_loss: 0.3348 - val_accuracy: 0.5758\n",
      "Epoch 103/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3471 - accuracy: 0.4694 - val_loss: 0.3411 - val_accuracy: 0.5152\n",
      "Epoch 104/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3370 - accuracy: 0.5510 - val_loss: 0.3072 - val_accuracy: 0.7273\n",
      "Epoch 105/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4015 - accuracy: 0.4184 - val_loss: 0.3916 - val_accuracy: 0.3939\n",
      "Epoch 106/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3586 - accuracy: 0.4898 - val_loss: 0.3695 - val_accuracy: 0.4545\n",
      "Epoch 107/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3518 - accuracy: 0.5204 - val_loss: 0.3511 - val_accuracy: 0.5152\n",
      "Epoch 108/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3443 - accuracy: 0.5510 - val_loss: 0.3202 - val_accuracy: 0.5152\n",
      "Epoch 109/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3348 - accuracy: 0.5306 - val_loss: 0.3064 - val_accuracy: 0.5455\n",
      "Epoch 110/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3482 - accuracy: 0.5102 - val_loss: 0.3268 - val_accuracy: 0.5758\n",
      "Epoch 111/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3734 - accuracy: 0.4694 - val_loss: 0.3749 - val_accuracy: 0.4545\n",
      "Epoch 112/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3598 - accuracy: 0.4796 - val_loss: 0.3461 - val_accuracy: 0.4848\n",
      "Epoch 113/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3197 - accuracy: 0.5510 - val_loss: 0.3123 - val_accuracy: 0.5455\n",
      "Epoch 114/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3339 - accuracy: 0.5408 - val_loss: 0.3110 - val_accuracy: 0.7879\n",
      "Epoch 115/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3201 - accuracy: 0.5714 - val_loss: 0.3042 - val_accuracy: 0.7879\n",
      "Epoch 116/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3305 - accuracy: 0.5510 - val_loss: 0.3608 - val_accuracy: 0.5455\n",
      "Epoch 117/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3390 - accuracy: 0.5612 - val_loss: 0.3050 - val_accuracy: 0.5758\n",
      "Epoch 118/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3255 - accuracy: 0.5816 - val_loss: 0.3030 - val_accuracy: 0.6061\n",
      "Epoch 119/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3076 - accuracy: 0.5816 - val_loss: 0.2983 - val_accuracy: 0.5758\n",
      "Epoch 120/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3418 - accuracy: 0.4898 - val_loss: 0.2908 - val_accuracy: 0.6364\n",
      "Epoch 121/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3212 - accuracy: 0.5816 - val_loss: 0.3070 - val_accuracy: 0.6061\n",
      "Epoch 122/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3260 - accuracy: 0.5408 - val_loss: 0.2937 - val_accuracy: 0.6364\n",
      "Epoch 123/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3146 - accuracy: 0.6020 - val_loss: 0.2891 - val_accuracy: 0.6061\n",
      "Epoch 124/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3280 - accuracy: 0.5510 - val_loss: 0.3033 - val_accuracy: 0.5455\n",
      "Epoch 125/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3170 - accuracy: 0.5612 - val_loss: 0.2978 - val_accuracy: 0.5758\n",
      "Epoch 126/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3030 - accuracy: 0.5918 - val_loss: 0.2943 - val_accuracy: 0.6061\n",
      "Epoch 127/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3278 - accuracy: 0.5816 - val_loss: 0.2801 - val_accuracy: 0.6667\n",
      "Epoch 128/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3096 - accuracy: 0.6429 - val_loss: 0.2830 - val_accuracy: 0.6970\n",
      "Epoch 129/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3268 - accuracy: 0.5612 - val_loss: 0.3071 - val_accuracy: 0.5758\n",
      "Epoch 130/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3441 - accuracy: 0.5102 - val_loss: 0.3197 - val_accuracy: 0.5152\n",
      "Epoch 131/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3313 - accuracy: 0.5612 - val_loss: 0.2962 - val_accuracy: 0.6364\n",
      "Epoch 132/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3128 - accuracy: 0.5816 - val_loss: 0.3019 - val_accuracy: 0.6061\n",
      "Epoch 133/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3238 - accuracy: 0.6224 - val_loss: 0.2724 - val_accuracy: 0.7273\n",
      "Epoch 134/275\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3162 - accuracy: 0.5714 - val_loss: 0.2686 - val_accuracy: 0.8182\n",
      "Epoch 135/275\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3019 - accuracy: 0.6633 - val_loss: 0.2697 - val_accuracy: 0.6364\n",
      "Epoch 136/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3135 - accuracy: 0.5510 - val_loss: 0.2954 - val_accuracy: 0.6061\n",
      "Epoch 137/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3380 - accuracy: 0.5408 - val_loss: 0.3697 - val_accuracy: 0.5152\n",
      "Epoch 138/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3600 - accuracy: 0.5714 - val_loss: 0.3067 - val_accuracy: 0.5455\n",
      "Epoch 139/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3261 - accuracy: 0.5408 - val_loss: 0.2916 - val_accuracy: 0.6667\n",
      "Epoch 140/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3167 - accuracy: 0.5816 - val_loss: 0.2876 - val_accuracy: 0.6061\n",
      "Epoch 141/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3057 - accuracy: 0.6429 - val_loss: 0.2686 - val_accuracy: 0.7576\n",
      "Epoch 142/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3151 - accuracy: 0.5816 - val_loss: 0.2741 - val_accuracy: 0.6061\n",
      "Epoch 143/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3143 - accuracy: 0.5714 - val_loss: 0.2933 - val_accuracy: 0.7273\n",
      "Epoch 144/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3004 - accuracy: 0.6020 - val_loss: 0.2886 - val_accuracy: 0.6061\n",
      "Epoch 145/275\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3118 - accuracy: 0.6020 - val_loss: 0.2625 - val_accuracy: 0.6970\n",
      "Epoch 146/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3017 - accuracy: 0.6429 - val_loss: 0.2583 - val_accuracy: 0.7273\n",
      "Epoch 147/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2912 - accuracy: 0.6327 - val_loss: 0.2604 - val_accuracy: 0.6970\n",
      "Epoch 148/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3186 - accuracy: 0.5612 - val_loss: 0.3037 - val_accuracy: 0.6061\n",
      "Epoch 149/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3016 - accuracy: 0.6020 - val_loss: 0.2566 - val_accuracy: 0.7576\n",
      "Epoch 150/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2948 - accuracy: 0.6633 - val_loss: 0.2561 - val_accuracy: 0.7273\n",
      "Epoch 151/275\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.2953 - accuracy: 0.6429 - val_loss: 0.2607 - val_accuracy: 0.6667\n",
      "Epoch 152/275\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3052 - accuracy: 0.6531 - val_loss: 0.2538 - val_accuracy: 0.7879\n",
      "Epoch 153/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3112 - accuracy: 0.6327 - val_loss: 0.2534 - val_accuracy: 0.8182\n",
      "Epoch 154/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3134 - accuracy: 0.5714 - val_loss: 0.2583 - val_accuracy: 0.7879\n",
      "Epoch 155/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2934 - accuracy: 0.6327 - val_loss: 0.2523 - val_accuracy: 0.6970\n",
      "Epoch 156/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2901 - accuracy: 0.6429 - val_loss: 0.2664 - val_accuracy: 0.6364\n",
      "Epoch 157/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2946 - accuracy: 0.6327 - val_loss: 0.2473 - val_accuracy: 0.6970\n",
      "Epoch 158/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2865 - accuracy: 0.6531 - val_loss: 0.2601 - val_accuracy: 0.6970\n",
      "Epoch 159/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3089 - accuracy: 0.6327 - val_loss: 0.2632 - val_accuracy: 0.6667\n",
      "Epoch 160/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3173 - accuracy: 0.5510 - val_loss: 0.2506 - val_accuracy: 0.8182\n",
      "Epoch 161/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3016 - accuracy: 0.6020 - val_loss: 0.3168 - val_accuracy: 0.7576\n",
      "Epoch 162/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3189 - accuracy: 0.5714 - val_loss: 0.3220 - val_accuracy: 0.6364\n",
      "Epoch 163/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2831 - accuracy: 0.6531 - val_loss: 0.2818 - val_accuracy: 0.5758\n",
      "Epoch 164/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2960 - accuracy: 0.6224 - val_loss: 0.2531 - val_accuracy: 0.6970\n",
      "Epoch 165/275\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.2853 - accuracy: 0.6633 - val_loss: 0.2655 - val_accuracy: 0.6061\n",
      "Epoch 166/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2944 - accuracy: 0.6224 - val_loss: 0.2698 - val_accuracy: 0.6061\n",
      "Epoch 167/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2962 - accuracy: 0.5816 - val_loss: 0.2605 - val_accuracy: 0.6061\n",
      "Epoch 168/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3051 - accuracy: 0.5510 - val_loss: 0.2983 - val_accuracy: 0.5758\n",
      "Epoch 169/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3128 - accuracy: 0.5816 - val_loss: 0.2733 - val_accuracy: 0.6061\n",
      "Epoch 170/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2987 - accuracy: 0.6327 - val_loss: 0.2844 - val_accuracy: 0.5758\n",
      "Epoch 171/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2980 - accuracy: 0.6224 - val_loss: 0.2501 - val_accuracy: 0.6970\n",
      "Epoch 172/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2850 - accuracy: 0.7041 - val_loss: 0.2420 - val_accuracy: 0.6970\n",
      "Epoch 173/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2790 - accuracy: 0.6837 - val_loss: 0.2451 - val_accuracy: 0.7576\n",
      "Epoch 174/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2751 - accuracy: 0.6531 - val_loss: 0.2730 - val_accuracy: 0.6667\n",
      "Epoch 175/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2951 - accuracy: 0.6735 - val_loss: 0.3881 - val_accuracy: 0.4848\n",
      "Epoch 176/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3145 - accuracy: 0.5612 - val_loss: 0.3287 - val_accuracy: 0.5758\n",
      "Epoch 177/275\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.2976 - accuracy: 0.6429 - val_loss: 0.2681 - val_accuracy: 0.6061\n",
      "Epoch 178/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2970 - accuracy: 0.6224 - val_loss: 0.2573 - val_accuracy: 0.6364\n",
      "Epoch 179/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2929 - accuracy: 0.6224 - val_loss: 0.2457 - val_accuracy: 0.6970\n",
      "Epoch 180/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2763 - accuracy: 0.6735 - val_loss: 0.2450 - val_accuracy: 0.6970\n",
      "Epoch 181/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2870 - accuracy: 0.6633 - val_loss: 0.2441 - val_accuracy: 0.6970\n",
      "Epoch 182/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2717 - accuracy: 0.6837 - val_loss: 0.2331 - val_accuracy: 0.7879\n",
      "Epoch 183/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2658 - accuracy: 0.6837 - val_loss: 0.2336 - val_accuracy: 0.7576\n",
      "Epoch 184/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2760 - accuracy: 0.6633 - val_loss: 0.2319 - val_accuracy: 0.7879\n",
      "Epoch 185/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2699 - accuracy: 0.6939 - val_loss: 0.2425 - val_accuracy: 0.6970\n",
      "Epoch 186/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2719 - accuracy: 0.6837 - val_loss: 0.2692 - val_accuracy: 0.6061\n",
      "Epoch 187/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2763 - accuracy: 0.6735 - val_loss: 0.2586 - val_accuracy: 0.6364\n",
      "Epoch 188/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2877 - accuracy: 0.6020 - val_loss: 0.2572 - val_accuracy: 0.6364\n",
      "Epoch 189/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2835 - accuracy: 0.6531 - val_loss: 0.2609 - val_accuracy: 0.6061\n",
      "Epoch 190/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2773 - accuracy: 0.6531 - val_loss: 0.2449 - val_accuracy: 0.6970\n",
      "Epoch 191/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2579 - accuracy: 0.6939 - val_loss: 0.2572 - val_accuracy: 0.6364\n",
      "Epoch 192/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2654 - accuracy: 0.6735 - val_loss: 0.2358 - val_accuracy: 0.6970\n",
      "Epoch 193/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2698 - accuracy: 0.6939 - val_loss: 0.2349 - val_accuracy: 0.7576\n",
      "Epoch 194/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2654 - accuracy: 0.7143 - val_loss: 0.2244 - val_accuracy: 0.7879\n",
      "Epoch 195/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2716 - accuracy: 0.6735 - val_loss: 0.2459 - val_accuracy: 0.6970\n",
      "Epoch 196/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3123 - accuracy: 0.5918 - val_loss: 0.2584 - val_accuracy: 0.7879\n",
      "Epoch 197/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2889 - accuracy: 0.6837 - val_loss: 0.2432 - val_accuracy: 0.7879\n",
      "Epoch 198/275\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.2627 - accuracy: 0.7041 - val_loss: 0.2373 - val_accuracy: 0.6970\n",
      "Epoch 199/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2736 - accuracy: 0.6735 - val_loss: 0.2549 - val_accuracy: 0.6061\n",
      "Epoch 200/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2784 - accuracy: 0.6837 - val_loss: 0.2518 - val_accuracy: 0.6364\n",
      "Epoch 201/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2656 - accuracy: 0.6735 - val_loss: 0.2345 - val_accuracy: 0.6970\n",
      "Epoch 202/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2683 - accuracy: 0.6633 - val_loss: 0.2649 - val_accuracy: 0.6061\n",
      "Epoch 203/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2662 - accuracy: 0.6837 - val_loss: 0.2353 - val_accuracy: 0.7273\n",
      "Epoch 204/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2703 - accuracy: 0.6939 - val_loss: 0.2444 - val_accuracy: 0.6364\n",
      "Epoch 205/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2780 - accuracy: 0.6429 - val_loss: 0.2574 - val_accuracy: 0.6061\n",
      "Epoch 206/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2852 - accuracy: 0.6224 - val_loss: 0.2420 - val_accuracy: 0.6970\n",
      "Epoch 207/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2575 - accuracy: 0.6633 - val_loss: 0.2201 - val_accuracy: 0.7576\n",
      "Epoch 208/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2752 - accuracy: 0.6837 - val_loss: 0.2459 - val_accuracy: 0.6970\n",
      "Epoch 209/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2634 - accuracy: 0.7041 - val_loss: 0.2286 - val_accuracy: 0.7576\n",
      "Epoch 210/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2615 - accuracy: 0.6837 - val_loss: 0.2208 - val_accuracy: 0.7576\n",
      "Epoch 211/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2759 - accuracy: 0.6429 - val_loss: 0.2684 - val_accuracy: 0.6061\n",
      "Epoch 212/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2604 - accuracy: 0.6735 - val_loss: 0.2231 - val_accuracy: 0.7576\n",
      "Epoch 213/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2758 - accuracy: 0.6633 - val_loss: 0.2394 - val_accuracy: 0.7273\n",
      "Epoch 214/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2881 - accuracy: 0.6837 - val_loss: 0.2228 - val_accuracy: 0.7576\n",
      "Epoch 215/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2959 - accuracy: 0.6939 - val_loss: 0.4003 - val_accuracy: 0.6364\n",
      "Epoch 216/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3125 - accuracy: 0.6327 - val_loss: 0.2302 - val_accuracy: 0.6970\n",
      "Epoch 217/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2620 - accuracy: 0.7041 - val_loss: 0.2325 - val_accuracy: 0.6970\n",
      "Epoch 218/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2688 - accuracy: 0.6531 - val_loss: 0.2237 - val_accuracy: 0.7576\n",
      "Epoch 219/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2733 - accuracy: 0.6633 - val_loss: 0.2420 - val_accuracy: 0.6364\n",
      "Epoch 220/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2797 - accuracy: 0.6837 - val_loss: 0.2385 - val_accuracy: 0.6364\n",
      "Epoch 221/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2905 - accuracy: 0.6429 - val_loss: 0.2328 - val_accuracy: 0.7879\n",
      "Epoch 222/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2681 - accuracy: 0.6735 - val_loss: 0.2420 - val_accuracy: 0.6970\n",
      "Epoch 223/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2676 - accuracy: 0.6735 - val_loss: 0.2259 - val_accuracy: 0.7273\n",
      "Epoch 224/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2610 - accuracy: 0.6939 - val_loss: 0.2298 - val_accuracy: 0.7576\n",
      "Epoch 225/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2629 - accuracy: 0.6837 - val_loss: 0.2149 - val_accuracy: 0.7273\n",
      "Epoch 226/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2464 - accuracy: 0.7143 - val_loss: 0.2258 - val_accuracy: 0.6970\n",
      "Epoch 227/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2584 - accuracy: 0.7041 - val_loss: 0.2290 - val_accuracy: 0.7273\n",
      "Epoch 228/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2754 - accuracy: 0.6633 - val_loss: 0.2207 - val_accuracy: 0.7879\n",
      "Epoch 229/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2620 - accuracy: 0.6633 - val_loss: 0.2256 - val_accuracy: 0.7273\n",
      "Epoch 230/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2651 - accuracy: 0.6939 - val_loss: 0.2261 - val_accuracy: 0.7273\n",
      "Epoch 231/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2580 - accuracy: 0.6837 - val_loss: 0.2138 - val_accuracy: 0.7576\n",
      "Epoch 232/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3782 - accuracy: 0.5408 - val_loss: 0.4228 - val_accuracy: 0.3939\n",
      "Epoch 233/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3952 - accuracy: 0.4898 - val_loss: 0.3903 - val_accuracy: 0.4242\n",
      "Epoch 234/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3950 - accuracy: 0.4286 - val_loss: 0.3923 - val_accuracy: 0.4242\n",
      "Epoch 235/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3910 - accuracy: 0.4694 - val_loss: 0.3888 - val_accuracy: 0.4242\n",
      "Epoch 236/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3821 - accuracy: 0.4796 - val_loss: 0.3802 - val_accuracy: 0.3939\n",
      "Epoch 237/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3645 - accuracy: 0.4592 - val_loss: 0.3458 - val_accuracy: 0.5152\n",
      "Epoch 238/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3126 - accuracy: 0.5816 - val_loss: 0.2529 - val_accuracy: 0.6667\n",
      "Epoch 239/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2886 - accuracy: 0.6122 - val_loss: 0.2451 - val_accuracy: 0.6970\n",
      "Epoch 240/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2725 - accuracy: 0.6327 - val_loss: 0.2441 - val_accuracy: 0.6667\n",
      "Epoch 241/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2753 - accuracy: 0.6633 - val_loss: 0.2474 - val_accuracy: 0.6667\n",
      "Epoch 242/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2568 - accuracy: 0.6939 - val_loss: 0.2348 - val_accuracy: 0.6970\n",
      "Epoch 243/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2636 - accuracy: 0.7245 - val_loss: 0.2285 - val_accuracy: 0.6970\n",
      "Epoch 244/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2620 - accuracy: 0.6939 - val_loss: 0.2202 - val_accuracy: 0.7576\n",
      "Epoch 245/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2670 - accuracy: 0.6939 - val_loss: 0.2096 - val_accuracy: 0.7273\n",
      "Epoch 246/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2551 - accuracy: 0.7041 - val_loss: 0.2277 - val_accuracy: 0.7576\n",
      "Epoch 247/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2631 - accuracy: 0.6939 - val_loss: 0.2210 - val_accuracy: 0.7576\n",
      "Epoch 248/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2565 - accuracy: 0.6837 - val_loss: 0.2214 - val_accuracy: 0.7576\n",
      "Epoch 249/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2591 - accuracy: 0.6939 - val_loss: 0.2261 - val_accuracy: 0.7576\n",
      "Epoch 250/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2468 - accuracy: 0.6939 - val_loss: 0.2166 - val_accuracy: 0.7576\n",
      "Epoch 251/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2530 - accuracy: 0.6939 - val_loss: 0.2108 - val_accuracy: 0.7273\n",
      "Epoch 252/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3194 - accuracy: 0.6327 - val_loss: 0.2097 - val_accuracy: 0.7576\n",
      "Epoch 253/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3150 - accuracy: 0.6122 - val_loss: 0.3028 - val_accuracy: 0.5455\n",
      "Epoch 254/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3392 - accuracy: 0.5612 - val_loss: 0.2752 - val_accuracy: 0.6061\n",
      "Epoch 255/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2955 - accuracy: 0.6429 - val_loss: 0.2413 - val_accuracy: 0.7879\n",
      "Epoch 256/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2859 - accuracy: 0.6531 - val_loss: 0.2960 - val_accuracy: 0.5758\n",
      "Epoch 257/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2764 - accuracy: 0.6429 - val_loss: 0.2853 - val_accuracy: 0.6061\n",
      "Epoch 258/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2820 - accuracy: 0.6633 - val_loss: 0.2618 - val_accuracy: 0.6061\n",
      "Epoch 259/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2929 - accuracy: 0.6429 - val_loss: 0.2759 - val_accuracy: 0.5758\n",
      "Epoch 260/275\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2851 - accuracy: 0.6327 - val_loss: 0.2757 - val_accuracy: 0.6061\n",
      "Epoch 261/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2824 - accuracy: 0.6531 - val_loss: 0.2401 - val_accuracy: 0.6970\n",
      "Epoch 262/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2657 - accuracy: 0.6735 - val_loss: 0.2612 - val_accuracy: 0.6061\n",
      "Epoch 263/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2684 - accuracy: 0.6531 - val_loss: 0.2276 - val_accuracy: 0.7576\n",
      "Epoch 264/275\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.2728 - accuracy: 0.6837 - val_loss: 0.2483 - val_accuracy: 0.6364\n",
      "Epoch 265/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2621 - accuracy: 0.6735 - val_loss: 0.2239 - val_accuracy: 0.7576\n",
      "Epoch 266/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2497 - accuracy: 0.7347 - val_loss: 0.2161 - val_accuracy: 0.7273\n",
      "Epoch 267/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2663 - accuracy: 0.6939 - val_loss: 0.2749 - val_accuracy: 0.5758\n",
      "Epoch 268/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2837 - accuracy: 0.6531 - val_loss: 0.2665 - val_accuracy: 0.5758\n",
      "Epoch 269/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2599 - accuracy: 0.7041 - val_loss: 0.2252 - val_accuracy: 0.8182\n",
      "Epoch 270/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2483 - accuracy: 0.7245 - val_loss: 0.2414 - val_accuracy: 0.6970\n",
      "Epoch 271/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2545 - accuracy: 0.6735 - val_loss: 0.2561 - val_accuracy: 0.6061\n",
      "Epoch 272/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2619 - accuracy: 0.6735 - val_loss: 0.2634 - val_accuracy: 0.6061\n",
      "Epoch 273/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2592 - accuracy: 0.6837 - val_loss: 0.2344 - val_accuracy: 0.6970\n",
      "Epoch 274/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2523 - accuracy: 0.6633 - val_loss: 0.2076 - val_accuracy: 0.7576\n",
      "Epoch 275/275\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.2422 - accuracy: 0.7347 - val_loss: 0.2294 - val_accuracy: 0.6970\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.674</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.580</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.517</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.273</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.494</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.273</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.497</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.273</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>0.254</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.606</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>0.262</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.606</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>0.259</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.697</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>0.252</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.758</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>0.242</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.697</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>275 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     loss  accuracy  val_loss  val_accuracy  epoch\n",
       "0   0.674     0.306     0.622         0.273      0\n",
       "1   0.580     0.306     0.499         0.273      1\n",
       "2   0.517     0.276     0.494         0.273      2\n",
       "3   0.494     0.296     0.495         0.273      3\n",
       "4   0.497     0.265     0.491         0.273      4\n",
       "..    ...       ...       ...           ...    ...\n",
       "270 0.254     0.673     0.256         0.606    270\n",
       "271 0.262     0.673     0.263         0.606    271\n",
       "272 0.259     0.684     0.234         0.697    272\n",
       "273 0.252     0.663     0.208         0.758    273\n",
       "274 0.242     0.735     0.229         0.697    274\n",
       "\n",
       "[275 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Curvas de Pérdida=Training Loss<br>Epoch=%{x}<br>Binary Cross Entropy=%{y}<extra></extra>",
         "legendgroup": "Training Loss",
         "line": {
          "color": "#46039f",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "Training Loss",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274
         ],
         "xaxis": "x",
         "y": [
          0.6737751960754395,
          0.5796937942504883,
          0.5169968008995056,
          0.49403607845306396,
          0.4973050057888031,
          0.4916014075279236,
          0.49275457859039307,
          0.4992339611053467,
          0.4988574683666229,
          0.49430277943611145,
          0.49175915122032166,
          0.5000674724578857,
          0.4935385286808014,
          0.49059537053108215,
          0.49094560742378235,
          0.48547112941741943,
          0.4894406497478485,
          0.4919935464859009,
          0.47983622550964355,
          0.4821910560131073,
          0.4802744388580322,
          0.4613339304924011,
          0.43999382853507996,
          0.41542983055114746,
          0.4070146977901459,
          0.4153044521808624,
          0.4066530466079712,
          0.4084884226322174,
          0.39250949025154114,
          0.4060443937778473,
          0.40852949023246765,
          0.4021303951740265,
          0.4038914740085602,
          0.400482177734375,
          0.39708849787712097,
          0.38658902049064636,
          0.3979964852333069,
          0.3970180153846741,
          0.3847937285900116,
          0.3866502344608307,
          0.38341405987739563,
          0.3872282803058624,
          0.39113783836364746,
          0.3906365931034088,
          0.38878634572029114,
          0.37240856885910034,
          0.4190462827682495,
          0.3863619863986969,
          0.385282039642334,
          0.39221495389938354,
          0.37850990891456604,
          0.38254034519195557,
          0.3697199821472168,
          0.3679693043231964,
          0.3685428500175476,
          0.37486711144447327,
          0.3677544593811035,
          0.3714592456817627,
          0.3963833153247833,
          0.39733242988586426,
          0.38814711570739746,
          0.3714706599712372,
          0.37503138184547424,
          0.37301239371299744,
          0.36625251173973083,
          0.39593034982681274,
          0.3720393180847168,
          0.37498342990875244,
          0.3727288842201233,
          0.34775233268737793,
          0.364216148853302,
          0.3833393454551697,
          0.3499033749103546,
          0.3576478660106659,
          0.36446014046669006,
          0.35562554001808167,
          0.3544096350669861,
          0.34998929500579834,
          0.36312243342399597,
          0.3841794729232788,
          0.38074955344200134,
          0.36484524607658386,
          0.3756753206253052,
          0.3739912509918213,
          0.36740338802337646,
          0.3644416630268097,
          0.37813377380371094,
          0.3655679523944855,
          0.3558381199836731,
          0.3494724631309509,
          0.345724493265152,
          0.3458264470100403,
          0.33898553252220154,
          0.34513232111930847,
          0.3374846577644348,
          0.3543836176395416,
          0.35531336069107056,
          0.34905582666397095,
          0.3463849723339081,
          0.3383767306804657,
          0.3333577513694763,
          0.3390141725540161,
          0.3471044898033142,
          0.3370331823825836,
          0.4014925956726074,
          0.3585825264453888,
          0.3518085777759552,
          0.34427502751350403,
          0.3348011076450348,
          0.34821590781211853,
          0.3733781576156616,
          0.3598317503929138,
          0.3196686804294586,
          0.3338674306869507,
          0.32009148597717285,
          0.3304852843284607,
          0.3390175998210907,
          0.3254551291465759,
          0.3076285123825073,
          0.34182703495025635,
          0.32123905420303345,
          0.3259614408016205,
          0.31461355090141296,
          0.32803967595100403,
          0.31701040267944336,
          0.3030265271663666,
          0.32777395844459534,
          0.3096233606338501,
          0.3268069922924042,
          0.34410884976387024,
          0.3312825858592987,
          0.3128349781036377,
          0.3237925171852112,
          0.31619930267333984,
          0.30185770988464355,
          0.3135007321834564,
          0.33801934123039246,
          0.3599701225757599,
          0.32614076137542725,
          0.3166850805282593,
          0.3056812882423401,
          0.3150554895401001,
          0.31430181860923767,
          0.3004157841205597,
          0.31176403164863586,
          0.30165114998817444,
          0.2911666929721832,
          0.31857284903526306,
          0.30160582065582275,
          0.29476049542427063,
          0.2953278422355652,
          0.3052334785461426,
          0.311248779296875,
          0.31337082386016846,
          0.2934422492980957,
          0.29007986187934875,
          0.2946271598339081,
          0.28647372126579285,
          0.30885520577430725,
          0.3173082768917084,
          0.30162546038627625,
          0.31893637776374817,
          0.28314322233200073,
          0.2959710955619812,
          0.2853139638900757,
          0.2944488823413849,
          0.29623943567276,
          0.305067241191864,
          0.31279054284095764,
          0.29873964190483093,
          0.29797378182411194,
          0.2849525809288025,
          0.27898579835891724,
          0.27513325214385986,
          0.29508817195892334,
          0.3145182132720947,
          0.29762759804725647,
          0.29696163535118103,
          0.2928524315357208,
          0.27625107765197754,
          0.2870495021343231,
          0.2717415690422058,
          0.26580262184143066,
          0.27599015831947327,
          0.2699436545372009,
          0.2719230651855469,
          0.2763097882270813,
          0.2877039909362793,
          0.28353574872016907,
          0.27726826071739197,
          0.25791922211647034,
          0.2653997242450714,
          0.2697865068912506,
          0.26536330580711365,
          0.27155089378356934,
          0.3122604787349701,
          0.2889125645160675,
          0.2626839876174927,
          0.2736350893974304,
          0.2784213721752167,
          0.2656378746032715,
          0.2683042883872986,
          0.26624158024787903,
          0.27025818824768066,
          0.27800968289375305,
          0.28516075015068054,
          0.25746315717697144,
          0.2752271890640259,
          0.2634235620498657,
          0.26151320338249207,
          0.27587705850601196,
          0.2604151666164398,
          0.2757773995399475,
          0.2880712151527405,
          0.29590871930122375,
          0.3124829828739166,
          0.26201775670051575,
          0.26884347200393677,
          0.2732911705970764,
          0.27969399094581604,
          0.2904515564441681,
          0.2680502235889435,
          0.26755794882774353,
          0.2610062062740326,
          0.2628844976425171,
          0.24639061093330383,
          0.258411169052124,
          0.27539145946502686,
          0.26200589537620544,
          0.2650526165962219,
          0.25800973176956177,
          0.3782028257846832,
          0.3952230215072632,
          0.3949996531009674,
          0.3910388946533203,
          0.3821225166320801,
          0.36447054147720337,
          0.31257128715515137,
          0.2886274456977844,
          0.27247336506843567,
          0.2752787172794342,
          0.2568186819553375,
          0.26362815499305725,
          0.2620231807231903,
          0.2669999897480011,
          0.25509437918663025,
          0.2630597651004791,
          0.256533145904541,
          0.25911709666252136,
          0.24682921171188354,
          0.25297272205352783,
          0.31939736008644104,
          0.31495600938796997,
          0.3392006754875183,
          0.2954922616481781,
          0.2859293818473816,
          0.27639520168304443,
          0.2819950580596924,
          0.29288384318351746,
          0.2851380705833435,
          0.28239214420318604,
          0.2657064199447632,
          0.26843488216400146,
          0.27284613251686096,
          0.2620568871498108,
          0.24974451959133148,
          0.2663240134716034,
          0.2836679220199585,
          0.2599121928215027,
          0.24830345809459686,
          0.2544902563095093,
          0.2619284987449646,
          0.25924229621887207,
          0.2522910535335541,
          0.2421751618385315
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "Curvas de Pérdida=Validation Loss<br>Epoch=%{x}<br>Binary Cross Entropy=%{y}<extra></extra>",
         "legendgroup": "Validation Loss",
         "line": {
          "color": "#fb9f3a",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "Validation Loss",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274
         ],
         "xaxis": "x",
         "y": [
          0.6223809719085693,
          0.4985460937023163,
          0.49371957778930664,
          0.4947715997695923,
          0.49119821190834045,
          0.4980998635292053,
          0.4947964549064636,
          0.48897701501846313,
          0.4957292079925537,
          0.4954836368560791,
          0.4890158772468567,
          0.5023103952407837,
          0.49043089151382446,
          0.48618176579475403,
          0.4922024607658386,
          0.4839766323566437,
          0.4850912392139435,
          0.4866108298301697,
          0.49184903502464294,
          0.4830906093120575,
          0.4712197482585907,
          0.4771721661090851,
          0.4572211503982544,
          0.4498007893562317,
          0.44528135657310486,
          0.43129584193229675,
          0.4569397270679474,
          0.4279659688472748,
          0.4524182081222534,
          0.43193772435188293,
          0.4304598271846771,
          0.43066778779029846,
          0.45227813720703125,
          0.4301545321941376,
          0.435926616191864,
          0.45108750462532043,
          0.43130922317504883,
          0.44706496596336365,
          0.422360897064209,
          0.4241114854812622,
          0.4144419729709625,
          0.4376467168331146,
          0.44394099712371826,
          0.40532711148262024,
          0.4114726185798645,
          0.43839994072914124,
          0.4315800070762634,
          0.4189295768737793,
          0.41486719250679016,
          0.4037875235080719,
          0.401567280292511,
          0.3851698040962219,
          0.3779807388782501,
          0.37177687883377075,
          0.3771558403968811,
          0.3972814083099365,
          0.382953941822052,
          0.37966611981391907,
          0.40419167280197144,
          0.4307056963443756,
          0.40063706040382385,
          0.40826576948165894,
          0.38202419877052307,
          0.37482699751853943,
          0.3815784752368927,
          0.39258748292922974,
          0.3900790214538574,
          0.3773614764213562,
          0.39423248171806335,
          0.358683705329895,
          0.39782974123954773,
          0.38389331102371216,
          0.33885836601257324,
          0.34960609674453735,
          0.3389839231967926,
          0.3276478052139282,
          0.36415112018585205,
          0.36852702498435974,
          0.35855698585510254,
          0.39646437764167786,
          0.42027977108955383,
          0.3894614577293396,
          0.40251943469047546,
          0.34603068232536316,
          0.4124065041542053,
          0.414242148399353,
          0.37131819128990173,
          0.3762498199939728,
          0.35037168860435486,
          0.35166096687316895,
          0.35248422622680664,
          0.3352242410182953,
          0.335176557302475,
          0.32741525769233704,
          0.32236671447753906,
          0.35579171776771545,
          0.3434293568134308,
          0.3263850808143616,
          0.3595275580883026,
          0.33523130416870117,
          0.31922009587287903,
          0.3348405957221985,
          0.34110087156295776,
          0.30724191665649414,
          0.391571968793869,
          0.3694996237754822,
          0.3510786294937134,
          0.32015275955200195,
          0.30640092492103577,
          0.32681989669799805,
          0.37487417459487915,
          0.3461337685585022,
          0.31229159235954285,
          0.3110326826572418,
          0.3042406141757965,
          0.3607509434223175,
          0.30502498149871826,
          0.30302855372428894,
          0.29832497239112854,
          0.2908223867416382,
          0.3070307672023773,
          0.29366013407707214,
          0.28907063603401184,
          0.30326616764068604,
          0.29776614904403687,
          0.29425108432769775,
          0.2801322638988495,
          0.28302058577537537,
          0.3071354627609253,
          0.31970512866973877,
          0.2961905598640442,
          0.3018810451030731,
          0.2724114954471588,
          0.26856088638305664,
          0.2697437107563019,
          0.2954273819923401,
          0.36967501044273376,
          0.3066880702972412,
          0.2916076183319092,
          0.28757244348526,
          0.26859450340270996,
          0.2740602493286133,
          0.293316513299942,
          0.288644015789032,
          0.26250362396240234,
          0.25833454728126526,
          0.26039543747901917,
          0.3037343919277191,
          0.25658100843429565,
          0.25608664751052856,
          0.2607475221157074,
          0.2538473904132843,
          0.25340548157691956,
          0.25832322239875793,
          0.25234097242355347,
          0.2663801610469818,
          0.24726055562496185,
          0.2601475715637207,
          0.26318684220314026,
          0.25059443712234497,
          0.3168319761753082,
          0.32195910811424255,
          0.28182268142700195,
          0.25314709544181824,
          0.26553255319595337,
          0.2697993516921997,
          0.2605046331882477,
          0.2983226776123047,
          0.27328959107398987,
          0.28442656993865967,
          0.2501240372657776,
          0.24199654161930084,
          0.24505794048309326,
          0.27298814058303833,
          0.38813531398773193,
          0.32868653535842896,
          0.26806050539016724,
          0.25727081298828125,
          0.24566145241260529,
          0.24495413899421692,
          0.2440948486328125,
          0.2330922931432724,
          0.23357610404491425,
          0.23189175128936768,
          0.24254931509494781,
          0.269239217042923,
          0.2585958242416382,
          0.2571878135204315,
          0.26088955998420715,
          0.2448544055223465,
          0.2571841776371002,
          0.23575985431671143,
          0.2348812371492386,
          0.22438013553619385,
          0.24587643146514893,
          0.2583570182323456,
          0.24315142631530762,
          0.23729844391345978,
          0.2549157738685608,
          0.2518158257007599,
          0.2344600111246109,
          0.2648562788963318,
          0.23531651496887207,
          0.24439574778079987,
          0.25744500756263733,
          0.24203509092330933,
          0.2200758010149002,
          0.24594956636428833,
          0.2286357283592224,
          0.22078381478786469,
          0.26837190985679626,
          0.22306367754936218,
          0.23935256898403168,
          0.22278517484664917,
          0.4002811014652252,
          0.2302446961402893,
          0.23252658545970917,
          0.22368502616882324,
          0.24199634790420532,
          0.2384648323059082,
          0.2327582687139511,
          0.24201686680316925,
          0.22589993476867676,
          0.22980283200740814,
          0.21485716104507446,
          0.2258380800485611,
          0.22903266549110413,
          0.22069178521633148,
          0.2256264090538025,
          0.2261141538619995,
          0.21376720070838928,
          0.4228227734565735,
          0.39029204845428467,
          0.39228543639183044,
          0.3887649178504944,
          0.3801615238189697,
          0.34576866030693054,
          0.25286245346069336,
          0.24513936042785645,
          0.24405181407928467,
          0.2474275678396225,
          0.2348446249961853,
          0.2284601330757141,
          0.2201511412858963,
          0.2096424549818039,
          0.22768186032772064,
          0.22101354598999023,
          0.22144298255443573,
          0.22606487572193146,
          0.21659064292907715,
          0.21075178682804108,
          0.20972800254821777,
          0.30278971791267395,
          0.2751513123512268,
          0.24134193360805511,
          0.2959820628166199,
          0.28533950448036194,
          0.2617960572242737,
          0.27590349316596985,
          0.27567341923713684,
          0.2401244342327118,
          0.26115021109580994,
          0.22760725021362305,
          0.24827754497528076,
          0.2239193618297577,
          0.2160935252904892,
          0.2748832106590271,
          0.2665233016014099,
          0.2251918464899063,
          0.2413690984249115,
          0.25606000423431396,
          0.2634371221065521,
          0.23438791930675507,
          0.20759317278862,
          0.22942893207073212
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "Curvas de Pérdida"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Gráficas de Pérdida de Entrenamiento y Evaluación"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Epoch"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Binary Cross Entropy"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Curvas de Exactitud=Exactitud de Entrenamiento<br>Epoch=%{x}<br>Exactitud=%{y}<extra></extra>",
         "legendgroup": "Exactitud de Entrenamiento",
         "line": {
          "color": "#00cc96",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "Exactitud de Entrenamiento",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274
         ],
         "xaxis": "x",
         "y": [
          0.30612245202064514,
          0.30612245202064514,
          0.27551019191741943,
          0.29591837525367737,
          0.26530611515045166,
          0.27551019191741943,
          0.30612245202064514,
          0.3163265287876129,
          0.29591837525367737,
          0.3265306055545807,
          0.30612245202064514,
          0.30612245202064514,
          0.30612245202064514,
          0.27551019191741943,
          0.3163265287876129,
          0.3163265287876129,
          0.3265306055545807,
          0.2857142984867096,
          0.2857142984867096,
          0.3469387888908386,
          0.36734694242477417,
          0.37755101919174194,
          0.43877550959587097,
          0.44897958636283875,
          0.44897958636283875,
          0.44897958636283875,
          0.44897958636283875,
          0.43877550959587097,
          0.47959184646606445,
          0.4591836631298065,
          0.3979591727256775,
          0.4183673560619354,
          0.4591836631298065,
          0.44897958636283875,
          0.4591836631298065,
          0.47959184646606445,
          0.4591836631298065,
          0.44897958636283875,
          0.4897959232330322,
          0.44897958636283875,
          0.44897958636283875,
          0.43877550959587097,
          0.4693877696990967,
          0.4693877696990967,
          0.44897958636283875,
          0.4897959232330322,
          0.36734694242477417,
          0.4897959232330322,
          0.4897959232330322,
          0.44897958636283875,
          0.5,
          0.47959184646606445,
          0.5102040767669678,
          0.5102040767669678,
          0.5,
          0.4693877696990967,
          0.4897959232330322,
          0.47959184646606445,
          0.47959184646606445,
          0.44897958636283875,
          0.4591836631298065,
          0.47959184646606445,
          0.5102040767669678,
          0.44897958636283875,
          0.5,
          0.43877550959587097,
          0.47959184646606445,
          0.4591836631298065,
          0.4591836631298065,
          0.4897959232330322,
          0.5,
          0.47959184646606445,
          0.5408163070678711,
          0.4693877696990967,
          0.47959184646606445,
          0.5,
          0.5408163070678711,
          0.47959184646606445,
          0.5408163070678711,
          0.47959184646606445,
          0.4591836631298065,
          0.5306122303009033,
          0.5,
          0.43877550959587097,
          0.47959184646606445,
          0.4591836631298065,
          0.4591836631298065,
          0.5102040767669678,
          0.5510203838348389,
          0.5306122303009033,
          0.5306122303009033,
          0.5102040767669678,
          0.5714285969734192,
          0.5102040767669678,
          0.5306122303009033,
          0.5408163070678711,
          0.47959184646606445,
          0.5408163070678711,
          0.5204081535339355,
          0.5612244606018066,
          0.5,
          0.5204081535339355,
          0.4693877696990967,
          0.5510203838348389,
          0.4183673560619354,
          0.4897959232330322,
          0.5204081535339355,
          0.5510203838348389,
          0.5306122303009033,
          0.5102040767669678,
          0.4693877696990967,
          0.47959184646606445,
          0.5510203838348389,
          0.5408163070678711,
          0.5714285969734192,
          0.5510203838348389,
          0.5612244606018066,
          0.581632673740387,
          0.581632673740387,
          0.4897959232330322,
          0.581632673740387,
          0.5408163070678711,
          0.6020408272743225,
          0.5510203838348389,
          0.5612244606018066,
          0.5918367505073547,
          0.581632673740387,
          0.6428571343421936,
          0.5612244606018066,
          0.5102040767669678,
          0.5612244606018066,
          0.581632673740387,
          0.6224489808082581,
          0.5714285969734192,
          0.6632652878761292,
          0.5510203838348389,
          0.5408163070678711,
          0.5714285969734192,
          0.5408163070678711,
          0.581632673740387,
          0.6428571343421936,
          0.581632673740387,
          0.5714285969734192,
          0.6020408272743225,
          0.6020408272743225,
          0.6428571343421936,
          0.6326530575752258,
          0.5612244606018066,
          0.6020408272743225,
          0.6632652878761292,
          0.6428571343421936,
          0.6530612111091614,
          0.6326530575752258,
          0.5714285969734192,
          0.6326530575752258,
          0.6428571343421936,
          0.6326530575752258,
          0.6530612111091614,
          0.6326530575752258,
          0.5510203838348389,
          0.6020408272743225,
          0.5714285969734192,
          0.6530612111091614,
          0.6224489808082581,
          0.6632652878761292,
          0.6224489808082581,
          0.581632673740387,
          0.5510203838348389,
          0.581632673740387,
          0.6326530575752258,
          0.6224489808082581,
          0.704081654548645,
          0.6836734414100647,
          0.6530612111091614,
          0.6734693646430969,
          0.5612244606018066,
          0.6428571343421936,
          0.6224489808082581,
          0.6224489808082581,
          0.6734693646430969,
          0.6632652878761292,
          0.6836734414100647,
          0.6836734414100647,
          0.6632652878761292,
          0.6938775777816772,
          0.6836734414100647,
          0.6734693646430969,
          0.6020408272743225,
          0.6530612111091614,
          0.6530612111091614,
          0.6938775777816772,
          0.6734693646430969,
          0.6938775777816772,
          0.7142857313156128,
          0.6734693646430969,
          0.5918367505073547,
          0.6836734414100647,
          0.704081654548645,
          0.6734693646430969,
          0.6836734414100647,
          0.6734693646430969,
          0.6632652878761292,
          0.6836734414100647,
          0.6938775777816772,
          0.6428571343421936,
          0.6224489808082581,
          0.6632652878761292,
          0.6836734414100647,
          0.704081654548645,
          0.6836734414100647,
          0.6428571343421936,
          0.6734693646430969,
          0.6632652878761292,
          0.6836734414100647,
          0.6938775777816772,
          0.6326530575752258,
          0.704081654548645,
          0.6530612111091614,
          0.6632652878761292,
          0.6836734414100647,
          0.6428571343421936,
          0.6734693646430969,
          0.6734693646430969,
          0.6938775777816772,
          0.6836734414100647,
          0.7142857313156128,
          0.704081654548645,
          0.6632652878761292,
          0.6632652878761292,
          0.6938775777816772,
          0.6836734414100647,
          0.5408163070678711,
          0.4897959232330322,
          0.4285714328289032,
          0.4693877696990967,
          0.47959184646606445,
          0.4591836631298065,
          0.581632673740387,
          0.6122449040412903,
          0.6326530575752258,
          0.6632652878761292,
          0.6938775777816772,
          0.7244898080825806,
          0.6938775777816772,
          0.6938775777816772,
          0.704081654548645,
          0.6938775777816772,
          0.6836734414100647,
          0.6938775777816772,
          0.6938775777816772,
          0.6938775777816772,
          0.6326530575752258,
          0.6122449040412903,
          0.5612244606018066,
          0.6428571343421936,
          0.6530612111091614,
          0.6428571343421936,
          0.6632652878761292,
          0.6428571343421936,
          0.6326530575752258,
          0.6530612111091614,
          0.6734693646430969,
          0.6530612111091614,
          0.6836734414100647,
          0.6734693646430969,
          0.7346938848495483,
          0.6938775777816772,
          0.6530612111091614,
          0.704081654548645,
          0.7244898080825806,
          0.6734693646430969,
          0.6734693646430969,
          0.6836734414100647,
          0.6632652878761292,
          0.7346938848495483
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "Curvas de Exactitud=Exactitud de Validación<br>Epoch=%{x}<br>Exactitud=%{y}<extra></extra>",
         "legendgroup": "Exactitud de Validación",
         "line": {
          "color": "#ab63fa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "Exactitud de Validación",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274
         ],
         "xaxis": "x",
         "y": [
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.3333333432674408,
          0.3333333432674408,
          0.3333333432674408,
          0.3333333432674408,
          0.3333333432674408,
          0.3333333432674408,
          0.3333333432674408,
          0.3333333432674408,
          0.3333333432674408,
          0.39393940567970276,
          0.3333333432674408,
          0.3333333432674408,
          0.3333333432674408,
          0.3636363744735718,
          0.3333333432674408,
          0.3333333432674408,
          0.3333333432674408,
          0.42424243688583374,
          0.39393940567970276,
          0.39393940567970276,
          0.39393940567970276,
          0.39393940567970276,
          0.39393940567970276,
          0.39393940567970276,
          0.3333333432674408,
          0.4848484992980957,
          0.39393940567970276,
          0.3333333432674408,
          0.3636363744735718,
          0.39393940567970276,
          0.3636363744735718,
          0.39393940567970276,
          0.42424243688583374,
          0.42424243688583374,
          0.42424243688583374,
          0.39393940567970276,
          0.4545454680919647,
          0.4545454680919647,
          0.39393940567970276,
          0.39393940567970276,
          0.39393940567970276,
          0.4848484992980957,
          0.42424243688583374,
          0.4545454680919647,
          0.39393940567970276,
          0.5151515007019043,
          0.39393940567970276,
          0.4545454680919647,
          0.39393940567970276,
          0.4848484992980957,
          0.39393940567970276,
          0.42424243688583374,
          0.5151515007019043,
          0.5151515007019043,
          0.5454545617103577,
          0.5151515007019043,
          0.4545454680919647,
          0.42424243688583374,
          0.5454545617103577,
          0.42424243688583374,
          0.4848484992980957,
          0.39393940567970276,
          0.39393940567970276,
          0.4848484992980957,
          0.39393940567970276,
          0.4848484992980957,
          0.4545454680919647,
          0.42424243688583374,
          0.5454545617103577,
          0.5151515007019043,
          0.4545454680919647,
          0.6060606241226196,
          0.5757575631141663,
          0.7575757503509521,
          0.7575757503509521,
          0.4545454680919647,
          0.4848484992980957,
          0.5757575631141663,
          0.4545454680919647,
          0.7272727489471436,
          0.6060606241226196,
          0.5757575631141663,
          0.5151515007019043,
          0.7272727489471436,
          0.39393940567970276,
          0.4545454680919647,
          0.5151515007019043,
          0.5151515007019043,
          0.5454545617103577,
          0.5757575631141663,
          0.4545454680919647,
          0.4848484992980957,
          0.5454545617103577,
          0.7878788113594055,
          0.7878788113594055,
          0.5454545617103577,
          0.5757575631141663,
          0.6060606241226196,
          0.5757575631141663,
          0.6363636255264282,
          0.6060606241226196,
          0.6363636255264282,
          0.6060606241226196,
          0.5454545617103577,
          0.5757575631141663,
          0.6060606241226196,
          0.6666666865348816,
          0.6969696879386902,
          0.5757575631141663,
          0.5151515007019043,
          0.6363636255264282,
          0.6060606241226196,
          0.7272727489471436,
          0.8181818127632141,
          0.6363636255264282,
          0.6060606241226196,
          0.5151515007019043,
          0.5454545617103577,
          0.6666666865348816,
          0.6060606241226196,
          0.7575757503509521,
          0.6060606241226196,
          0.7272727489471436,
          0.6060606241226196,
          0.6969696879386902,
          0.7272727489471436,
          0.6969696879386902,
          0.6060606241226196,
          0.7575757503509521,
          0.7272727489471436,
          0.6666666865348816,
          0.7878788113594055,
          0.8181818127632141,
          0.7878788113594055,
          0.6969696879386902,
          0.6363636255264282,
          0.6969696879386902,
          0.6969696879386902,
          0.6666666865348816,
          0.8181818127632141,
          0.7575757503509521,
          0.6363636255264282,
          0.5757575631141663,
          0.6969696879386902,
          0.6060606241226196,
          0.6060606241226196,
          0.6060606241226196,
          0.5757575631141663,
          0.6060606241226196,
          0.5757575631141663,
          0.6969696879386902,
          0.6969696879386902,
          0.7575757503509521,
          0.6666666865348816,
          0.4848484992980957,
          0.5757575631141663,
          0.6060606241226196,
          0.6363636255264282,
          0.6969696879386902,
          0.6969696879386902,
          0.6969696879386902,
          0.7878788113594055,
          0.7575757503509521,
          0.7878788113594055,
          0.6969696879386902,
          0.6060606241226196,
          0.6363636255264282,
          0.6363636255264282,
          0.6060606241226196,
          0.6969696879386902,
          0.6363636255264282,
          0.6969696879386902,
          0.7575757503509521,
          0.7878788113594055,
          0.6969696879386902,
          0.7878788113594055,
          0.7878788113594055,
          0.6969696879386902,
          0.6060606241226196,
          0.6363636255264282,
          0.6969696879386902,
          0.6060606241226196,
          0.7272727489471436,
          0.6363636255264282,
          0.6060606241226196,
          0.6969696879386902,
          0.7575757503509521,
          0.6969696879386902,
          0.7575757503509521,
          0.7575757503509521,
          0.6060606241226196,
          0.7575757503509521,
          0.7272727489471436,
          0.7575757503509521,
          0.6363636255264282,
          0.6969696879386902,
          0.6969696879386902,
          0.7575757503509521,
          0.6363636255264282,
          0.6363636255264282,
          0.7878788113594055,
          0.6969696879386902,
          0.7272727489471436,
          0.7575757503509521,
          0.7272727489471436,
          0.6969696879386902,
          0.7272727489471436,
          0.7878788113594055,
          0.7272727489471436,
          0.7272727489471436,
          0.7575757503509521,
          0.39393940567970276,
          0.42424243688583374,
          0.42424243688583374,
          0.42424243688583374,
          0.39393940567970276,
          0.5151515007019043,
          0.6666666865348816,
          0.6969696879386902,
          0.6666666865348816,
          0.6666666865348816,
          0.6969696879386902,
          0.6969696879386902,
          0.7575757503509521,
          0.7272727489471436,
          0.7575757503509521,
          0.7575757503509521,
          0.7575757503509521,
          0.7575757503509521,
          0.7575757503509521,
          0.7272727489471436,
          0.7575757503509521,
          0.5454545617103577,
          0.6060606241226196,
          0.7878788113594055,
          0.5757575631141663,
          0.6060606241226196,
          0.6060606241226196,
          0.5757575631141663,
          0.6060606241226196,
          0.6969696879386902,
          0.6060606241226196,
          0.7575757503509521,
          0.6363636255264282,
          0.7575757503509521,
          0.7272727489471436,
          0.5757575631141663,
          0.5757575631141663,
          0.8181818127632141,
          0.6969696879386902,
          0.6060606241226196,
          0.6060606241226196,
          0.6969696879386902,
          0.7575757503509521,
          0.6969696879386902
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "Curvas de Exactitud"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Gráficas de Exactitud"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Epoch"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Exactitud"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Exactitud de Entrenamiento</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Exactitud de Validación</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.674</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.580</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.517</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.273</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.494</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.273</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.497</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.273</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>0.254</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.606</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>0.262</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.606</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>0.259</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.697</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>0.252</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.758</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>0.242</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.697</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>275 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Training Loss  Exactitud de Entrenamiento  Validation Loss  \\\n",
       "0            0.674                       0.306            0.622   \n",
       "1            0.580                       0.306            0.499   \n",
       "2            0.517                       0.276            0.494   \n",
       "3            0.494                       0.296            0.495   \n",
       "4            0.497                       0.265            0.491   \n",
       "..             ...                         ...              ...   \n",
       "270          0.254                       0.673            0.256   \n",
       "271          0.262                       0.673            0.263   \n",
       "272          0.259                       0.684            0.234   \n",
       "273          0.252                       0.663            0.208   \n",
       "274          0.242                       0.735            0.229   \n",
       "\n",
       "     Exactitud de Validación  epoch  \n",
       "0                      0.273      0  \n",
       "1                      0.273      1  \n",
       "2                      0.273      2  \n",
       "3                      0.273      3  \n",
       "4                      0.273      4  \n",
       "..                       ...    ...  \n",
       "270                    0.606    270  \n",
       "271                    0.606    271  \n",
       "272                    0.697    272  \n",
       "273                    0.758    273  \n",
       "274                    0.697    274  \n",
       "\n",
       "[275 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learning_rate = 0.002\n",
    "epochs = 275\n",
    "batch_size = 5\n",
    "model = my_model(learning_rate)\n",
    "history= train_model(model, train_features, train_labels, epochs, batch_size)\n",
    "display(history)\n",
    "loss_curves(history)\n",
    "accuracy_curve(history)\n",
    "#view_filters(model)\n",
    "display(history)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normal</th>\n",
       "      <th>collision_in_tool</th>\n",
       "      <th>collision_in_part</th>\n",
       "      <th>bottom_collision</th>\n",
       "      <th>bottom_obstruction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.014</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    normal  collision_in_tool  collision_in_part  bottom_collision  \\\n",
       "0    0.000              0.000              0.011             0.986   \n",
       "1    0.000              0.000              0.000             0.000   \n",
       "2    0.000              0.000              0.000             1.000   \n",
       "3    0.805              0.076              0.117             0.001   \n",
       "4    0.000              0.079              0.916             0.001   \n",
       "..     ...                ...                ...               ...   \n",
       "28   0.000              0.000              0.011             0.985   \n",
       "29   0.001              0.146              0.848             0.001   \n",
       "30   0.000              0.000              0.033             0.963   \n",
       "31   0.014              0.108              0.859             0.013   \n",
       "32   0.802              0.077              0.119             0.001   \n",
       "\n",
       "    bottom_obstruction  \n",
       "0                0.003  \n",
       "1                1.000  \n",
       "2                0.000  \n",
       "3                0.000  \n",
       "4                0.004  \n",
       "..                 ...  \n",
       "28               0.004  \n",
       "29               0.004  \n",
       "30               0.004  \n",
       "31               0.006  \n",
       "32               0.000  \n",
       "\n",
       "[33 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1  2  3  4  5\n",
       "135  0  0  0  1  0\n",
       "115  0  0  0  0  1\n",
       "131  0  0  0  0  1\n",
       "55   1  0  0  0  0\n",
       "95   0  1  0  0  0\n",
       "..  .. .. .. .. ..\n",
       "134  0  0  0  1  0\n",
       "160  0  1  0  0  0\n",
       "139  0  0  0  1  0\n",
       "78   0  0  1  0  0\n",
       "60   1  0  0  0  0\n",
       "\n",
       "[33 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = model.predict(test_features)\n",
    "predictions_df = pd.DataFrame(predictions, columns=['normal', 'collision_in_tool', 'collision_in_part', 'bottom_collision', 'bottom_obstruction'])\n",
    "display(predictions_df)\n",
    "display(test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
