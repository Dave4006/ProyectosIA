{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar Modulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import plotly.express as px\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import display\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importación de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>normal</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>normal</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normal</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>normal</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>normal</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>collision_in_tool</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>collision_in_tool</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>collision_in_tool</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>collision_in_tool</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>collision_in_tool</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                labels 1  2  3  4  5 \n",
       "0               normal               \n",
       "1               normal               \n",
       "2               normal               \n",
       "3               normal               \n",
       "4               normal               \n",
       "..                 ... .. .. .. .. ..\n",
       "159  collision_in_tool               \n",
       "160  collision_in_tool               \n",
       "161  collision_in_tool               \n",
       "162  collision_in_tool               \n",
       "163  collision_in_tool               \n",
       "\n",
       "[164 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[[ -2.,  -1.,  81.,   0.,  -5.,   0.],\n",
       "        [ -2.,  -1.,  79.,   0.,  -4.,   0.],\n",
       "        [ -2.,  -1.,  79.,   0.,  -4.,   0.],\n",
       "        ...,\n",
       "        [ -2.,  -1.,  78.,   0.,  -5.,   0.],\n",
       "        [ -3.,  -1.,  80.,   1.,  -4.,   1.],\n",
       "        [ -2.,  -1.,  79.,   0.,  -4.,   0.]],\n",
       "\n",
       "       [[  6.,  -1.,  79.,  -2.,   4.,  -3.],\n",
       "        [ 42.,  -3.,  80.,   5.,  53.,   3.],\n",
       "        [ -5.,   4.,  74., -15., -10.,  -1.],\n",
       "        ...,\n",
       "        [ -1.,  -5.,  80.,   6.,  -6.,   0.],\n",
       "        [ -4.,   5.,  78., -14.,  -9.,  -4.],\n",
       "        [ -4.,   1.,  80.,  -3., -12.,   5.]],\n",
       "\n",
       "       [[ -2.,  -6.,  85.,  14.,  -5.,   2.],\n",
       "        [  0.,   2.,  74.,  -7.,   1.,   0.],\n",
       "        [ -4.,  -5.,  76.,   7., -11.,   4.],\n",
       "        ...,\n",
       "        [  0.,  -9.,  87.,  13.,  -5.,   2.],\n",
       "        [ -5.,   5.,  67., -17., -16.,   7.],\n",
       "        [ -6., -10.,  86.,  16., -14.,  -1.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-12.,  17.,   3., -19., -10.,  -4.],\n",
       "        [-12.,  12.,  11., -13., -16.,  -4.],\n",
       "        [ -8.,   3.,   6.,   2., -11.,  -4.],\n",
       "        ...,\n",
       "        [  0.,   1.,   3.,   1.,   1.,  -3.],\n",
       "        [  1.,   2.,   9.,   0.,   3.,  -4.],\n",
       "        [  1.,   2.,   9.,   0.,   3.,  -4.]],\n",
       "\n",
       "       [[-41.,  21.,  -5., -23., -59.,  -4.],\n",
       "        [-32.,  21.,  -6., -25., -45.,  -4.],\n",
       "        [-21.,  12.,  -6., -14., -31.,  -4.],\n",
       "        ...,\n",
       "        [ -4.,   4.,   3.,   0.,  -1.,  -3.],\n",
       "        [ -4.,   3.,   2.,   2.,  -3.,  -3.],\n",
       "        [ -2.,   3.,   5.,   0.,  -2.,  -3.]],\n",
       "\n",
       "       [[  9., -10., -11.,  17.,   7.,  -4.],\n",
       "        [  5.,   0.,   4.,   0.,   7.,  -4.],\n",
       "        [ -3.,   6.,  -2.,  -8.,  -8.,  -4.],\n",
       "        ...,\n",
       "        [ -1.,   1.,  -3.,  -3.,  -2.,  -3.],\n",
       "        [  0.,  -1.,  -5.,  -1.,   1.,  -3.],\n",
       "        [ -1.,   1.,   4.,   0.,  -1.,  -3.]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = \"{:.3f}\".format\n",
    "\n",
    "data = np.loadtxt(\"lp5.csv\", delimiter=\",\", dtype=str)\n",
    "data_copy = data #va de 0 a 2623 o sea 2624 datos\n",
    "cont = 16\n",
    "labels = []\n",
    "numbers = []\n",
    "features= np.zeros((164,15,6))\n",
    "\n",
    "for i in range(len(data_copy)):\n",
    "    if(cont == 16):\n",
    "        labels.append(data_copy[i])\n",
    "    if(cont<16):\n",
    "        numbers.append(data_copy[i])\n",
    "    cont -= 1\n",
    "    if(cont == 0):\n",
    "        cont = 16\n",
    "        \n",
    "cont = 0\n",
    "for i in range(164):\n",
    "    for j in range(15):\n",
    "        for z in range(6):\n",
    "            features[i][j][z] = numbers[cont][z]\n",
    "        cont += 1\n",
    "        \n",
    "labels_df = pd.DataFrame(labels, columns=['labels','1','2','3','4','5'])\n",
    "#labels_df = labels_df.loc[:,['labels']]\n",
    "display(labels_df)\n",
    "display(features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manejo de Datos y Normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dave4\\AppData\\Local\\Temp\\ipykernel_23384\\1747463221.py:8: FutureWarning:\n",
      "\n",
      "In a future version of pandas all arguments of StringMethods.split except for the argument 'pat' will be keyword-only.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0.77660263, 0.78156702, 0.79084826, 0.77055903, 0.7684006 ,\n",
       "         0.77422836],\n",
       "        [0.77466005, 0.78739478, 0.78717893, 0.75156486, 0.7638679 ,\n",
       "         0.77206993],\n",
       "        [0.77401252, 0.78804231, 0.79041658, 0.74465789, 0.76106195,\n",
       "         0.77012735],\n",
       "        ...,\n",
       "        [0.78005612, 0.7804878 , 0.78437298, 0.78135118, 0.78113533,\n",
       "         0.78027196],\n",
       "        [0.78027196, 0.78091949, 0.77962443, 0.78091949, 0.78027196,\n",
       "         0.78027196],\n",
       "        [0.78027196, 0.78070365, 0.78286208, 0.78156702, 0.78091949,\n",
       "         0.78005612]],\n",
       "\n",
       "       [[0.78027196, 0.77940859, 0.79905029, 0.78372545, 0.77962443,\n",
       "         0.78113533],\n",
       "        [0.78070365, 0.78113533, 0.79667602, 0.77919275, 0.78091949,\n",
       "         0.78070365],\n",
       "        [0.77984028, 0.77962443, 0.79710771, 0.78221455, 0.77832938,\n",
       "         0.78156702],\n",
       "        ...,\n",
       "        [0.78070365, 0.77876106, 0.79948198, 0.78350961, 0.77962443,\n",
       "         0.78113533],\n",
       "        [0.77962443, 0.78178286, 0.79516512, 0.77703432, 0.77725016,\n",
       "         0.78221455],\n",
       "        [0.77940859, 0.77854522, 0.79926613, 0.78415713, 0.77768185,\n",
       "         0.7804878 ]],\n",
       "\n",
       "       [[0.78502051, 0.77725016, 0.78264623, 0.78631556, 0.78696309,\n",
       "         0.7804878 ],\n",
       "        [0.78588388, 0.78005612, 0.78717893, 0.78243039, 0.78890568,\n",
       "         0.77984028],\n",
       "        [0.78653141, 0.77876106, 0.78027196, 0.78480466, 0.78933736,\n",
       "         0.78027196],\n",
       "        ...,\n",
       "        [0.78005612, 0.78135118, 0.77962443, 0.7804878 , 0.77962443,\n",
       "         0.77962443],\n",
       "        [0.78005612, 0.78091949, 0.7789769 , 0.78091949, 0.78027196,\n",
       "         0.77962443],\n",
       "        [0.7804878 , 0.78091949, 0.78005612, 0.78156702, 0.78070365,\n",
       "         0.77962443]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.78005612, 0.78070365, 0.79689186, 0.77919275, 0.77660263,\n",
       "         0.77984028],\n",
       "        [0.77962443, 0.77832938, 0.79883445, 0.78307792, 0.77617095,\n",
       "         0.77811353],\n",
       "        [0.78005612, 0.78264623, 0.79516512, 0.77487589, 0.77681848,\n",
       "         0.7789769 ],\n",
       "        ...,\n",
       "        [0.7804878 , 0.77832938, 0.79969782, 0.78307792, 0.777466  ,\n",
       "         0.77854522],\n",
       "        [0.77940859, 0.77984028, 0.79710771, 0.77962443, 0.77573926,\n",
       "         0.77984028],\n",
       "        [0.77940859, 0.78243039, 0.79710771, 0.77530758, 0.77617095,\n",
       "         0.77940859]],\n",
       "\n",
       "       [[0.77077488, 0.79494928, 0.77617095, 0.75588172, 0.77832938,\n",
       "         0.7804878 ],\n",
       "        [0.7653788 , 0.78135118, 0.78243039, 0.777466  , 0.7638679 ,\n",
       "         0.78027196],\n",
       "        [0.76365206, 0.78264623, 0.78350961, 0.78005612, 0.75674509,\n",
       "         0.78027196],\n",
       "        ...,\n",
       "        [0.77984028, 0.78113533, 0.78243039, 0.78113533, 0.78005612,\n",
       "         0.78005612],\n",
       "        [0.78027196, 0.78113533, 0.78350961, 0.78091949, 0.78070365,\n",
       "         0.78027196],\n",
       "        [0.7804878 , 0.78091949, 0.78480466, 0.78221455, 0.78156702,\n",
       "         0.78005612]],\n",
       "\n",
       "       [[0.77789769, 0.77789769, 0.7744442 , 0.78696309, 0.78653141,\n",
       "         0.77789769],\n",
       "        [0.77832938, 0.77811353, 0.77422836, 0.78631556, 0.78868983,\n",
       "         0.7789769 ],\n",
       "        [0.77832938, 0.77789769, 0.77466005, 0.78696309, 0.78804231,\n",
       "         0.77768185],\n",
       "        ...,\n",
       "        [0.67882581, 0.70472696, 0.09842435, 0.7759551 , 0.85732787,\n",
       "         0.74940643],\n",
       "        [0.69933089, 0.73796676, 0.34448521, 0.77099072, 0.81674941,\n",
       "         0.77530758],\n",
       "        [0.72199439, 0.73170732, 0.7155191 , 0.81804446, 0.69156054,\n",
       "         0.77012735]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1  2  3  4  5\n",
       "84   0  0  1  0  0\n",
       "2    1  0  0  0  0\n",
       "94   0  1  0  0  0\n",
       "45   0  0  1  0  0\n",
       "42   0  0  1  0  0\n",
       "..  .. .. .. .. ..\n",
       "71   0  0  1  0  0\n",
       "106  0  0  0  1  0\n",
       "14   1  0  0  0  0\n",
       "92   0  1  0  0  0\n",
       "102  0  0  0  0  1\n",
       "\n",
       "[131 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes_dict = {'normal':'1 0 0 0 0', #1\n",
    "        'collision_in_tool':'0 1 0 0 0', #2\n",
    "        'collision_in_part':'0 0 1 0 0', #3\n",
    "        'bottom_collision':'0 0 0 1 0', #4\n",
    "        'bottom_obstruction':'0 0 0 0 1'} #5\n",
    "\n",
    "labels_df = labels_df.replace({'labels':classes_dict})\n",
    "labels_df[['1', '2', '3', '4', '5']] = labels_df['labels'].str.split(' ', 4, expand= True)\n",
    "labels_df = labels_df.loc[:,['1', '2', '3', '4', '5']]\n",
    "labels_df[['1', '2', '3', '4', '5']]=labels_df[['1', '2', '3', '4', '5']].astype(str).astype(int)\n",
    "\n",
    "def norm(x):\n",
    "    x_min = x.min()\n",
    "    x_max = x.max()\n",
    "    range = x_max - x_min  #min max entre 0 y 1\n",
    "    return((x-x_min)/(range))\n",
    "\n",
    "norm_features = norm(features)\n",
    "#split para entrenamiento y validacion\n",
    "train_features, test_features, train_labels, test_labels  = train_test_split(norm_features, labels_df, test_size=0.2, random_state= 42)\n",
    "display(train_features)\n",
    "display(train_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_model(learning_rate):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(8, (3,3), activation='relu', input_shape = (15,6,1), padding='same'), # #de feature maps, dimensiones del kernel, kernel entre más pequeño mejor y se prefiere un número impar\n",
    "        tf.keras.layers.Conv2D(8, (3,3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.MaxPooling2D((2,2), strides= 2, padding= 'valid'), # dimensiones del pooling\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Conv2D(16, (3,3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.Conv2D(16, (3,3), activation='relu', padding='same'),# #de feature maps, dimensiones del kernel, kernel entre más pequeño mejor y se prefiere un número impar\n",
    "        tf.keras.layers.MaxPooling2D((2,2), strides= 2, padding='valid'), # dimensiones del pooling\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(24, activation='relu'),\n",
    "        tf.keras.layers.Dense(5, activation='softmax')])\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate), loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "# input shape es 15 filas, 6 columnas y 1 canal de color\n",
    "#model = model = my_model(0.01)\n",
    "#model.summary()\n",
    "\n",
    "# initialize tuner to run the model.\n",
    "# using the Hyperband search algorithm\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, features, labels, epochs, batch_size):\n",
    "    history = model.fit(\n",
    "        x = features,\n",
    "        y = labels,\n",
    "        epochs= epochs,\n",
    "        batch_size= batch_size,\n",
    "        validation_split= 0.25\n",
    "    )\n",
    "    hist= pd.DataFrame(history.history) #se guardan los valores de errores y metricas en un diccionario\n",
    "    hist['epoch'] = history.epoch #los epochs se deben añadir aparte\n",
    "    return hist"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizaciones\n",
    "### Pasos para visualizar los filtros:\n",
    "##### 1. Iterar por todas las capas del modelo usando model.layers\n",
    "##### 2. Si la capa actual es de convolucion se extraen los pesos y sesgos usando get_weights()\n",
    "##### 3. Se normalizan los pesos de los filtros entre 0 y 1\n",
    "##### 4. Se plotean los filtros para cada capa convolutional y todos los canales de color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_curves(history):\n",
    "    hist = history\n",
    "    labels = {\"loss\":\"Training Loss\", \"val_loss\":\"Validation Loss\"}\n",
    "    hist.rename(columns = labels, inplace = True)\n",
    "    \n",
    "    fig = px.line(hist, x='epoch', y=['Training Loss', 'Validation Loss'],\n",
    "                title='Gráficas de Pérdida de Entrenamiento y Evaluación',\n",
    "                labels={\"epoch\": \"Epoch\", \"value\":\"Binary Cross Entropy\", \"variable\":\"Curvas de Pérdida\"},\n",
    "                color_discrete_map={ # replaces default color mapping by value\n",
    "                \"Training Loss\": \"#46039f\", \"Validation Loss\": \"#fb9f3a\"})\n",
    "    fig.update_layout(template='plotly_white')\n",
    "    fig.show()\n",
    "    \n",
    "def accuracy_curve(history):\n",
    "    hist = history\n",
    "    labels = {\"val_accuracy\":\"Exactitud de Validación\", \"accuracy\":\"Exactitud de Entrenamiento\"}\n",
    "    hist.rename(columns = labels, inplace = True)\n",
    "    \n",
    "    fig = px.line(hist, x='epoch', y=['Exactitud de Entrenamiento', 'Exactitud de Validación'],\n",
    "                title='Gráficas de Exactitud',\n",
    "                labels={\"epoch\": \"Epoch\", \"value\":\"Exactitud\", \"variable\":\"Curvas de Exactitud\"},\n",
    "                color_discrete_map={ # replaces default color mapping by value\n",
    "                \"Training Loss\": \"#46039f\", \"Validation Loss\": \"#fb9f3a\"})\n",
    "    fig.update_layout(template='plotly_white')\n",
    "    fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se corren las funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dave4\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\backend.py:5703: UserWarning:\n",
      "\n",
      "\"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 9ms/step - loss: 0.6813 - accuracy: 0.2449 - val_loss: 0.6649 - val_accuracy: 0.2727\n",
      "Epoch 2/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6338 - accuracy: 0.2347 - val_loss: 0.6034 - val_accuracy: 0.0606\n",
      "Epoch 3/275\n",
      " 1/20 [>.............................] - ETA: 0s - loss: 0.5658 - accuracy: 0.2000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dave4\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\backend.py:5703: UserWarning:\n",
      "\n",
      "\"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5656 - accuracy: 0.1939 - val_loss: 0.5441 - val_accuracy: 0.0606\n",
      "Epoch 4/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5229 - accuracy: 0.2041 - val_loss: 0.5221 - val_accuracy: 0.2727\n",
      "Epoch 5/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5126 - accuracy: 0.2959 - val_loss: 0.5129 - val_accuracy: 0.2727\n",
      "Epoch 6/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5139 - accuracy: 0.2857 - val_loss: 0.5077 - val_accuracy: 0.2727\n",
      "Epoch 7/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4981 - accuracy: 0.3061 - val_loss: 0.5007 - val_accuracy: 0.2727\n",
      "Epoch 8/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5006 - accuracy: 0.2755 - val_loss: 0.5018 - val_accuracy: 0.2727\n",
      "Epoch 9/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4978 - accuracy: 0.3265 - val_loss: 0.5001 - val_accuracy: 0.2727\n",
      "Epoch 10/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4985 - accuracy: 0.3061 - val_loss: 0.5009 - val_accuracy: 0.2727\n",
      "Epoch 11/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4880 - accuracy: 0.2959 - val_loss: 0.4958 - val_accuracy: 0.2727\n",
      "Epoch 12/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4998 - accuracy: 0.2857 - val_loss: 0.5020 - val_accuracy: 0.2727\n",
      "Epoch 13/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4866 - accuracy: 0.3061 - val_loss: 0.4945 - val_accuracy: 0.2727\n",
      "Epoch 14/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4940 - accuracy: 0.3571 - val_loss: 0.5017 - val_accuracy: 0.2727\n",
      "Epoch 15/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4964 - accuracy: 0.3265 - val_loss: 0.4963 - val_accuracy: 0.2727\n",
      "Epoch 16/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4970 - accuracy: 0.2959 - val_loss: 0.4946 - val_accuracy: 0.2727\n",
      "Epoch 17/275\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4931 - accuracy: 0.3163 - val_loss: 0.4967 - val_accuracy: 0.2727\n",
      "Epoch 18/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4905 - accuracy: 0.3061 - val_loss: 0.4949 - val_accuracy: 0.2727\n",
      "Epoch 19/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4971 - accuracy: 0.2653 - val_loss: 0.4943 - val_accuracy: 0.2727\n",
      "Epoch 20/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4836 - accuracy: 0.3469 - val_loss: 0.4949 - val_accuracy: 0.2727\n",
      "Epoch 21/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4930 - accuracy: 0.3061 - val_loss: 0.4934 - val_accuracy: 0.2727\n",
      "Epoch 22/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4924 - accuracy: 0.3061 - val_loss: 0.4930 - val_accuracy: 0.2727\n",
      "Epoch 23/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4906 - accuracy: 0.3061 - val_loss: 0.4929 - val_accuracy: 0.2727\n",
      "Epoch 24/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4939 - accuracy: 0.3061 - val_loss: 0.4936 - val_accuracy: 0.2727\n",
      "Epoch 25/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4975 - accuracy: 0.2755 - val_loss: 0.4930 - val_accuracy: 0.2727\n",
      "Epoch 26/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4985 - accuracy: 0.3163 - val_loss: 0.4955 - val_accuracy: 0.2727\n",
      "Epoch 27/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4864 - accuracy: 0.3673 - val_loss: 0.4904 - val_accuracy: 0.2727\n",
      "Epoch 28/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4879 - accuracy: 0.3571 - val_loss: 0.4933 - val_accuracy: 0.2727\n",
      "Epoch 29/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4856 - accuracy: 0.3061 - val_loss: 0.4939 - val_accuracy: 0.2727\n",
      "Epoch 30/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4977 - accuracy: 0.3265 - val_loss: 0.4977 - val_accuracy: 0.2727\n",
      "Epoch 31/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4895 - accuracy: 0.2959 - val_loss: 0.4940 - val_accuracy: 0.2727\n",
      "Epoch 32/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4929 - accuracy: 0.3265 - val_loss: 0.4932 - val_accuracy: 0.2727\n",
      "Epoch 33/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4899 - accuracy: 0.2857 - val_loss: 0.4904 - val_accuracy: 0.2727\n",
      "Epoch 34/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4881 - accuracy: 0.3163 - val_loss: 0.4924 - val_accuracy: 0.2727\n",
      "Epoch 35/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4891 - accuracy: 0.3061 - val_loss: 0.4933 - val_accuracy: 0.2727\n",
      "Epoch 36/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4857 - accuracy: 0.3469 - val_loss: 0.4911 - val_accuracy: 0.2727\n",
      "Epoch 37/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4928 - accuracy: 0.2551 - val_loss: 0.4917 - val_accuracy: 0.2727\n",
      "Epoch 38/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4879 - accuracy: 0.2653 - val_loss: 0.4943 - val_accuracy: 0.2727\n",
      "Epoch 39/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4888 - accuracy: 0.2449 - val_loss: 0.4867 - val_accuracy: 0.2727\n",
      "Epoch 40/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4857 - accuracy: 0.3163 - val_loss: 0.4881 - val_accuracy: 0.2727\n",
      "Epoch 41/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.3061 - val_loss: 0.4820 - val_accuracy: 0.2727\n",
      "Epoch 42/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4806 - accuracy: 0.3469 - val_loss: 0.4921 - val_accuracy: 0.3333\n",
      "Epoch 43/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4734 - accuracy: 0.3776 - val_loss: 0.4770 - val_accuracy: 0.3030\n",
      "Epoch 44/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4629 - accuracy: 0.3265 - val_loss: 0.4677 - val_accuracy: 0.3333\n",
      "Epoch 45/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.3980 - val_loss: 0.4662 - val_accuracy: 0.3333\n",
      "Epoch 46/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.4388 - val_loss: 0.4513 - val_accuracy: 0.3333\n",
      "Epoch 47/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.4184 - val_loss: 0.4431 - val_accuracy: 0.3333\n",
      "Epoch 48/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4166 - accuracy: 0.4184 - val_loss: 0.4381 - val_accuracy: 0.3333\n",
      "Epoch 49/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4141 - accuracy: 0.4286 - val_loss: 0.4425 - val_accuracy: 0.3333\n",
      "Epoch 50/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4094 - accuracy: 0.4082 - val_loss: 0.4305 - val_accuracy: 0.3333\n",
      "Epoch 51/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4054 - accuracy: 0.4388 - val_loss: 0.4463 - val_accuracy: 0.3333\n",
      "Epoch 52/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3996 - accuracy: 0.4082 - val_loss: 0.4438 - val_accuracy: 0.3333\n",
      "Epoch 53/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4120 - accuracy: 0.4490 - val_loss: 0.4291 - val_accuracy: 0.3333\n",
      "Epoch 54/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4031 - accuracy: 0.4286 - val_loss: 0.4276 - val_accuracy: 0.3333\n",
      "Epoch 55/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4055 - accuracy: 0.4490 - val_loss: 0.4205 - val_accuracy: 0.3333\n",
      "Epoch 56/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3958 - accuracy: 0.4388 - val_loss: 0.4550 - val_accuracy: 0.3939\n",
      "Epoch 57/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4010 - accuracy: 0.3878 - val_loss: 0.4364 - val_accuracy: 0.3333\n",
      "Epoch 58/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4058 - accuracy: 0.4592 - val_loss: 0.4266 - val_accuracy: 0.3333\n",
      "Epoch 59/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4079 - accuracy: 0.4082 - val_loss: 0.4255 - val_accuracy: 0.3333\n",
      "Epoch 60/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3965 - accuracy: 0.4388 - val_loss: 0.4437 - val_accuracy: 0.3333\n",
      "Epoch 61/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.4082 - val_loss: 0.4400 - val_accuracy: 0.3333\n",
      "Epoch 62/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3847 - accuracy: 0.4694 - val_loss: 0.4276 - val_accuracy: 0.3333\n",
      "Epoch 63/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4035 - accuracy: 0.4388 - val_loss: 0.4342 - val_accuracy: 0.3333\n",
      "Epoch 64/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3904 - accuracy: 0.4490 - val_loss: 0.4291 - val_accuracy: 0.3333\n",
      "Epoch 65/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3842 - accuracy: 0.4592 - val_loss: 0.4320 - val_accuracy: 0.3333\n",
      "Epoch 66/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3893 - accuracy: 0.4796 - val_loss: 0.4344 - val_accuracy: 0.3333\n",
      "Epoch 67/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4053 - accuracy: 0.4796 - val_loss: 0.4333 - val_accuracy: 0.3333\n",
      "Epoch 68/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3939 - accuracy: 0.4286 - val_loss: 0.4269 - val_accuracy: 0.3333\n",
      "Epoch 69/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.4082 - val_loss: 0.4225 - val_accuracy: 0.3333\n",
      "Epoch 70/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3938 - accuracy: 0.4490 - val_loss: 0.4328 - val_accuracy: 0.3333\n",
      "Epoch 71/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3978 - accuracy: 0.4184 - val_loss: 0.4159 - val_accuracy: 0.3333\n",
      "Epoch 72/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3895 - accuracy: 0.4592 - val_loss: 0.4663 - val_accuracy: 0.3939\n",
      "Epoch 73/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4050 - accuracy: 0.4490 - val_loss: 0.4205 - val_accuracy: 0.3333\n",
      "Epoch 74/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3995 - accuracy: 0.4388 - val_loss: 0.4373 - val_accuracy: 0.3333\n",
      "Epoch 75/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3965 - accuracy: 0.4490 - val_loss: 0.4309 - val_accuracy: 0.3636\n",
      "Epoch 76/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3849 - accuracy: 0.4592 - val_loss: 0.4144 - val_accuracy: 0.3333\n",
      "Epoch 77/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3883 - accuracy: 0.5000 - val_loss: 0.4330 - val_accuracy: 0.3939\n",
      "Epoch 78/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3674 - accuracy: 0.4898 - val_loss: 0.4134 - val_accuracy: 0.3333\n",
      "Epoch 79/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3816 - accuracy: 0.4694 - val_loss: 0.4095 - val_accuracy: 0.3939\n",
      "Epoch 80/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3857 - accuracy: 0.4490 - val_loss: 0.4108 - val_accuracy: 0.3333\n",
      "Epoch 81/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3743 - accuracy: 0.4898 - val_loss: 0.4059 - val_accuracy: 0.3939\n",
      "Epoch 82/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3779 - accuracy: 0.5000 - val_loss: 0.3979 - val_accuracy: 0.3939\n",
      "Epoch 83/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3768 - accuracy: 0.4694 - val_loss: 0.4057 - val_accuracy: 0.3636\n",
      "Epoch 84/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.4388 - val_loss: 0.4143 - val_accuracy: 0.3636\n",
      "Epoch 85/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3783 - accuracy: 0.5000 - val_loss: 0.3977 - val_accuracy: 0.3636\n",
      "Epoch 86/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3785 - accuracy: 0.4592 - val_loss: 0.4075 - val_accuracy: 0.3939\n",
      "Epoch 87/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3661 - accuracy: 0.4694 - val_loss: 0.4074 - val_accuracy: 0.3939\n",
      "Epoch 88/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3725 - accuracy: 0.4898 - val_loss: 0.3971 - val_accuracy: 0.3636\n",
      "Epoch 89/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3899 - accuracy: 0.4592 - val_loss: 0.4101 - val_accuracy: 0.3939\n",
      "Epoch 90/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3856 - accuracy: 0.4898 - val_loss: 0.4104 - val_accuracy: 0.3939\n",
      "Epoch 91/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3673 - accuracy: 0.4592 - val_loss: 0.3708 - val_accuracy: 0.3939\n",
      "Epoch 92/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3677 - accuracy: 0.5102 - val_loss: 0.3810 - val_accuracy: 0.4242\n",
      "Epoch 93/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3569 - accuracy: 0.4592 - val_loss: 0.3818 - val_accuracy: 0.4848\n",
      "Epoch 94/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3598 - accuracy: 0.5102 - val_loss: 0.3848 - val_accuracy: 0.4242\n",
      "Epoch 95/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3636 - accuracy: 0.5102 - val_loss: 0.4146 - val_accuracy: 0.4848\n",
      "Epoch 96/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3808 - accuracy: 0.4592 - val_loss: 0.3672 - val_accuracy: 0.4545\n",
      "Epoch 97/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3530 - accuracy: 0.4796 - val_loss: 0.3915 - val_accuracy: 0.4242\n",
      "Epoch 98/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3522 - accuracy: 0.4796 - val_loss: 0.3568 - val_accuracy: 0.5152\n",
      "Epoch 99/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3565 - accuracy: 0.5816 - val_loss: 0.4255 - val_accuracy: 0.4848\n",
      "Epoch 100/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3714 - accuracy: 0.5204 - val_loss: 0.4031 - val_accuracy: 0.3939\n",
      "Epoch 101/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3642 - accuracy: 0.4592 - val_loss: 0.3772 - val_accuracy: 0.4242\n",
      "Epoch 102/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3709 - accuracy: 0.4694 - val_loss: 0.3751 - val_accuracy: 0.4242\n",
      "Epoch 103/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3592 - accuracy: 0.5102 - val_loss: 0.3882 - val_accuracy: 0.3939\n",
      "Epoch 104/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3485 - accuracy: 0.4898 - val_loss: 0.3762 - val_accuracy: 0.4242\n",
      "Epoch 105/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3556 - accuracy: 0.5510 - val_loss: 0.3784 - val_accuracy: 0.4545\n",
      "Epoch 106/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3442 - accuracy: 0.5204 - val_loss: 0.3520 - val_accuracy: 0.4545\n",
      "Epoch 107/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3559 - accuracy: 0.4796 - val_loss: 0.3801 - val_accuracy: 0.4848\n",
      "Epoch 108/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3350 - accuracy: 0.5510 - val_loss: 0.3516 - val_accuracy: 0.4545\n",
      "Epoch 109/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3487 - accuracy: 0.4286 - val_loss: 0.3407 - val_accuracy: 0.5455\n",
      "Epoch 110/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3527 - accuracy: 0.4592 - val_loss: 0.3539 - val_accuracy: 0.5152\n",
      "Epoch 111/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3373 - accuracy: 0.5816 - val_loss: 0.3658 - val_accuracy: 0.5455\n",
      "Epoch 112/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3347 - accuracy: 0.5408 - val_loss: 0.3949 - val_accuracy: 0.4848\n",
      "Epoch 113/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3588 - accuracy: 0.5510 - val_loss: 0.3706 - val_accuracy: 0.4545\n",
      "Epoch 114/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3405 - accuracy: 0.5306 - val_loss: 0.3682 - val_accuracy: 0.4848\n",
      "Epoch 115/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3382 - accuracy: 0.5510 - val_loss: 0.3571 - val_accuracy: 0.4848\n",
      "Epoch 116/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3409 - accuracy: 0.4898 - val_loss: 0.3434 - val_accuracy: 0.5758\n",
      "Epoch 117/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3545 - accuracy: 0.4694 - val_loss: 0.3639 - val_accuracy: 0.4242\n",
      "Epoch 118/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3473 - accuracy: 0.5408 - val_loss: 0.3429 - val_accuracy: 0.4848\n",
      "Epoch 119/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3481 - accuracy: 0.5714 - val_loss: 0.3690 - val_accuracy: 0.4848\n",
      "Epoch 120/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3320 - accuracy: 0.5306 - val_loss: 0.3458 - val_accuracy: 0.5758\n",
      "Epoch 121/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3427 - accuracy: 0.5306 - val_loss: 0.3224 - val_accuracy: 0.6970\n",
      "Epoch 122/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3323 - accuracy: 0.6122 - val_loss: 0.3375 - val_accuracy: 0.7273\n",
      "Epoch 123/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3488 - accuracy: 0.5306 - val_loss: 0.3536 - val_accuracy: 0.5152\n",
      "Epoch 124/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3317 - accuracy: 0.5918 - val_loss: 0.3295 - val_accuracy: 0.6061\n",
      "Epoch 125/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3388 - accuracy: 0.5510 - val_loss: 0.3316 - val_accuracy: 0.5455\n",
      "Epoch 126/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3335 - accuracy: 0.5102 - val_loss: 0.3349 - val_accuracy: 0.5455\n",
      "Epoch 127/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3279 - accuracy: 0.5612 - val_loss: 0.3251 - val_accuracy: 0.6061\n",
      "Epoch 128/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3384 - accuracy: 0.5408 - val_loss: 0.3438 - val_accuracy: 0.4848\n",
      "Epoch 129/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3414 - accuracy: 0.5408 - val_loss: 0.3418 - val_accuracy: 0.5455\n",
      "Epoch 130/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3278 - accuracy: 0.5102 - val_loss: 0.3174 - val_accuracy: 0.5152\n",
      "Epoch 131/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3324 - accuracy: 0.5204 - val_loss: 0.3437 - val_accuracy: 0.5455\n",
      "Epoch 132/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3225 - accuracy: 0.5612 - val_loss: 0.3323 - val_accuracy: 0.7273\n",
      "Epoch 133/275\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3277 - accuracy: 0.5612 - val_loss: 0.3214 - val_accuracy: 0.5758\n",
      "Epoch 134/275\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3324 - accuracy: 0.5000 - val_loss: 0.3208 - val_accuracy: 0.5758\n",
      "Epoch 135/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3236 - accuracy: 0.5918 - val_loss: 0.3133 - val_accuracy: 0.6364\n",
      "Epoch 136/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3299 - accuracy: 0.5510 - val_loss: 0.3148 - val_accuracy: 0.6061\n",
      "Epoch 137/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3232 - accuracy: 0.5306 - val_loss: 0.3386 - val_accuracy: 0.5152\n",
      "Epoch 138/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3245 - accuracy: 0.6122 - val_loss: 0.3175 - val_accuracy: 0.6061\n",
      "Epoch 139/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3463 - accuracy: 0.5102 - val_loss: 0.3067 - val_accuracy: 0.6364\n",
      "Epoch 140/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3285 - accuracy: 0.5714 - val_loss: 0.3256 - val_accuracy: 0.7576\n",
      "Epoch 141/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3372 - accuracy: 0.5510 - val_loss: 0.3217 - val_accuracy: 0.6970\n",
      "Epoch 142/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3250 - accuracy: 0.5102 - val_loss: 0.3246 - val_accuracy: 0.5758\n",
      "Epoch 143/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3378 - accuracy: 0.5306 - val_loss: 0.3271 - val_accuracy: 0.4848\n",
      "Epoch 144/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3240 - accuracy: 0.6020 - val_loss: 0.3336 - val_accuracy: 0.6667\n",
      "Epoch 145/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3232 - accuracy: 0.6531 - val_loss: 0.3638 - val_accuracy: 0.6364\n",
      "Epoch 146/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3226 - accuracy: 0.6020 - val_loss: 0.3582 - val_accuracy: 0.4848\n",
      "Epoch 147/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3361 - accuracy: 0.5510 - val_loss: 0.3155 - val_accuracy: 0.7576\n",
      "Epoch 148/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3160 - accuracy: 0.6429 - val_loss: 0.3171 - val_accuracy: 0.5758\n",
      "Epoch 149/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3271 - accuracy: 0.6020 - val_loss: 0.3063 - val_accuracy: 0.6667\n",
      "Epoch 150/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3195 - accuracy: 0.6327 - val_loss: 0.3065 - val_accuracy: 0.6061\n",
      "Epoch 151/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3186 - accuracy: 0.6020 - val_loss: 0.3114 - val_accuracy: 0.7273\n",
      "Epoch 152/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3214 - accuracy: 0.6224 - val_loss: 0.3115 - val_accuracy: 0.7576\n",
      "Epoch 153/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3276 - accuracy: 0.5714 - val_loss: 0.3221 - val_accuracy: 0.5758\n",
      "Epoch 154/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3168 - accuracy: 0.5714 - val_loss: 0.3176 - val_accuracy: 0.5758\n",
      "Epoch 155/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3185 - accuracy: 0.5918 - val_loss: 0.3070 - val_accuracy: 0.6970\n",
      "Epoch 156/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3203 - accuracy: 0.5714 - val_loss: 0.3067 - val_accuracy: 0.6667\n",
      "Epoch 157/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3105 - accuracy: 0.6224 - val_loss: 0.3424 - val_accuracy: 0.5455\n",
      "Epoch 158/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3224 - accuracy: 0.5714 - val_loss: 0.3004 - val_accuracy: 0.6061\n",
      "Epoch 159/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3103 - accuracy: 0.6327 - val_loss: 0.2990 - val_accuracy: 0.6061\n",
      "Epoch 160/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3232 - accuracy: 0.6020 - val_loss: 0.3273 - val_accuracy: 0.5758\n",
      "Epoch 161/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3078 - accuracy: 0.6531 - val_loss: 0.3060 - val_accuracy: 0.6667\n",
      "Epoch 162/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3180 - accuracy: 0.6429 - val_loss: 0.2959 - val_accuracy: 0.6970\n",
      "Epoch 163/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3053 - accuracy: 0.6020 - val_loss: 0.3022 - val_accuracy: 0.5455\n",
      "Epoch 164/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3206 - accuracy: 0.5714 - val_loss: 0.2920 - val_accuracy: 0.6970\n",
      "Epoch 165/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3131 - accuracy: 0.6429 - val_loss: 0.2990 - val_accuracy: 0.6364\n",
      "Epoch 166/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3107 - accuracy: 0.6122 - val_loss: 0.3012 - val_accuracy: 0.6970\n",
      "Epoch 167/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3084 - accuracy: 0.6122 - val_loss: 0.2815 - val_accuracy: 0.7576\n",
      "Epoch 168/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3152 - accuracy: 0.6327 - val_loss: 0.3984 - val_accuracy: 0.7273\n",
      "Epoch 169/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3178 - accuracy: 0.6020 - val_loss: 0.3341 - val_accuracy: 0.5758\n",
      "Epoch 170/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3234 - accuracy: 0.5612 - val_loss: 0.2827 - val_accuracy: 0.7273\n",
      "Epoch 171/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3060 - accuracy: 0.6224 - val_loss: 0.3020 - val_accuracy: 0.7273\n",
      "Epoch 172/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3162 - accuracy: 0.6224 - val_loss: 0.3023 - val_accuracy: 0.7273\n",
      "Epoch 173/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3111 - accuracy: 0.6122 - val_loss: 0.2808 - val_accuracy: 0.7576\n",
      "Epoch 174/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3004 - accuracy: 0.6429 - val_loss: 0.2845 - val_accuracy: 0.7879\n",
      "Epoch 175/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3065 - accuracy: 0.6327 - val_loss: 0.2888 - val_accuracy: 0.6667\n",
      "Epoch 176/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2925 - accuracy: 0.7041 - val_loss: 0.2715 - val_accuracy: 0.7273\n",
      "Epoch 177/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2997 - accuracy: 0.6429 - val_loss: 0.5974 - val_accuracy: 0.6364\n",
      "Epoch 178/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3453 - accuracy: 0.5816 - val_loss: 0.3038 - val_accuracy: 0.7576\n",
      "Epoch 179/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3047 - accuracy: 0.5918 - val_loss: 0.2783 - val_accuracy: 0.7273\n",
      "Epoch 180/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3042 - accuracy: 0.6224 - val_loss: 0.2818 - val_accuracy: 0.6970\n",
      "Epoch 181/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3118 - accuracy: 0.5612 - val_loss: 0.2806 - val_accuracy: 0.7576\n",
      "Epoch 182/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2996 - accuracy: 0.6633 - val_loss: 0.2856 - val_accuracy: 0.7273\n",
      "Epoch 183/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2997 - accuracy: 0.6327 - val_loss: 0.2904 - val_accuracy: 0.6667\n",
      "Epoch 184/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2960 - accuracy: 0.6429 - val_loss: 0.2712 - val_accuracy: 0.7879\n",
      "Epoch 185/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3062 - accuracy: 0.6429 - val_loss: 0.2840 - val_accuracy: 0.6667\n",
      "Epoch 186/275\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3035 - accuracy: 0.6531 - val_loss: 0.2871 - val_accuracy: 0.7576\n",
      "Epoch 187/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3040 - accuracy: 0.6224 - val_loss: 0.2877 - val_accuracy: 0.6364\n",
      "Epoch 188/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2976 - accuracy: 0.6327 - val_loss: 0.2847 - val_accuracy: 0.6970\n",
      "Epoch 189/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2817 - accuracy: 0.6735 - val_loss: 0.2783 - val_accuracy: 0.7273\n",
      "Epoch 190/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2975 - accuracy: 0.6531 - val_loss: 0.2708 - val_accuracy: 0.7273\n",
      "Epoch 191/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2863 - accuracy: 0.6633 - val_loss: 0.2728 - val_accuracy: 0.7273\n",
      "Epoch 192/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2840 - accuracy: 0.6735 - val_loss: 0.2675 - val_accuracy: 0.6970\n",
      "Epoch 193/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2852 - accuracy: 0.6837 - val_loss: 0.2680 - val_accuracy: 0.7273\n",
      "Epoch 194/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2950 - accuracy: 0.6633 - val_loss: 0.2760 - val_accuracy: 0.6970\n",
      "Epoch 195/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2826 - accuracy: 0.6837 - val_loss: 0.2753 - val_accuracy: 0.6970\n",
      "Epoch 196/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2997 - accuracy: 0.6327 - val_loss: 0.2894 - val_accuracy: 0.6667\n",
      "Epoch 197/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2855 - accuracy: 0.6735 - val_loss: 0.2654 - val_accuracy: 0.7273\n",
      "Epoch 198/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2866 - accuracy: 0.6735 - val_loss: 0.2553 - val_accuracy: 0.7576\n",
      "Epoch 199/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2942 - accuracy: 0.6327 - val_loss: 0.2567 - val_accuracy: 0.7273\n",
      "Epoch 200/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2868 - accuracy: 0.6429 - val_loss: 0.2644 - val_accuracy: 0.6970\n",
      "Epoch 201/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2891 - accuracy: 0.6735 - val_loss: 0.2632 - val_accuracy: 0.7576\n",
      "Epoch 202/275\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.2814 - accuracy: 0.6735 - val_loss: 0.2506 - val_accuracy: 0.7576\n",
      "Epoch 203/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2916 - accuracy: 0.6633 - val_loss: 0.2520 - val_accuracy: 0.7879\n",
      "Epoch 204/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2868 - accuracy: 0.6224 - val_loss: 0.2591 - val_accuracy: 0.7273\n",
      "Epoch 205/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2873 - accuracy: 0.6633 - val_loss: 0.2493 - val_accuracy: 0.7576\n",
      "Epoch 206/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2915 - accuracy: 0.6429 - val_loss: 0.2548 - val_accuracy: 0.7879\n",
      "Epoch 207/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2817 - accuracy: 0.6735 - val_loss: 0.2591 - val_accuracy: 0.6970\n",
      "Epoch 208/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2779 - accuracy: 0.6633 - val_loss: 0.2404 - val_accuracy: 0.7576\n",
      "Epoch 209/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2998 - accuracy: 0.6531 - val_loss: 0.2490 - val_accuracy: 0.7879\n",
      "Epoch 210/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2881 - accuracy: 0.6531 - val_loss: 0.2588 - val_accuracy: 0.7273\n",
      "Epoch 211/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2874 - accuracy: 0.6633 - val_loss: 0.2572 - val_accuracy: 0.7273\n",
      "Epoch 212/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2790 - accuracy: 0.6429 - val_loss: 0.2486 - val_accuracy: 0.7273\n",
      "Epoch 213/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2919 - accuracy: 0.6122 - val_loss: 0.2585 - val_accuracy: 0.7273\n",
      "Epoch 214/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2727 - accuracy: 0.6939 - val_loss: 0.2518 - val_accuracy: 0.7273\n",
      "Epoch 215/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2675 - accuracy: 0.6939 - val_loss: 0.2455 - val_accuracy: 0.7879\n",
      "Epoch 216/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2914 - accuracy: 0.6633 - val_loss: 0.2559 - val_accuracy: 0.7273\n",
      "Epoch 217/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2906 - accuracy: 0.6531 - val_loss: 0.2602 - val_accuracy: 0.6970\n",
      "Epoch 218/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2946 - accuracy: 0.6020 - val_loss: 0.2688 - val_accuracy: 0.6364\n",
      "Epoch 219/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2827 - accuracy: 0.6429 - val_loss: 0.2408 - val_accuracy: 0.7576\n",
      "Epoch 220/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2796 - accuracy: 0.6735 - val_loss: 0.2395 - val_accuracy: 0.7273\n",
      "Epoch 221/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2756 - accuracy: 0.6633 - val_loss: 0.2376 - val_accuracy: 0.7273\n",
      "Epoch 222/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2781 - accuracy: 0.6735 - val_loss: 0.2383 - val_accuracy: 0.7273\n",
      "Epoch 223/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2756 - accuracy: 0.6939 - val_loss: 0.2384 - val_accuracy: 0.7576\n",
      "Epoch 224/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2723 - accuracy: 0.6735 - val_loss: 0.2414 - val_accuracy: 0.7273\n",
      "Epoch 225/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2706 - accuracy: 0.6939 - val_loss: 0.2375 - val_accuracy: 0.7879\n",
      "Epoch 226/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2745 - accuracy: 0.6735 - val_loss: 0.2398 - val_accuracy: 0.7273\n",
      "Epoch 227/275\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.2680 - accuracy: 0.6939 - val_loss: 0.2472 - val_accuracy: 0.6970\n",
      "Epoch 228/275\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.2695 - accuracy: 0.6939 - val_loss: 0.2308 - val_accuracy: 0.7879\n",
      "Epoch 229/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2724 - accuracy: 0.6837 - val_loss: 0.2283 - val_accuracy: 0.7273\n",
      "Epoch 230/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2740 - accuracy: 0.6837 - val_loss: 0.2520 - val_accuracy: 0.6970\n",
      "Epoch 231/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2813 - accuracy: 0.6837 - val_loss: 0.4863 - val_accuracy: 0.7273\n",
      "Epoch 232/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3301 - accuracy: 0.6122 - val_loss: 0.2407 - val_accuracy: 0.7576\n",
      "Epoch 233/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2792 - accuracy: 0.6633 - val_loss: 0.2403 - val_accuracy: 0.7273\n",
      "Epoch 234/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3003 - accuracy: 0.5918 - val_loss: 0.2773 - val_accuracy: 0.5758\n",
      "Epoch 235/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3033 - accuracy: 0.5918 - val_loss: 0.2622 - val_accuracy: 0.7273\n",
      "Epoch 236/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2865 - accuracy: 0.6735 - val_loss: 0.2544 - val_accuracy: 0.7273\n",
      "Epoch 237/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2765 - accuracy: 0.6633 - val_loss: 0.2525 - val_accuracy: 0.7273\n",
      "Epoch 238/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2695 - accuracy: 0.6735 - val_loss: 0.2386 - val_accuracy: 0.7273\n",
      "Epoch 239/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2771 - accuracy: 0.6837 - val_loss: 0.2441 - val_accuracy: 0.7273\n",
      "Epoch 240/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2874 - accuracy: 0.6531 - val_loss: 0.2411 - val_accuracy: 0.7273\n",
      "Epoch 241/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2665 - accuracy: 0.6837 - val_loss: 0.2358 - val_accuracy: 0.7273\n",
      "Epoch 242/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2598 - accuracy: 0.6939 - val_loss: 0.2389 - val_accuracy: 0.7273\n",
      "Epoch 243/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2877 - accuracy: 0.6327 - val_loss: 0.2445 - val_accuracy: 0.7273\n",
      "Epoch 244/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2697 - accuracy: 0.6633 - val_loss: 0.2403 - val_accuracy: 0.7273\n",
      "Epoch 245/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2615 - accuracy: 0.6735 - val_loss: 0.2457 - val_accuracy: 0.7273\n",
      "Epoch 246/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2769 - accuracy: 0.6939 - val_loss: 0.2299 - val_accuracy: 0.7879\n",
      "Epoch 247/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2778 - accuracy: 0.6837 - val_loss: 0.2473 - val_accuracy: 0.7273\n",
      "Epoch 248/275\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.2633 - accuracy: 0.7041 - val_loss: 0.2289 - val_accuracy: 0.7273\n",
      "Epoch 249/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2675 - accuracy: 0.7041 - val_loss: 0.2490 - val_accuracy: 0.7273\n",
      "Epoch 250/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2688 - accuracy: 0.7143 - val_loss: 0.2300 - val_accuracy: 0.7879\n",
      "Epoch 251/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2842 - accuracy: 0.6735 - val_loss: 0.2346 - val_accuracy: 0.7273\n",
      "Epoch 252/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2604 - accuracy: 0.6837 - val_loss: 0.2406 - val_accuracy: 0.7273\n",
      "Epoch 253/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2747 - accuracy: 0.6735 - val_loss: 0.2542 - val_accuracy: 0.6970\n",
      "Epoch 254/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2724 - accuracy: 0.6837 - val_loss: 0.2333 - val_accuracy: 0.7273\n",
      "Epoch 255/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2784 - accuracy: 0.6735 - val_loss: 0.2337 - val_accuracy: 0.7273\n",
      "Epoch 256/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3054 - accuracy: 0.6327 - val_loss: 0.2448 - val_accuracy: 0.7273\n",
      "Epoch 257/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2744 - accuracy: 0.7041 - val_loss: 0.2358 - val_accuracy: 0.7273\n",
      "Epoch 258/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2664 - accuracy: 0.6939 - val_loss: 0.2391 - val_accuracy: 0.7273\n",
      "Epoch 259/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2593 - accuracy: 0.7143 - val_loss: 0.2406 - val_accuracy: 0.7273\n",
      "Epoch 260/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2680 - accuracy: 0.6837 - val_loss: 0.2300 - val_accuracy: 0.7273\n",
      "Epoch 261/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2652 - accuracy: 0.6939 - val_loss: 0.2327 - val_accuracy: 0.7273\n",
      "Epoch 262/275\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3135 - accuracy: 0.6429 - val_loss: 0.3471 - val_accuracy: 0.6970\n",
      "Epoch 263/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2652 - accuracy: 0.6939 - val_loss: 0.2719 - val_accuracy: 0.6061\n",
      "Epoch 264/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2758 - accuracy: 0.6939 - val_loss: 0.2546 - val_accuracy: 0.7273\n",
      "Epoch 265/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2862 - accuracy: 0.6429 - val_loss: 0.2622 - val_accuracy: 0.6667\n",
      "Epoch 266/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2877 - accuracy: 0.6429 - val_loss: 0.2491 - val_accuracy: 0.6970\n",
      "Epoch 267/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2607 - accuracy: 0.6633 - val_loss: 0.2397 - val_accuracy: 0.7273\n",
      "Epoch 268/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2616 - accuracy: 0.7143 - val_loss: 0.2391 - val_accuracy: 0.7273\n",
      "Epoch 269/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2668 - accuracy: 0.6633 - val_loss: 0.2230 - val_accuracy: 0.7576\n",
      "Epoch 270/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2616 - accuracy: 0.7143 - val_loss: 0.2365 - val_accuracy: 0.7273\n",
      "Epoch 271/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2722 - accuracy: 0.6837 - val_loss: 0.2354 - val_accuracy: 0.7576\n",
      "Epoch 272/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2733 - accuracy: 0.6939 - val_loss: 0.2431 - val_accuracy: 0.7273\n",
      "Epoch 273/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2734 - accuracy: 0.6837 - val_loss: 0.2421 - val_accuracy: 0.7273\n",
      "Epoch 274/275\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2726 - accuracy: 0.6939 - val_loss: 0.2270 - val_accuracy: 0.7273\n",
      "Epoch 275/275\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.2597 - accuracy: 0.7041 - val_loss: 0.2185 - val_accuracy: 0.7576\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.681</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.634</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.061</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.566</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.061</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.523</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.273</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.513</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.273</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>0.272</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.758</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>0.273</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.727</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>0.273</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.727</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>0.273</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.727</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>0.260</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.758</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>275 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     loss  accuracy  val_loss  val_accuracy  epoch\n",
       "0   0.681     0.245     0.665         0.273      0\n",
       "1   0.634     0.235     0.603         0.061      1\n",
       "2   0.566     0.194     0.544         0.061      2\n",
       "3   0.523     0.204     0.522         0.273      3\n",
       "4   0.513     0.296     0.513         0.273      4\n",
       "..    ...       ...       ...           ...    ...\n",
       "270 0.272     0.684     0.235         0.758    270\n",
       "271 0.273     0.694     0.243         0.727    271\n",
       "272 0.273     0.684     0.242         0.727    272\n",
       "273 0.273     0.694     0.227         0.727    273\n",
       "274 0.260     0.704     0.219         0.758    274\n",
       "\n",
       "[275 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Curvas de Pérdida=Training Loss<br>Epoch=%{x}<br>Binary Cross Entropy=%{y}<extra></extra>",
         "legendgroup": "Training Loss",
         "line": {
          "color": "#46039f",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "Training Loss",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274
         ],
         "xaxis": "x",
         "y": [
          0.6812629103660583,
          0.633823573589325,
          0.5656288862228394,
          0.5228666067123413,
          0.5125896334648132,
          0.5139270424842834,
          0.4981304407119751,
          0.5006498098373413,
          0.4977649450302124,
          0.4985390603542328,
          0.487982839345932,
          0.4998140037059784,
          0.48662200570106506,
          0.493988037109375,
          0.49635186791419983,
          0.49700671434402466,
          0.493100643157959,
          0.490488201379776,
          0.4970603883266449,
          0.4836183786392212,
          0.492980033159256,
          0.4923515319824219,
          0.49060362577438354,
          0.49392449855804443,
          0.4975394010543823,
          0.4985325336456299,
          0.4863881766796112,
          0.4879424571990967,
          0.48555082082748413,
          0.49769556522369385,
          0.48947852849960327,
          0.4929187595844269,
          0.48987656831741333,
          0.4881010353565216,
          0.48906606435775757,
          0.48572301864624023,
          0.49278536438941956,
          0.48794883489608765,
          0.48875313997268677,
          0.48567017912864685,
          0.48427125811576843,
          0.4805676341056824,
          0.4733734130859375,
          0.46288129687309265,
          0.44456642866134644,
          0.42823782563209534,
          0.42538633942604065,
          0.4165659546852112,
          0.4140828847885132,
          0.40943461656570435,
          0.40536433458328247,
          0.39959606528282166,
          0.411966472864151,
          0.4030671715736389,
          0.40554261207580566,
          0.3957650363445282,
          0.4009903371334076,
          0.4057563841342926,
          0.40785908699035645,
          0.3964967131614685,
          0.4061873257160187,
          0.3846937417984009,
          0.4035136103630066,
          0.39036405086517334,
          0.38418224453926086,
          0.38931918144226074,
          0.40529412031173706,
          0.3939281404018402,
          0.4040326178073883,
          0.3938220143318176,
          0.39778441190719604,
          0.38949891924858093,
          0.40496498346328735,
          0.39945337176322937,
          0.39646977186203003,
          0.38489943742752075,
          0.388271301984787,
          0.36744439601898193,
          0.38160040974617004,
          0.3856940269470215,
          0.37431490421295166,
          0.37790700793266296,
          0.37683141231536865,
          0.4039982259273529,
          0.37830042839050293,
          0.37852200865745544,
          0.3661389946937561,
          0.37249425053596497,
          0.3899294137954712,
          0.38560155034065247,
          0.3673190772533417,
          0.36768803000450134,
          0.3569149971008301,
          0.3598215878009796,
          0.36361607909202576,
          0.38077250123023987,
          0.3530229330062866,
          0.35224267840385437,
          0.35648876428604126,
          0.3714388310909271,
          0.36416855454444885,
          0.37088316679000854,
          0.3591870367527008,
          0.34852486848831177,
          0.3556286692619324,
          0.34422567486763,
          0.3558800220489502,
          0.3350290060043335,
          0.34866514801979065,
          0.3526526391506195,
          0.3372820317745209,
          0.33471396565437317,
          0.35877683758735657,
          0.34050115942955017,
          0.3382489085197449,
          0.34090858697891235,
          0.35445427894592285,
          0.3473179340362549,
          0.3480958640575409,
          0.33204519748687744,
          0.3427351713180542,
          0.33230099081993103,
          0.34881386160850525,
          0.33172622323036194,
          0.33880093693733215,
          0.3335185647010803,
          0.3278959095478058,
          0.3384131193161011,
          0.34137895703315735,
          0.32781627774238586,
          0.3323597311973572,
          0.32249265909194946,
          0.3277088403701782,
          0.33237478137016296,
          0.3235574960708618,
          0.3298855125904083,
          0.3231862783432007,
          0.3245183825492859,
          0.34630727767944336,
          0.3284952938556671,
          0.3371676504611969,
          0.3249969482421875,
          0.3378244936466217,
          0.32398727536201477,
          0.3231717646121979,
          0.3226194381713867,
          0.3361378014087677,
          0.3159676194190979,
          0.3270966708660126,
          0.31948256492614746,
          0.3186197578907013,
          0.3214060366153717,
          0.3276355266571045,
          0.3168194591999054,
          0.31845730543136597,
          0.3203433156013489,
          0.3104915916919708,
          0.32243484258651733,
          0.31031063199043274,
          0.32320553064346313,
          0.3077579140663147,
          0.3180474042892456,
          0.3052522540092468,
          0.32063931226730347,
          0.31308603286743164,
          0.31070348620414734,
          0.30836182832717896,
          0.31515932083129883,
          0.3177774250507355,
          0.3233952522277832,
          0.30599406361579895,
          0.3162294030189514,
          0.31109991669654846,
          0.300383597612381,
          0.30645689368247986,
          0.29251888394355774,
          0.2997312843799591,
          0.3453283905982971,
          0.30472874641418457,
          0.30422312021255493,
          0.31176435947418213,
          0.29955098032951355,
          0.29969626665115356,
          0.29601648449897766,
          0.3061600923538208,
          0.3034554123878479,
          0.30397313833236694,
          0.2975750267505646,
          0.28168830275535583,
          0.29750657081604004,
          0.28628990054130554,
          0.2840319871902466,
          0.2851583957672119,
          0.29503417015075684,
          0.28256577253341675,
          0.299710214138031,
          0.28551504015922546,
          0.28664007782936096,
          0.29418662190437317,
          0.28676068782806396,
          0.2890860438346863,
          0.2814243733882904,
          0.2915896773338318,
          0.28676337003707886,
          0.28732508420944214,
          0.29151633381843567,
          0.2816598415374756,
          0.277939110994339,
          0.2997618019580841,
          0.28813230991363525,
          0.2873692512512207,
          0.2790290117263794,
          0.29189684987068176,
          0.2727220356464386,
          0.26747408509254456,
          0.29136785864830017,
          0.29064711928367615,
          0.294630765914917,
          0.28265103697776794,
          0.2795717716217041,
          0.2756325602531433,
          0.278102308511734,
          0.2755533456802368,
          0.2722950577735901,
          0.27064573764801025,
          0.27450031042099,
          0.26797157526016235,
          0.2695418894290924,
          0.27240660786628723,
          0.2740180790424347,
          0.2813032567501068,
          0.3301071524620056,
          0.2791799306869507,
          0.3002890944480896,
          0.30331742763519287,
          0.28650957345962524,
          0.27648335695266724,
          0.2695026099681854,
          0.2771157920360565,
          0.2873876094818115,
          0.26647472381591797,
          0.2597940266132355,
          0.2876761257648468,
          0.26973646879196167,
          0.26148584485054016,
          0.2769186198711395,
          0.27775728702545166,
          0.2633347809314728,
          0.2674558460712433,
          0.26879066228866577,
          0.28415393829345703,
          0.2604052424430847,
          0.2746904194355011,
          0.2724195718765259,
          0.2784067988395691,
          0.3054072856903076,
          0.274370938539505,
          0.26643356680870056,
          0.2592655420303345,
          0.2679730951786041,
          0.26519790291786194,
          0.31354308128356934,
          0.2651687264442444,
          0.2758273780345917,
          0.2861509621143341,
          0.2877263128757477,
          0.2607216536998749,
          0.26155519485473633,
          0.2668449580669403,
          0.2616330683231354,
          0.27219358086586,
          0.27327775955200195,
          0.2734418511390686,
          0.2726283669471741,
          0.2597445547580719
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "Curvas de Pérdida=Validation Loss<br>Epoch=%{x}<br>Binary Cross Entropy=%{y}<extra></extra>",
         "legendgroup": "Validation Loss",
         "line": {
          "color": "#fb9f3a",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "Validation Loss",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274
         ],
         "xaxis": "x",
         "y": [
          0.6648840308189392,
          0.6034281253814697,
          0.5441408753395081,
          0.5220763683319092,
          0.5128672122955322,
          0.507682740688324,
          0.5006675720214844,
          0.5018047094345093,
          0.5001225471496582,
          0.5009421110153198,
          0.49579116702079773,
          0.502007782459259,
          0.49447521567344666,
          0.5017170906066895,
          0.496265172958374,
          0.4946437478065491,
          0.49665746092796326,
          0.4948855936527252,
          0.4942800998687744,
          0.4948910176753998,
          0.4934118986129761,
          0.4929583668708801,
          0.4928814768791199,
          0.49357882142066956,
          0.4930266737937927,
          0.495471328496933,
          0.49038535356521606,
          0.49332305788993835,
          0.49391698837280273,
          0.49773597717285156,
          0.4939786195755005,
          0.4932178854942322,
          0.49041324853897095,
          0.4923880696296692,
          0.49325284361839294,
          0.49107876420021057,
          0.49173563718795776,
          0.4943128526210785,
          0.48667600750923157,
          0.4881367087364197,
          0.48199358582496643,
          0.49208900332450867,
          0.47701016068458557,
          0.46770811080932617,
          0.46624991297721863,
          0.4513157308101654,
          0.4430699646472931,
          0.4381328523159027,
          0.442523330450058,
          0.4305340051651001,
          0.44626182317733765,
          0.44377851486206055,
          0.4291268289089203,
          0.4275912642478943,
          0.4205394387245178,
          0.45502179861068726,
          0.4364229738712311,
          0.42658504843711853,
          0.4254871904850006,
          0.44367316365242004,
          0.4400312304496765,
          0.42763471603393555,
          0.4342426657676697,
          0.42912164330482483,
          0.43196630477905273,
          0.4344489872455597,
          0.43333280086517334,
          0.42687705159187317,
          0.422521710395813,
          0.4328455924987793,
          0.41591671109199524,
          0.4662560522556305,
          0.42045164108276367,
          0.43731945753097534,
          0.430938720703125,
          0.4143890142440796,
          0.4329816699028015,
          0.41342777013778687,
          0.40948283672332764,
          0.41076013445854187,
          0.40591126680374146,
          0.3979223072528839,
          0.4057219624519348,
          0.41429397463798523,
          0.3977181911468506,
          0.4074673652648926,
          0.4074126183986664,
          0.397137314081192,
          0.41013091802597046,
          0.41041427850723267,
          0.370792031288147,
          0.38103386759757996,
          0.3818429112434387,
          0.38482406735420227,
          0.41456010937690735,
          0.3672146797180176,
          0.3914644420146942,
          0.3568236231803894,
          0.42553091049194336,
          0.4030594229698181,
          0.3771880865097046,
          0.3750975430011749,
          0.38817912340164185,
          0.376150906085968,
          0.37835121154785156,
          0.35195302963256836,
          0.38009676337242126,
          0.35162732005119324,
          0.3407466411590576,
          0.35388535261154175,
          0.36579084396362305,
          0.39488473534584045,
          0.3705620765686035,
          0.3682401478290558,
          0.3571178913116455,
          0.3434232771396637,
          0.36393487453460693,
          0.34286320209503174,
          0.3690023720264435,
          0.3457795977592468,
          0.32236021757125854,
          0.3375352919101715,
          0.3535672724246979,
          0.3295444846153259,
          0.33158573508262634,
          0.33491867780685425,
          0.3251362442970276,
          0.34383293986320496,
          0.3417927622795105,
          0.3174067735671997,
          0.34374046325683594,
          0.33225131034851074,
          0.3214486837387085,
          0.3207530081272125,
          0.313305139541626,
          0.31483983993530273,
          0.338554322719574,
          0.31748083233833313,
          0.30672767758369446,
          0.3256068229675293,
          0.3216519355773926,
          0.324606329202652,
          0.3271302580833435,
          0.33359232544898987,
          0.36377111077308655,
          0.35821670293807983,
          0.31546661257743835,
          0.31708937883377075,
          0.3062618672847748,
          0.3064603805541992,
          0.3113900125026703,
          0.311514288187027,
          0.32206106185913086,
          0.31764087080955505,
          0.30702611804008484,
          0.3066658079624176,
          0.3424016535282135,
          0.300382137298584,
          0.29896336793899536,
          0.3272794187068939,
          0.30599212646484375,
          0.29589396715164185,
          0.3021637797355652,
          0.2920146584510803,
          0.2989867925643921,
          0.3012019693851471,
          0.2815256416797638,
          0.3984120488166809,
          0.3340805172920227,
          0.2826971411705017,
          0.30197659134864807,
          0.3023187816143036,
          0.28077858686447144,
          0.28446778655052185,
          0.2888062596321106,
          0.2714955806732178,
          0.5974489450454712,
          0.30380138754844666,
          0.2782588601112366,
          0.2818332314491272,
          0.28064751625061035,
          0.28557005524635315,
          0.290361225605011,
          0.2711956799030304,
          0.2840100824832916,
          0.2870738208293915,
          0.2877109944820404,
          0.2847360372543335,
          0.278315931558609,
          0.2708074748516083,
          0.2728162109851837,
          0.26746752858161926,
          0.2679685652256012,
          0.2760016918182373,
          0.2752602994441986,
          0.28941527009010315,
          0.2653696537017822,
          0.25526365637779236,
          0.2566501200199127,
          0.26444441080093384,
          0.26318952441215515,
          0.250620573759079,
          0.252022922039032,
          0.25907760858535767,
          0.2493242472410202,
          0.2548101544380188,
          0.25907906889915466,
          0.24042591452598572,
          0.24903222918510437,
          0.25875306129455566,
          0.25715532898902893,
          0.2486100047826767,
          0.25853970646858215,
          0.2517785429954529,
          0.24547992646694183,
          0.25586047768592834,
          0.2602446973323822,
          0.26875734329223633,
          0.24083562195301056,
          0.23949582874774933,
          0.23756688833236694,
          0.23831278085708618,
          0.2384181022644043,
          0.241369366645813,
          0.23751147091388702,
          0.239755779504776,
          0.24717207252979279,
          0.23082418739795685,
          0.22831512987613678,
          0.25204747915267944,
          0.486278235912323,
          0.24068188667297363,
          0.2403188794851303,
          0.2773253619670868,
          0.2622310519218445,
          0.2543632388114929,
          0.25251534581184387,
          0.23859481513500214,
          0.24413524568080902,
          0.2410575896501541,
          0.2357766181230545,
          0.23892143368721008,
          0.24449658393859863,
          0.24026966094970703,
          0.2456567883491516,
          0.229926198720932,
          0.24734832346439362,
          0.2288755476474762,
          0.24896110594272614,
          0.2300298511981964,
          0.23462142050266266,
          0.24056090414524078,
          0.2541528642177582,
          0.23327910900115967,
          0.23371639847755432,
          0.24476143717765808,
          0.23581373691558838,
          0.23908701539039612,
          0.24057871103286743,
          0.23004774749279022,
          0.23273921012878418,
          0.3471042811870575,
          0.27190709114074707,
          0.2545977830886841,
          0.26216045022010803,
          0.24911756813526154,
          0.2397042214870453,
          0.23914863169193268,
          0.22295930981636047,
          0.23648349940776825,
          0.2354445606470108,
          0.24308189749717712,
          0.24210327863693237,
          0.22699935734272003,
          0.21853424608707428
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "Curvas de Pérdida"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Gráficas de Pérdida de Entrenamiento y Evaluación"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Epoch"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Binary Cross Entropy"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Curvas de Exactitud=Exactitud de Entrenamiento<br>Epoch=%{x}<br>Exactitud=%{y}<extra></extra>",
         "legendgroup": "Exactitud de Entrenamiento",
         "line": {
          "color": "#00cc96",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "Exactitud de Entrenamiento",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274
         ],
         "xaxis": "x",
         "y": [
          0.2448979616165161,
          0.23469388484954834,
          0.19387754797935486,
          0.20408163964748383,
          0.29591837525367737,
          0.2857142984867096,
          0.30612245202064514,
          0.27551019191741943,
          0.3265306055545807,
          0.30612245202064514,
          0.29591837525367737,
          0.2857142984867096,
          0.30612245202064514,
          0.3571428656578064,
          0.3265306055545807,
          0.29591837525367737,
          0.3163265287876129,
          0.30612245202064514,
          0.26530611515045166,
          0.3469387888908386,
          0.30612245202064514,
          0.30612245202064514,
          0.30612245202064514,
          0.30612245202064514,
          0.27551019191741943,
          0.3163265287876129,
          0.36734694242477417,
          0.3571428656578064,
          0.30612245202064514,
          0.3265306055545807,
          0.29591837525367737,
          0.3265306055545807,
          0.2857142984867096,
          0.3163265287876129,
          0.30612245202064514,
          0.3469387888908386,
          0.2551020383834839,
          0.26530611515045166,
          0.2448979616165161,
          0.3163265287876129,
          0.30612245202064514,
          0.3469387888908386,
          0.37755101919174194,
          0.3265306055545807,
          0.3979591727256775,
          0.43877550959587097,
          0.4183673560619354,
          0.4183673560619354,
          0.4285714328289032,
          0.40816327929496765,
          0.43877550959587097,
          0.40816327929496765,
          0.44897958636283875,
          0.4285714328289032,
          0.44897958636283875,
          0.43877550959587097,
          0.3877550959587097,
          0.4591836631298065,
          0.40816327929496765,
          0.43877550959587097,
          0.40816327929496765,
          0.4693877696990967,
          0.43877550959587097,
          0.44897958636283875,
          0.4591836631298065,
          0.47959184646606445,
          0.47959184646606445,
          0.4285714328289032,
          0.40816327929496765,
          0.44897958636283875,
          0.4183673560619354,
          0.4591836631298065,
          0.44897958636283875,
          0.43877550959587097,
          0.44897958636283875,
          0.4591836631298065,
          0.5,
          0.4897959232330322,
          0.4693877696990967,
          0.44897958636283875,
          0.4897959232330322,
          0.5,
          0.4693877696990967,
          0.43877550959587097,
          0.5,
          0.4591836631298065,
          0.4693877696990967,
          0.4897959232330322,
          0.4591836631298065,
          0.4897959232330322,
          0.4591836631298065,
          0.5102040767669678,
          0.4591836631298065,
          0.5102040767669678,
          0.5102040767669678,
          0.4591836631298065,
          0.47959184646606445,
          0.47959184646606445,
          0.581632673740387,
          0.5204081535339355,
          0.4591836631298065,
          0.4693877696990967,
          0.5102040767669678,
          0.4897959232330322,
          0.5510203838348389,
          0.5204081535339355,
          0.47959184646606445,
          0.5510203838348389,
          0.4285714328289032,
          0.4591836631298065,
          0.581632673740387,
          0.5408163070678711,
          0.5510203838348389,
          0.5306122303009033,
          0.5510203838348389,
          0.4897959232330322,
          0.4693877696990967,
          0.5408163070678711,
          0.5714285969734192,
          0.5306122303009033,
          0.5306122303009033,
          0.6122449040412903,
          0.5306122303009033,
          0.5918367505073547,
          0.5510203838348389,
          0.5102040767669678,
          0.5612244606018066,
          0.5408163070678711,
          0.5408163070678711,
          0.5102040767669678,
          0.5204081535339355,
          0.5612244606018066,
          0.5612244606018066,
          0.5,
          0.5918367505073547,
          0.5510203838348389,
          0.5306122303009033,
          0.6122449040412903,
          0.5102040767669678,
          0.5714285969734192,
          0.5510203838348389,
          0.5102040767669678,
          0.5306122303009033,
          0.6020408272743225,
          0.6530612111091614,
          0.6020408272743225,
          0.5510203838348389,
          0.6428571343421936,
          0.6020408272743225,
          0.6326530575752258,
          0.6020408272743225,
          0.6224489808082581,
          0.5714285969734192,
          0.5714285969734192,
          0.5918367505073547,
          0.5714285969734192,
          0.6224489808082581,
          0.5714285969734192,
          0.6326530575752258,
          0.6020408272743225,
          0.6530612111091614,
          0.6428571343421936,
          0.6020408272743225,
          0.5714285969734192,
          0.6428571343421936,
          0.6122449040412903,
          0.6122449040412903,
          0.6326530575752258,
          0.6020408272743225,
          0.5612244606018066,
          0.6224489808082581,
          0.6224489808082581,
          0.6122449040412903,
          0.6428571343421936,
          0.6326530575752258,
          0.704081654548645,
          0.6428571343421936,
          0.581632673740387,
          0.5918367505073547,
          0.6224489808082581,
          0.5612244606018066,
          0.6632652878761292,
          0.6326530575752258,
          0.6428571343421936,
          0.6428571343421936,
          0.6530612111091614,
          0.6224489808082581,
          0.6326530575752258,
          0.6734693646430969,
          0.6530612111091614,
          0.6632652878761292,
          0.6734693646430969,
          0.6836734414100647,
          0.6632652878761292,
          0.6836734414100647,
          0.6326530575752258,
          0.6734693646430969,
          0.6734693646430969,
          0.6326530575752258,
          0.6428571343421936,
          0.6734693646430969,
          0.6734693646430969,
          0.6632652878761292,
          0.6224489808082581,
          0.6632652878761292,
          0.6428571343421936,
          0.6734693646430969,
          0.6632652878761292,
          0.6530612111091614,
          0.6530612111091614,
          0.6632652878761292,
          0.6428571343421936,
          0.6122449040412903,
          0.6938775777816772,
          0.6938775777816772,
          0.6632652878761292,
          0.6530612111091614,
          0.6020408272743225,
          0.6428571343421936,
          0.6734693646430969,
          0.6632652878761292,
          0.6734693646430969,
          0.6938775777816772,
          0.6734693646430969,
          0.6938775777816772,
          0.6734693646430969,
          0.6938775777816772,
          0.6938775777816772,
          0.6836734414100647,
          0.6836734414100647,
          0.6836734414100647,
          0.6122449040412903,
          0.6632652878761292,
          0.5918367505073547,
          0.5918367505073547,
          0.6734693646430969,
          0.6632652878761292,
          0.6734693646430969,
          0.6836734414100647,
          0.6530612111091614,
          0.6836734414100647,
          0.6938775777816772,
          0.6326530575752258,
          0.6632652878761292,
          0.6734693646430969,
          0.6938775777816772,
          0.6836734414100647,
          0.704081654548645,
          0.704081654548645,
          0.7142857313156128,
          0.6734693646430969,
          0.6836734414100647,
          0.6734693646430969,
          0.6836734414100647,
          0.6734693646430969,
          0.6326530575752258,
          0.704081654548645,
          0.6938775777816772,
          0.7142857313156128,
          0.6836734414100647,
          0.6938775777816772,
          0.6428571343421936,
          0.6938775777816772,
          0.6938775777816772,
          0.6428571343421936,
          0.6428571343421936,
          0.6632652878761292,
          0.7142857313156128,
          0.6632652878761292,
          0.7142857313156128,
          0.6836734414100647,
          0.6938775777816772,
          0.6836734414100647,
          0.6938775777816772,
          0.704081654548645
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "Curvas de Exactitud=Exactitud de Validación<br>Epoch=%{x}<br>Exactitud=%{y}<extra></extra>",
         "legendgroup": "Exactitud de Validación",
         "line": {
          "color": "#ab63fa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "Exactitud de Validación",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274
         ],
         "xaxis": "x",
         "y": [
          0.27272728085517883,
          0.06060606241226196,
          0.06060606241226196,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.27272728085517883,
          0.3333333432674408,
          0.3030303120613098,
          0.3333333432674408,
          0.3333333432674408,
          0.3333333432674408,
          0.3333333432674408,
          0.3333333432674408,
          0.3333333432674408,
          0.3333333432674408,
          0.3333333432674408,
          0.3333333432674408,
          0.3333333432674408,
          0.3333333432674408,
          0.3333333432674408,
          0.39393940567970276,
          0.3333333432674408,
          0.3333333432674408,
          0.3333333432674408,
          0.3333333432674408,
          0.3333333432674408,
          0.3333333432674408,
          0.3333333432674408,
          0.3333333432674408,
          0.3333333432674408,
          0.3333333432674408,
          0.3333333432674408,
          0.3333333432674408,
          0.3333333432674408,
          0.3333333432674408,
          0.3333333432674408,
          0.39393940567970276,
          0.3333333432674408,
          0.3333333432674408,
          0.3636363744735718,
          0.3333333432674408,
          0.39393940567970276,
          0.3333333432674408,
          0.39393940567970276,
          0.3333333432674408,
          0.39393940567970276,
          0.39393940567970276,
          0.3636363744735718,
          0.3636363744735718,
          0.3636363744735718,
          0.39393940567970276,
          0.39393940567970276,
          0.3636363744735718,
          0.39393940567970276,
          0.39393940567970276,
          0.39393940567970276,
          0.42424243688583374,
          0.4848484992980957,
          0.42424243688583374,
          0.4848484992980957,
          0.4545454680919647,
          0.42424243688583374,
          0.5151515007019043,
          0.4848484992980957,
          0.39393940567970276,
          0.42424243688583374,
          0.42424243688583374,
          0.39393940567970276,
          0.42424243688583374,
          0.4545454680919647,
          0.4545454680919647,
          0.4848484992980957,
          0.4545454680919647,
          0.5454545617103577,
          0.5151515007019043,
          0.5454545617103577,
          0.4848484992980957,
          0.4545454680919647,
          0.4848484992980957,
          0.4848484992980957,
          0.5757575631141663,
          0.42424243688583374,
          0.4848484992980957,
          0.4848484992980957,
          0.5757575631141663,
          0.6969696879386902,
          0.7272727489471436,
          0.5151515007019043,
          0.6060606241226196,
          0.5454545617103577,
          0.5454545617103577,
          0.6060606241226196,
          0.4848484992980957,
          0.5454545617103577,
          0.5151515007019043,
          0.5454545617103577,
          0.7272727489471436,
          0.5757575631141663,
          0.5757575631141663,
          0.6363636255264282,
          0.6060606241226196,
          0.5151515007019043,
          0.6060606241226196,
          0.6363636255264282,
          0.7575757503509521,
          0.6969696879386902,
          0.5757575631141663,
          0.4848484992980957,
          0.6666666865348816,
          0.6363636255264282,
          0.4848484992980957,
          0.7575757503509521,
          0.5757575631141663,
          0.6666666865348816,
          0.6060606241226196,
          0.7272727489471436,
          0.7575757503509521,
          0.5757575631141663,
          0.5757575631141663,
          0.6969696879386902,
          0.6666666865348816,
          0.5454545617103577,
          0.6060606241226196,
          0.6060606241226196,
          0.5757575631141663,
          0.6666666865348816,
          0.6969696879386902,
          0.5454545617103577,
          0.6969696879386902,
          0.6363636255264282,
          0.6969696879386902,
          0.7575757503509521,
          0.7272727489471436,
          0.5757575631141663,
          0.7272727489471436,
          0.7272727489471436,
          0.7272727489471436,
          0.7575757503509521,
          0.7878788113594055,
          0.6666666865348816,
          0.7272727489471436,
          0.6363636255264282,
          0.7575757503509521,
          0.7272727489471436,
          0.6969696879386902,
          0.7575757503509521,
          0.7272727489471436,
          0.6666666865348816,
          0.7878788113594055,
          0.6666666865348816,
          0.7575757503509521,
          0.6363636255264282,
          0.6969696879386902,
          0.7272727489471436,
          0.7272727489471436,
          0.7272727489471436,
          0.6969696879386902,
          0.7272727489471436,
          0.6969696879386902,
          0.6969696879386902,
          0.6666666865348816,
          0.7272727489471436,
          0.7575757503509521,
          0.7272727489471436,
          0.6969696879386902,
          0.7575757503509521,
          0.7575757503509521,
          0.7878788113594055,
          0.7272727489471436,
          0.7575757503509521,
          0.7878788113594055,
          0.6969696879386902,
          0.7575757503509521,
          0.7878788113594055,
          0.7272727489471436,
          0.7272727489471436,
          0.7272727489471436,
          0.7272727489471436,
          0.7272727489471436,
          0.7878788113594055,
          0.7272727489471436,
          0.6969696879386902,
          0.6363636255264282,
          0.7575757503509521,
          0.7272727489471436,
          0.7272727489471436,
          0.7272727489471436,
          0.7575757503509521,
          0.7272727489471436,
          0.7878788113594055,
          0.7272727489471436,
          0.6969696879386902,
          0.7878788113594055,
          0.7272727489471436,
          0.6969696879386902,
          0.7272727489471436,
          0.7575757503509521,
          0.7272727489471436,
          0.5757575631141663,
          0.7272727489471436,
          0.7272727489471436,
          0.7272727489471436,
          0.7272727489471436,
          0.7272727489471436,
          0.7272727489471436,
          0.7272727489471436,
          0.7272727489471436,
          0.7272727489471436,
          0.7272727489471436,
          0.7272727489471436,
          0.7878788113594055,
          0.7272727489471436,
          0.7272727489471436,
          0.7272727489471436,
          0.7878788113594055,
          0.7272727489471436,
          0.7272727489471436,
          0.6969696879386902,
          0.7272727489471436,
          0.7272727489471436,
          0.7272727489471436,
          0.7272727489471436,
          0.7272727489471436,
          0.7272727489471436,
          0.7272727489471436,
          0.7272727489471436,
          0.6969696879386902,
          0.6060606241226196,
          0.7272727489471436,
          0.6666666865348816,
          0.6969696879386902,
          0.7272727489471436,
          0.7272727489471436,
          0.7575757503509521,
          0.7272727489471436,
          0.7575757503509521,
          0.7272727489471436,
          0.7272727489471436,
          0.7272727489471436,
          0.7575757503509521
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "Curvas de Exactitud"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Gráficas de Exactitud"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Epoch"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Exactitud"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Exactitud de Entrenamiento</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Exactitud de Validación</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.681</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.634</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.061</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.566</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.061</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.523</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.273</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.513</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.273</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>0.272</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.758</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>0.273</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.727</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>0.273</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.727</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>0.273</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.727</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>0.260</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.758</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>275 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Training Loss  Exactitud de Entrenamiento  Validation Loss  \\\n",
       "0            0.681                       0.245            0.665   \n",
       "1            0.634                       0.235            0.603   \n",
       "2            0.566                       0.194            0.544   \n",
       "3            0.523                       0.204            0.522   \n",
       "4            0.513                       0.296            0.513   \n",
       "..             ...                         ...              ...   \n",
       "270          0.272                       0.684            0.235   \n",
       "271          0.273                       0.694            0.243   \n",
       "272          0.273                       0.684            0.242   \n",
       "273          0.273                       0.694            0.227   \n",
       "274          0.260                       0.704            0.219   \n",
       "\n",
       "     Exactitud de Validación  epoch  \n",
       "0                      0.273      0  \n",
       "1                      0.061      1  \n",
       "2                      0.061      2  \n",
       "3                      0.273      3  \n",
       "4                      0.273      4  \n",
       "..                       ...    ...  \n",
       "270                    0.758    270  \n",
       "271                    0.727    271  \n",
       "272                    0.727    272  \n",
       "273                    0.727    273  \n",
       "274                    0.758    274  \n",
       "\n",
       "[275 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "epochs = 275\n",
    "batch_size = 5\n",
    "model = my_model(learning_rate)\n",
    "history= train_model(model, train_features, train_labels, epochs, batch_size)\n",
    "display(history)\n",
    "loss_curves(history)\n",
    "accuracy_curve(history)\n",
    "#view_filters(model)\n",
    "display(history)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normal</th>\n",
       "      <th>collision_in_tool</th>\n",
       "      <th>collision_in_part</th>\n",
       "      <th>bottom_collision</th>\n",
       "      <th>bottom_obstruction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.817</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.011</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.739</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    normal  collision_in_tool  collision_in_part  bottom_collision  \\\n",
       "0    0.000              0.004              0.208             0.768   \n",
       "1    0.000              0.000              0.000             0.000   \n",
       "2    0.000              0.000              0.000             0.701   \n",
       "3    0.817              0.082              0.099             0.001   \n",
       "4    0.001              0.070              0.843             0.063   \n",
       "..     ...                ...                ...               ...   \n",
       "28   0.000              0.001              0.080             0.908   \n",
       "29   0.005              0.106              0.826             0.039   \n",
       "30   0.000              0.002              0.158             0.824   \n",
       "31   0.011              0.090              0.799             0.072   \n",
       "32   0.739              0.112              0.147             0.002   \n",
       "\n",
       "    bottom_obstruction  \n",
       "0                0.020  \n",
       "1                1.000  \n",
       "2                0.299  \n",
       "3                0.000  \n",
       "4                0.023  \n",
       "..                 ...  \n",
       "28               0.012  \n",
       "29               0.023  \n",
       "30               0.016  \n",
       "31               0.028  \n",
       "32               0.001  \n",
       "\n",
       "[33 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1  2  3  4  5\n",
       "135  0  0  0  1  0\n",
       "115  0  0  0  0  1\n",
       "131  0  0  0  0  1\n",
       "55   1  0  0  0  0\n",
       "95   0  1  0  0  0\n",
       "..  .. .. .. .. ..\n",
       "134  0  0  0  1  0\n",
       "160  0  1  0  0  0\n",
       "139  0  0  0  1  0\n",
       "78   0  0  1  0  0\n",
       "60   1  0  0  0  0\n",
       "\n",
       "[33 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ModeloConvolucion_A0.75\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ModeloConvolucion_A0.75\\assets\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_features)\n",
    "predictions_df = pd.DataFrame(predictions, columns=['normal', 'collision_in_tool', 'collision_in_part', 'bottom_collision', 'bottom_obstruction'])\n",
    "display(predictions_df)\n",
    "display(test_labels)\n",
    "model.save('ModeloConvolucion_A0.75')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
